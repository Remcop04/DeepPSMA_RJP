
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-04-17 17:19:43.065814: Using torch.compile... 
2025-04-17 17:19:46.511684: do_dummy_2d_data_aug: False 
2025-04-17 17:19:46.512761: Using splits from existing split file: /physical_sciences/DEEP-PSMA/GTRC_Baseline/nnUNet_data/preprocessed/Dataset801_PSMA_PET/splits_final.json 
2025-04-17 17:19:46.513442: The split file contains 5 splits. 
2025-04-17 17:19:46.513551: Desired fold for training: 0 
2025-04-17 17:19:46.513643: This split has 80 training and 20 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 192, 112], 'median_image_size_in_voxels': [183.0, 335.0, 183.0], 'spacing': [3.822916626930237, 3.2699999809265137, 3.822916626930237], 'normalization_schemes': ['NoNormalization', 'CTNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset801_PSMA_PET', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.822916626930237, 3.2699999809265137, 3.822916626930237], 'original_median_shape_after_transp': [192, 335, 192], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 122.71910858154297, 'mean': 2.8940117359161377, 'median': 1.8349229097366333, 'min': 1.0, 'percentile_00_5': 1.005632758140564, 'percentile_99_5': 20.26571466445921, 'std': 3.168116807937622}, '1': {'max': 3071.0, 'mean': 50.1551513671875, 'median': 33.0, 'min': -1024.0, 'percentile_00_5': -725.0, 'percentile_99_5': 976.0, 'std': 191.87095642089844}}} 
 
2025-04-17 17:19:52.520079: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-04-17 17:19:52.570533:  
2025-04-17 17:19:52.571188: Epoch 700 
2025-04-17 17:19:52.572309: Current learning rate: 0.00338 
2025-04-17 17:24:32.474351: train_loss -0.9038 
2025-04-17 17:24:32.477579: val_loss -0.8717 
2025-04-17 17:24:32.477788: Pseudo dice [np.float32(0.9024), np.float32(0.9447)] 
2025-04-17 17:24:32.477944: Epoch time: 279.91 s 
2025-04-17 17:24:33.637656:  
2025-04-17 17:24:33.637908: Epoch 701 
2025-04-17 17:24:33.638088: Current learning rate: 0.00337 
2025-04-17 17:27:45.443320: train_loss -0.9046 
2025-04-17 17:27:45.447676: val_loss -0.8672 
2025-04-17 17:27:45.448058: Pseudo dice [np.float32(0.9146), np.float32(0.9413)] 
2025-04-17 17:27:45.448373: Epoch time: 191.81 s 
2025-04-17 17:27:46.575846:  
2025-04-17 17:27:46.576316: Epoch 702 
2025-04-17 17:27:46.576627: Current learning rate: 0.00336 
2025-04-17 17:30:56.462681: train_loss -0.9056 
2025-04-17 17:30:56.463614: val_loss -0.8569 
2025-04-17 17:30:56.463931: Pseudo dice [np.float32(0.8976), np.float32(0.9272)] 
2025-04-17 17:30:56.464222: Epoch time: 189.89 s 
2025-04-17 17:30:57.555119:  
2025-04-17 17:30:57.555620: Epoch 703 
2025-04-17 17:30:57.555943: Current learning rate: 0.00335 
2025-04-17 17:34:11.240955: train_loss -0.9126 
2025-04-17 17:34:11.244500: val_loss -0.8532 
2025-04-17 17:34:11.244790: Pseudo dice [np.float32(0.8954), np.float32(0.9393)] 
2025-04-17 17:34:11.245057: Epoch time: 193.69 s 
2025-04-17 17:34:12.348078:  
2025-04-17 17:34:12.348629: Epoch 704 
2025-04-17 17:34:12.348944: Current learning rate: 0.00334 
2025-04-17 17:37:26.743301: train_loss -0.9017 
2025-04-17 17:37:26.745627: val_loss -0.8692 
2025-04-17 17:37:26.745950: Pseudo dice [np.float32(0.9149), np.float32(0.9443)] 
2025-04-17 17:37:26.746275: Epoch time: 194.4 s 
2025-04-17 17:37:27.869265:  
2025-04-17 17:37:27.869769: Epoch 705 
2025-04-17 17:37:27.870076: Current learning rate: 0.00333 
2025-04-17 17:40:42.425151: train_loss -0.9096 
2025-04-17 17:40:42.428378: val_loss -0.8556 
2025-04-17 17:40:42.428681: Pseudo dice [np.float32(0.9004), np.float32(0.933)] 
2025-04-17 17:40:42.428957: Epoch time: 194.56 s 
2025-04-17 17:40:43.527140:  
2025-04-17 17:40:43.527672: Epoch 706 
2025-04-17 17:40:43.528003: Current learning rate: 0.00332 
2025-04-17 17:43:57.959775: train_loss -0.9068 
2025-04-17 17:43:57.960604: val_loss -0.8692 
2025-04-17 17:43:57.960879: Pseudo dice [np.float32(0.9095), np.float32(0.9375)] 
2025-04-17 17:43:57.961178: Epoch time: 194.43 s 
2025-04-17 17:43:59.045244:  
2025-04-17 17:43:59.046123: Epoch 707 
2025-04-17 17:43:59.046429: Current learning rate: 0.00331 
2025-04-17 17:47:13.610511: train_loss -0.9037 
2025-04-17 17:47:13.614002: val_loss -0.8746 
2025-04-17 17:47:13.614321: Pseudo dice [np.float32(0.9079), np.float32(0.9479)] 
2025-04-17 17:47:13.614594: Epoch time: 194.57 s 
2025-04-17 17:47:14.727182:  
2025-04-17 17:47:14.727642: Epoch 708 
2025-04-17 17:47:14.727943: Current learning rate: 0.0033 
2025-04-17 17:50:29.376258: train_loss -0.9064 
2025-04-17 17:50:29.377088: val_loss -0.8523 
2025-04-17 17:50:29.377358: Pseudo dice [np.float32(0.9094), np.float32(0.9417)] 
2025-04-17 17:50:29.377638: Epoch time: 194.65 s 
2025-04-17 17:50:30.473161:  
2025-04-17 17:50:30.473606: Epoch 709 
2025-04-17 17:50:30.473924: Current learning rate: 0.00329 
2025-04-17 17:53:45.262571: train_loss -0.9109 
2025-04-17 17:53:45.265852: val_loss -0.8481 
2025-04-17 17:53:45.266119: Pseudo dice [np.float32(0.8922), np.float32(0.9395)] 
2025-04-17 17:53:45.266387: Epoch time: 194.79 s 
2025-04-17 17:53:46.338961:  
2025-04-17 17:53:46.339499: Epoch 710 
2025-04-17 17:53:46.339827: Current learning rate: 0.00328 
2025-04-17 17:57:01.088375: train_loss -0.9103 
2025-04-17 17:57:01.089234: val_loss -0.8843 
2025-04-17 17:57:01.089517: Pseudo dice [np.float32(0.9118), np.float32(0.9577)] 
2025-04-17 17:57:01.089806: Epoch time: 194.75 s 
2025-04-17 17:57:02.982139:  
2025-04-17 17:57:02.982736: Epoch 711 
2025-04-17 17:57:02.983091: Current learning rate: 0.00327 
2025-04-17 18:00:18.217153: train_loss -0.9121 
2025-04-17 18:00:18.220925: val_loss -0.8919 
2025-04-17 18:00:18.221245: Pseudo dice [np.float32(0.9268), np.float32(0.9559)] 
2025-04-17 18:00:18.221557: Epoch time: 195.24 s 
2025-04-17 18:00:19.330492:  
2025-04-17 18:00:19.331059: Epoch 712 
2025-04-17 18:00:19.331428: Current learning rate: 0.00326 
2025-04-17 18:03:34.565835: train_loss -0.9175 
2025-04-17 18:03:34.566599: val_loss -0.8711 
2025-04-17 18:03:34.566877: Pseudo dice [np.float32(0.9159), np.float32(0.9445)] 
2025-04-17 18:03:34.567165: Epoch time: 195.24 s 
2025-04-17 18:03:35.709575:  
2025-04-17 18:03:35.710103: Epoch 713 
2025-04-17 18:03:35.710424: Current learning rate: 0.00325 
2025-04-17 18:06:51.121564: train_loss -0.9064 
2025-04-17 18:06:51.125701: val_loss -0.863 
2025-04-17 18:06:51.126052: Pseudo dice [np.float32(0.9138), np.float32(0.9464)] 
2025-04-17 18:06:51.126375: Epoch time: 195.41 s 
2025-04-17 18:06:52.235154:  
2025-04-17 18:06:52.235735: Epoch 714 
2025-04-17 18:06:52.236091: Current learning rate: 0.00324 
2025-04-17 18:10:07.363621: train_loss -0.9078 
2025-04-17 18:10:07.364430: val_loss -0.8784 
2025-04-17 18:10:07.364723: Pseudo dice [np.float32(0.9033), np.float32(0.95)] 
2025-04-17 18:10:07.365016: Epoch time: 195.13 s 
2025-04-17 18:10:08.461494:  
2025-04-17 18:10:08.462010: Epoch 715 
2025-04-17 18:10:08.462329: Current learning rate: 0.00323 
2025-04-17 18:13:22.963803: train_loss -0.9008 
2025-04-17 18:13:22.964598: val_loss -0.8612 
2025-04-17 18:13:22.964865: Pseudo dice [np.float32(0.906), np.float32(0.9381)] 
2025-04-17 18:13:22.965243: Epoch time: 194.5 s 
2025-04-17 18:13:24.070305:  
2025-04-17 18:13:24.070809: Epoch 716 
2025-04-17 18:13:24.071142: Current learning rate: 0.00322 
2025-04-17 18:16:38.662004: train_loss -0.9093 
2025-04-17 18:16:38.662843: val_loss -0.8744 
2025-04-17 18:16:38.663129: Pseudo dice [np.float32(0.9118), np.float32(0.9475)] 
2025-04-17 18:16:38.663420: Epoch time: 194.59 s 
2025-04-17 18:16:39.792245:  
2025-04-17 18:16:39.792866: Epoch 717 
2025-04-17 18:16:39.793201: Current learning rate: 0.00321 
2025-04-17 18:19:54.550235: train_loss -0.9053 
2025-04-17 18:19:54.551015: val_loss -0.8574 
2025-04-17 18:19:54.551304: Pseudo dice [np.float32(0.8972), np.float32(0.9341)] 
2025-04-17 18:19:54.551584: Epoch time: 194.76 s 
2025-04-17 18:19:55.867718:  
2025-04-17 18:19:55.868304: Epoch 718 
2025-04-17 18:19:55.868641: Current learning rate: 0.0032 
2025-04-17 18:23:10.437445: train_loss -0.9113 
2025-04-17 18:23:10.441822: val_loss -0.8644 
2025-04-17 18:23:10.442147: Pseudo dice [np.float32(0.9031), np.float32(0.9424)] 
2025-04-17 18:23:10.442463: Epoch time: 194.57 s 
2025-04-17 18:23:11.558658:  
2025-04-17 18:23:11.559189: Epoch 719 
2025-04-17 18:23:11.559533: Current learning rate: 0.00319 
2025-04-17 18:26:26.143944: train_loss -0.9115 
2025-04-17 18:26:26.144846: val_loss -0.8822 
2025-04-17 18:26:26.145154: Pseudo dice [np.float32(0.9173), np.float32(0.9582)] 
2025-04-17 18:26:26.145453: Epoch time: 194.59 s 
2025-04-17 18:26:27.266257:  
2025-04-17 18:26:27.266843: Epoch 720 
2025-04-17 18:26:27.267187: Current learning rate: 0.00318 
2025-04-17 18:29:41.259971: train_loss -0.9085 
2025-04-17 18:29:41.263523: val_loss -0.8706 
2025-04-17 18:29:41.263850: Pseudo dice [np.float32(0.8944), np.float32(0.9333)] 
2025-04-17 18:29:41.264149: Epoch time: 194.0 s 
2025-04-17 18:29:42.410755:  
2025-04-17 18:29:42.411384: Epoch 721 
2025-04-17 18:29:42.411732: Current learning rate: 0.00317 
2025-04-17 18:32:56.299437: train_loss -0.9099 
2025-04-17 18:32:56.300283: val_loss -0.8523 
2025-04-17 18:32:56.300614: Pseudo dice [np.float32(0.9028), np.float32(0.9407)] 
2025-04-17 18:32:56.300930: Epoch time: 193.89 s 
2025-04-17 18:32:57.468158:  
2025-04-17 18:32:57.468750: Epoch 722 
2025-04-17 18:32:57.469103: Current learning rate: 0.00316 
2025-04-17 18:36:11.455118: train_loss -0.9042 
2025-04-17 18:36:11.459104: val_loss -0.848 
2025-04-17 18:36:11.459410: Pseudo dice [np.float32(0.891), np.float32(0.948)] 
2025-04-17 18:36:11.459702: Epoch time: 193.99 s 
2025-04-17 18:36:12.588383:  
2025-04-17 18:36:12.588920: Epoch 723 
2025-04-17 18:36:12.589268: Current learning rate: 0.00315 
2025-04-17 18:39:26.504301: train_loss -0.9102 
2025-04-17 18:39:26.505160: val_loss -0.8706 
2025-04-17 18:39:26.505473: Pseudo dice [np.float32(0.9163), np.float32(0.9422)] 
2025-04-17 18:39:26.505798: Epoch time: 193.92 s 
2025-04-17 18:39:27.653762:  
2025-04-17 18:39:27.654375: Epoch 724 
2025-04-17 18:39:27.654731: Current learning rate: 0.00314 
2025-04-17 18:42:41.694841: train_loss -0.9033 
2025-04-17 18:42:41.698346: val_loss -0.8761 
2025-04-17 18:42:41.699066: Pseudo dice [np.float32(0.9177), np.float32(0.9525)] 
2025-04-17 18:42:41.699373: Epoch time: 194.04 s 
2025-04-17 18:42:42.823694:  
2025-04-17 18:42:42.824326: Epoch 725 
2025-04-17 18:42:42.824656: Current learning rate: 0.00313 
2025-04-17 18:45:56.571077: train_loss -0.9108 
2025-04-17 18:45:56.571879: val_loss -0.8682 
2025-04-17 18:45:56.572160: Pseudo dice [np.float32(0.8918), np.float32(0.9384)] 
2025-04-17 18:45:56.572446: Epoch time: 193.75 s 
2025-04-17 18:45:57.669489:  
2025-04-17 18:45:57.670065: Epoch 726 
2025-04-17 18:45:57.670397: Current learning rate: 0.00312 
2025-04-17 18:49:11.491978: train_loss -0.9043 
2025-04-17 18:49:11.495477: val_loss -0.8486 
2025-04-17 18:49:11.495813: Pseudo dice [np.float32(0.9001), np.float32(0.9392)] 
2025-04-17 18:49:11.496122: Epoch time: 193.82 s 
2025-04-17 18:49:12.611181:  
2025-04-17 18:49:12.611663: Epoch 727 
2025-04-17 18:49:12.611988: Current learning rate: 0.00311 
2025-04-17 18:52:26.669794: train_loss -0.9131 
2025-04-17 18:52:26.670674: val_loss -0.8912 
2025-04-17 18:52:26.670975: Pseudo dice [np.float32(0.925), np.float32(0.9545)] 
2025-04-17 18:52:26.671278: Epoch time: 194.06 s 
2025-04-17 18:52:27.884861:  
2025-04-17 18:52:27.885526: Epoch 728 
2025-04-17 18:52:27.885930: Current learning rate: 0.0031 
2025-04-17 18:55:42.336483: train_loss -0.9057 
2025-04-17 18:55:42.339849: val_loss -0.8881 
2025-04-17 18:55:42.340188: Pseudo dice [np.float32(0.9223), np.float32(0.9535)] 
2025-04-17 18:55:42.340501: Epoch time: 194.45 s 
2025-04-17 18:55:44.185117:  
2025-04-17 18:55:44.185702: Epoch 729 
2025-04-17 18:55:44.186068: Current learning rate: 0.00309 
2025-04-17 18:58:58.331927: train_loss -0.9093 
2025-04-17 18:58:58.332672: val_loss -0.8733 
2025-04-17 18:58:58.332989: Pseudo dice [np.float32(0.9175), np.float32(0.941)] 
2025-04-17 18:58:58.333288: Epoch time: 194.15 s 
2025-04-17 18:58:59.429955:  
2025-04-17 18:58:59.430464: Epoch 730 
2025-04-17 18:58:59.430778: Current learning rate: 0.00308 
2025-04-17 19:02:13.263496: train_loss -0.9071 
2025-04-17 19:02:13.267008: val_loss -0.8732 
2025-04-17 19:02:13.267326: Pseudo dice [np.float32(0.9148), np.float32(0.9409)] 
2025-04-17 19:02:13.267613: Epoch time: 193.84 s 
2025-04-17 19:02:14.380045:  
2025-04-17 19:02:14.380728: Epoch 731 
2025-04-17 19:02:14.381135: Current learning rate: 0.00307 
2025-04-17 19:05:28.080875: train_loss -0.9103 
2025-04-17 19:05:28.081686: val_loss -0.8883 
2025-04-17 19:05:28.081972: Pseudo dice [np.float32(0.9147), np.float32(0.9543)] 
2025-04-17 19:05:28.082250: Epoch time: 193.7 s 
2025-04-17 19:05:28.082501: Yayy! New best EMA pseudo Dice: 0.9280999898910522 
2025-04-17 19:05:29.704736:  
2025-04-17 19:05:29.705296: Epoch 732 
2025-04-17 19:05:29.705621: Current learning rate: 0.00306 
2025-04-17 19:08:43.473454: train_loss -0.9089 
2025-04-17 19:08:43.477317: val_loss -0.8853 
2025-04-17 19:08:43.477705: Pseudo dice [np.float32(0.9277), np.float32(0.9528)] 
2025-04-17 19:08:43.478106: Epoch time: 193.77 s 
2025-04-17 19:08:43.478496: Yayy! New best EMA pseudo Dice: 0.9293000102043152 
2025-04-17 19:08:45.095002:  
2025-04-17 19:08:45.095544: Epoch 733 
2025-04-17 19:08:45.095917: Current learning rate: 0.00305 
2025-04-17 19:11:58.913445: train_loss -0.9094 
2025-04-17 19:11:58.914273: val_loss -0.8653 
2025-04-17 19:11:58.914547: Pseudo dice [np.float32(0.9025), np.float32(0.9478)] 
2025-04-17 19:11:58.914839: Epoch time: 193.82 s 
2025-04-17 19:12:00.043301:  
2025-04-17 19:12:00.043920: Epoch 734 
2025-04-17 19:12:00.044290: Current learning rate: 0.00304 
2025-04-17 19:15:13.831149: train_loss -0.9075 
2025-04-17 19:15:13.834481: val_loss -0.8897 
2025-04-17 19:15:13.834786: Pseudo dice [np.float32(0.9153), np.float32(0.9541)] 
2025-04-17 19:15:13.835064: Epoch time: 193.79 s 
2025-04-17 19:15:13.835315: Yayy! New best EMA pseudo Dice: 0.9294999837875366 
2025-04-17 19:15:15.321815:  
2025-04-17 19:15:15.322332: Epoch 735 
2025-04-17 19:15:15.322662: Current learning rate: 0.00303 
2025-04-17 19:18:29.310404: train_loss -0.9057 
2025-04-17 19:18:29.311705: val_loss -0.8608 
2025-04-17 19:18:29.312008: Pseudo dice [np.float32(0.9152), np.float32(0.9451)] 
2025-04-17 19:18:29.312300: Epoch time: 193.99 s 
2025-04-17 19:18:29.312564: Yayy! New best EMA pseudo Dice: 0.9294999837875366 
2025-04-17 19:18:30.826182:  
2025-04-17 19:18:30.826823: Epoch 736 
2025-04-17 19:18:30.827160: Current learning rate: 0.00302 
2025-04-17 19:21:45.193031: train_loss -0.9019 
2025-04-17 19:21:45.196714: val_loss -0.8872 
2025-04-17 19:21:45.197061: Pseudo dice [np.float32(0.9246), np.float32(0.9532)] 
2025-04-17 19:21:45.197367: Epoch time: 194.37 s 
2025-04-17 19:21:45.197646: Yayy! New best EMA pseudo Dice: 0.9304999709129333 
2025-04-17 19:21:46.759107:  
2025-04-17 19:21:46.759656: Epoch 737 
2025-04-17 19:21:46.760011: Current learning rate: 0.00301 
2025-04-17 19:25:01.482203: train_loss -0.9006 
2025-04-17 19:25:01.483075: val_loss -0.8801 
2025-04-17 19:25:01.483393: Pseudo dice [np.float32(0.9105), np.float32(0.9542)] 
2025-04-17 19:25:01.483704: Epoch time: 194.73 s 
2025-04-17 19:25:01.484003: Yayy! New best EMA pseudo Dice: 0.9305999875068665 
2025-04-17 19:25:03.004168:  
2025-04-17 19:25:03.004755: Epoch 738 
2025-04-17 19:25:03.005096: Current learning rate: 0.003 
2025-04-17 19:28:17.550445: train_loss -0.9083 
2025-04-17 19:28:17.554699: val_loss -0.8636 
2025-04-17 19:28:17.555044: Pseudo dice [np.float32(0.9068), np.float32(0.9359)] 
2025-04-17 19:28:17.555350: Epoch time: 194.55 s 
2025-04-17 19:28:18.668652:  
2025-04-17 19:28:18.669357: Epoch 739 
2025-04-17 19:28:18.669738: Current learning rate: 0.00299 
2025-04-17 19:31:33.162666: train_loss -0.9057 
2025-04-17 19:31:33.163563: val_loss -0.8775 
2025-04-17 19:31:33.163851: Pseudo dice [np.float32(0.9086), np.float32(0.9382)] 
2025-04-17 19:31:33.164149: Epoch time: 194.5 s 
2025-04-17 19:31:34.307111:  
2025-04-17 19:31:34.307717: Epoch 740 
2025-04-17 19:31:34.308079: Current learning rate: 0.00297 
2025-04-17 19:34:48.602735: train_loss -0.9073 
2025-04-17 19:34:48.606368: val_loss -0.8801 
2025-04-17 19:34:48.606706: Pseudo dice [np.float32(0.9149), np.float32(0.9442)] 
2025-04-17 19:34:48.607025: Epoch time: 194.3 s 
2025-04-17 19:34:49.705335:  
2025-04-17 19:34:49.705828: Epoch 741 
2025-04-17 19:34:49.706157: Current learning rate: 0.00296 
2025-04-17 19:38:03.644635: train_loss -0.9124 
2025-04-17 19:38:03.645582: val_loss -0.8752 
2025-04-17 19:38:03.645894: Pseudo dice [np.float32(0.9108), np.float32(0.9398)] 
2025-04-17 19:38:03.646200: Epoch time: 193.94 s 
2025-04-17 19:38:04.789318:  
2025-04-17 19:38:04.789835: Epoch 742 
2025-04-17 19:38:04.790151: Current learning rate: 0.00295 
2025-04-17 19:41:18.651170: train_loss -0.9074 
2025-04-17 19:41:18.654913: val_loss -0.8619 
2025-04-17 19:41:18.655287: Pseudo dice [np.float32(0.9077), np.float32(0.9268)] 
2025-04-17 19:41:18.655605: Epoch time: 193.86 s 
2025-04-17 19:41:19.779702:  
2025-04-17 19:41:19.780307: Epoch 743 
2025-04-17 19:41:19.780657: Current learning rate: 0.00294 
2025-04-17 19:44:33.676262: train_loss -0.9111 
2025-04-17 19:44:33.677097: val_loss -0.8472 
2025-04-17 19:44:33.677387: Pseudo dice [np.float32(0.889), np.float32(0.9379)] 
2025-04-17 19:44:33.677669: Epoch time: 193.9 s 
2025-04-17 19:44:34.802119:  
2025-04-17 19:44:34.802712: Epoch 744 
2025-04-17 19:44:34.803086: Current learning rate: 0.00293 
2025-04-17 19:47:48.822785: train_loss -0.911 
2025-04-17 19:47:48.826399: val_loss -0.8549 
2025-04-17 19:47:48.826697: Pseudo dice [np.float32(0.9016), np.float32(0.9318)] 
2025-04-17 19:47:48.826991: Epoch time: 194.02 s 
2025-04-17 19:47:49.917254:  
2025-04-17 19:47:49.917734: Epoch 745 
2025-04-17 19:47:49.918064: Current learning rate: 0.00292 
2025-04-17 19:51:04.774314: train_loss -0.909 
2025-04-17 19:51:04.775150: val_loss -0.8727 
2025-04-17 19:51:04.775450: Pseudo dice [np.float32(0.9227), np.float32(0.9489)] 
2025-04-17 19:51:04.775752: Epoch time: 194.86 s 
2025-04-17 19:51:05.874418:  
2025-04-17 19:51:05.874911: Epoch 746 
2025-04-17 19:51:05.875245: Current learning rate: 0.00291 
2025-04-17 19:54:20.883209: train_loss -0.9066 
2025-04-17 19:54:20.886852: val_loss -0.874 
2025-04-17 19:54:20.887170: Pseudo dice [np.float32(0.9078), np.float32(0.9518)] 
2025-04-17 19:54:20.887452: Epoch time: 195.01 s 
2025-04-17 19:54:22.859030:  
2025-04-17 19:54:22.859573: Epoch 747 
2025-04-17 19:54:22.859901: Current learning rate: 0.0029 
2025-04-17 19:57:38.003781: train_loss -0.9099 
2025-04-17 19:57:38.004648: val_loss -0.8371 
2025-04-17 19:57:38.004969: Pseudo dice [np.float32(0.9062), np.float32(0.9343)] 
2025-04-17 19:57:38.005272: Epoch time: 195.15 s 
2025-04-17 19:57:39.110332:  
2025-04-17 19:57:39.110800: Epoch 748 
2025-04-17 19:57:39.111126: Current learning rate: 0.00289 
2025-04-17 20:00:54.137930: train_loss -0.909 
2025-04-17 20:00:54.141425: val_loss -0.8921 
2025-04-17 20:00:54.141732: Pseudo dice [np.float32(0.9243), np.float32(0.9468)] 
2025-04-17 20:00:54.142031: Epoch time: 195.03 s 
2025-04-17 20:00:55.240843:  
2025-04-17 20:00:55.241369: Epoch 749 
2025-04-17 20:00:55.241687: Current learning rate: 0.00288 
2025-04-17 20:04:09.676911: train_loss -0.9089 
2025-04-17 20:04:09.677692: val_loss -0.8686 
2025-04-17 20:04:09.678004: Pseudo dice [np.float32(0.898), np.float32(0.9359)] 
2025-04-17 20:04:09.678315: Epoch time: 194.44 s 
2025-04-17 20:04:11.284022:  
2025-04-17 20:04:11.284608: Epoch 750 
2025-04-17 20:04:11.284961: Current learning rate: 0.00287 
2025-04-17 20:07:25.941081: train_loss -0.9101 
2025-04-17 20:07:25.944611: val_loss -0.8634 
2025-04-17 20:07:25.944946: Pseudo dice [np.float32(0.9081), np.float32(0.9388)] 
2025-04-17 20:07:25.945246: Epoch time: 194.66 s 
2025-04-17 20:07:27.076946:  
2025-04-17 20:07:27.077447: Epoch 751 
2025-04-17 20:07:27.077785: Current learning rate: 0.00286 
2025-04-17 20:10:41.658991: train_loss -0.9118 
2025-04-17 20:10:41.659821: val_loss -0.8767 
2025-04-17 20:10:41.660112: Pseudo dice [np.float32(0.9184), np.float32(0.9479)] 
2025-04-17 20:10:41.660411: Epoch time: 194.58 s 
2025-04-17 20:10:42.782045:  
2025-04-17 20:10:42.782599: Epoch 752 
2025-04-17 20:10:42.782945: Current learning rate: 0.00285 
2025-04-17 20:13:57.262372: train_loss -0.9135 
2025-04-17 20:13:57.265900: val_loss -0.8673 
2025-04-17 20:13:57.266265: Pseudo dice [np.float32(0.9163), np.float32(0.9469)] 
2025-04-17 20:13:57.266606: Epoch time: 194.48 s 
2025-04-17 20:13:58.400908:  
2025-04-17 20:13:58.401435: Epoch 753 
2025-04-17 20:13:58.401754: Current learning rate: 0.00284 
2025-04-17 20:17:12.421296: train_loss -0.9133 
2025-04-17 20:17:12.422085: val_loss -0.8672 
2025-04-17 20:17:12.422356: Pseudo dice [np.float32(0.901), np.float32(0.9473)] 
2025-04-17 20:17:12.422630: Epoch time: 194.02 s 
2025-04-17 20:17:13.533456:  
2025-04-17 20:17:13.533941: Epoch 754 
2025-04-17 20:17:13.534254: Current learning rate: 0.00283 
2025-04-17 20:20:27.462600: train_loss -0.9017 
2025-04-17 20:20:27.466145: val_loss -0.8816 
2025-04-17 20:20:27.466503: Pseudo dice [np.float32(0.9066), np.float32(0.9586)] 
2025-04-17 20:20:27.466844: Epoch time: 193.93 s 
2025-04-17 20:20:28.602604:  
2025-04-17 20:20:28.603198: Epoch 755 
2025-04-17 20:20:28.603552: Current learning rate: 0.00282 
2025-04-17 20:23:42.603587: train_loss -0.9039 
2025-04-17 20:23:42.609315: val_loss -0.8703 
2025-04-17 20:23:42.609676: Pseudo dice [np.float32(0.9104), np.float32(0.9451)] 
2025-04-17 20:23:42.610003: Epoch time: 194.0 s 
2025-04-17 20:23:43.752678:  
2025-04-17 20:23:43.753176: Epoch 756 
2025-04-17 20:23:43.753490: Current learning rate: 0.00281 
2025-04-17 20:26:57.691813: train_loss -0.9117 
2025-04-17 20:26:57.695254: val_loss -0.8751 
2025-04-17 20:26:57.695553: Pseudo dice [np.float32(0.9145), np.float32(0.9524)] 
2025-04-17 20:26:57.695849: Epoch time: 193.94 s 
2025-04-17 20:26:58.803841:  
2025-04-17 20:26:58.804383: Epoch 757 
2025-04-17 20:26:58.804708: Current learning rate: 0.0028 
2025-04-17 20:30:13.324017: train_loss -0.9056 
2025-04-17 20:30:13.324854: val_loss -0.8735 
2025-04-17 20:30:13.325140: Pseudo dice [np.float32(0.9147), np.float32(0.9404)] 
2025-04-17 20:30:13.325968: Epoch time: 194.52 s 
2025-04-17 20:30:14.427969:  
2025-04-17 20:30:14.428522: Epoch 758 
2025-04-17 20:30:14.428889: Current learning rate: 0.00279 
2025-04-17 20:33:35.882777: train_loss -0.9069 
2025-04-17 20:33:35.886171: val_loss -0.8826 
2025-04-17 20:33:35.886555: Pseudo dice [np.float32(0.9093), np.float32(0.9442)] 
2025-04-17 20:33:35.886894: Epoch time: 201.46 s 
2025-04-17 20:33:37.031627:  
2025-04-17 20:33:37.032228: Epoch 759 
2025-04-17 20:33:37.032568: Current learning rate: 0.00278 
2025-04-17 20:36:58.591791: train_loss -0.9047 
2025-04-17 20:36:58.592568: val_loss -0.8699 
2025-04-17 20:36:58.592860: Pseudo dice [np.float32(0.8969), np.float32(0.9405)] 
2025-04-17 20:36:58.593158: Epoch time: 201.56 s 
2025-04-17 20:36:59.708218:  
2025-04-17 20:36:59.708771: Epoch 760 
2025-04-17 20:36:59.709101: Current learning rate: 0.00277 
2025-04-17 20:40:13.240896: train_loss -0.9079 
2025-04-17 20:40:13.244321: val_loss -0.8576 
2025-04-17 20:40:13.244682: Pseudo dice [np.float32(0.9027), np.float32(0.9476)] 
2025-04-17 20:40:13.245025: Epoch time: 193.53 s 
2025-04-17 20:40:14.390964:  
2025-04-17 20:40:14.391593: Epoch 761 
2025-04-17 20:40:14.391948: Current learning rate: 0.00276 
2025-04-17 20:43:28.088345: train_loss -0.9112 
2025-04-17 20:43:28.089290: val_loss -0.8632 
2025-04-17 20:43:28.089604: Pseudo dice [np.float32(0.9057), np.float32(0.9411)] 
2025-04-17 20:43:28.089906: Epoch time: 193.7 s 
2025-04-17 20:43:29.198916:  
2025-04-17 20:43:29.199443: Epoch 762 
2025-04-17 20:43:29.199788: Current learning rate: 0.00275 
2025-04-17 20:46:43.487560: train_loss -0.9083 
2025-04-17 20:46:43.490932: val_loss -0.8709 
2025-04-17 20:46:43.491240: Pseudo dice [np.float32(0.9074), np.float32(0.9496)] 
2025-04-17 20:46:43.491527: Epoch time: 194.29 s 
2025-04-17 20:46:44.607219:  
2025-04-17 20:46:44.607847: Epoch 763 
2025-04-17 20:46:44.608195: Current learning rate: 0.00274 
2025-04-17 20:49:59.000454: train_loss -0.9118 
2025-04-17 20:49:59.001345: val_loss -0.8764 
2025-04-17 20:49:59.001639: Pseudo dice [np.float32(0.9064), np.float32(0.9479)] 
2025-04-17 20:49:59.001949: Epoch time: 194.4 s 
2025-04-17 20:50:00.120595:  
2025-04-17 20:50:00.121132: Epoch 764 
2025-04-17 20:50:00.121470: Current learning rate: 0.00273 
2025-04-17 20:53:14.252860: train_loss -0.9118 
2025-04-17 20:53:14.256460: val_loss -0.8774 
2025-04-17 20:53:14.256837: Pseudo dice [np.float32(0.9105), np.float32(0.9463)] 
2025-04-17 20:53:14.257173: Epoch time: 194.13 s 
2025-04-17 20:53:16.300728:  
2025-04-17 20:53:16.301387: Epoch 765 
2025-04-17 20:53:16.301780: Current learning rate: 0.00272 
2025-04-17 20:56:30.026788: train_loss -0.9006 
2025-04-17 20:56:30.027672: val_loss -0.8762 
2025-04-17 20:56:30.027978: Pseudo dice [np.float32(0.9056), np.float32(0.9412)] 
2025-04-17 20:56:30.028278: Epoch time: 193.73 s 
2025-04-17 20:56:31.155011:  
2025-04-17 20:56:31.155536: Epoch 766 
2025-04-17 20:56:31.155881: Current learning rate: 0.00271 
2025-04-17 20:59:44.813559: train_loss -0.908 
2025-04-17 20:59:44.817298: val_loss -0.8537 
2025-04-17 20:59:44.817620: Pseudo dice [np.float32(0.911), np.float32(0.9444)] 
2025-04-17 20:59:44.817945: Epoch time: 193.66 s 
2025-04-17 20:59:45.932724:  
2025-04-17 20:59:45.933334: Epoch 767 
2025-04-17 20:59:45.933671: Current learning rate: 0.0027 
2025-04-17 21:02:59.683022: train_loss -0.9121 
2025-04-17 21:02:59.683884: val_loss -0.868 
2025-04-17 21:02:59.684200: Pseudo dice [np.float32(0.8983), np.float32(0.941)] 
2025-04-17 21:02:59.684541: Epoch time: 193.75 s 
2025-04-17 21:03:00.818350:  
2025-04-17 21:03:00.818978: Epoch 768 
2025-04-17 21:03:00.819325: Current learning rate: 0.00268 
2025-04-17 21:06:15.077073: train_loss -0.904 
2025-04-17 21:06:15.080789: val_loss -0.8609 
2025-04-17 21:06:15.081105: Pseudo dice [np.float32(0.9019), np.float32(0.9471)] 
2025-04-17 21:06:15.081398: Epoch time: 194.26 s 
2025-04-17 21:06:16.198951:  
2025-04-17 21:06:16.199503: Epoch 769 
2025-04-17 21:06:16.199860: Current learning rate: 0.00267 
2025-04-17 21:09:30.227989: train_loss -0.9121 
2025-04-17 21:09:30.229590: val_loss -0.8668 
2025-04-17 21:09:30.230084: Pseudo dice [np.float32(0.9078), np.float32(0.9494)] 
2025-04-17 21:09:30.230543: Epoch time: 194.03 s 
2025-04-17 21:09:31.402354:  
2025-04-17 21:09:31.402833: Epoch 770 
2025-04-17 21:09:31.403157: Current learning rate: 0.00266 
2025-04-17 21:12:45.440296: train_loss -0.9124 
2025-04-17 21:12:45.443944: val_loss -0.8644 
2025-04-17 21:12:45.444280: Pseudo dice [np.float32(0.9041), np.float32(0.9379)] 
2025-04-17 21:12:45.444576: Epoch time: 194.04 s 
2025-04-17 21:12:46.578815:  
2025-04-17 21:12:46.579346: Epoch 771 
2025-04-17 21:12:46.579675: Current learning rate: 0.00265 
2025-04-17 21:16:00.702215: train_loss -0.9105 
2025-04-17 21:16:00.703093: val_loss -0.8555 
2025-04-17 21:16:00.703408: Pseudo dice [np.float32(0.8922), np.float32(0.9401)] 
2025-04-17 21:16:00.703713: Epoch time: 194.13 s 
2025-04-17 21:16:01.840330:  
2025-04-17 21:16:01.840858: Epoch 772 
2025-04-17 21:16:01.841180: Current learning rate: 0.00264 
2025-04-17 21:19:16.078781: train_loss -0.9104 
2025-04-17 21:19:16.082329: val_loss -0.8723 
2025-04-17 21:19:16.082631: Pseudo dice [np.float32(0.9086), np.float32(0.9497)] 
2025-04-17 21:19:16.082928: Epoch time: 194.24 s 
2025-04-17 21:19:17.226250:  
2025-04-17 21:19:17.226773: Epoch 773 
2025-04-17 21:19:17.227114: Current learning rate: 0.00263 
2025-04-17 21:22:31.579248: train_loss -0.9128 
2025-04-17 21:22:31.580277: val_loss -0.8725 
2025-04-17 21:22:31.580580: Pseudo dice [np.float32(0.9006), np.float32(0.935)] 
2025-04-17 21:22:31.580883: Epoch time: 194.36 s 
2025-04-17 21:22:32.715534:  
2025-04-17 21:22:32.716197: Epoch 774 
2025-04-17 21:22:32.716558: Current learning rate: 0.00262 
2025-04-17 21:25:47.257384: train_loss -0.9051 
2025-04-17 21:25:47.260951: val_loss -0.8538 
2025-04-17 21:25:47.261274: Pseudo dice [np.float32(0.8941), np.float32(0.9461)] 
2025-04-17 21:25:47.261596: Epoch time: 194.54 s 
2025-04-17 21:25:48.427034:  
2025-04-17 21:25:48.427607: Epoch 775 
2025-04-17 21:25:48.427970: Current learning rate: 0.00261 
2025-04-17 21:29:02.849661: train_loss -0.8939 
2025-04-17 21:29:02.850511: val_loss -0.8672 
2025-04-17 21:29:02.850852: Pseudo dice [np.float32(0.9149), np.float32(0.9522)] 
2025-04-17 21:29:02.851177: Epoch time: 194.42 s 
2025-04-17 21:29:03.993758:  
2025-04-17 21:29:03.994334: Epoch 776 
2025-04-17 21:29:03.994690: Current learning rate: 0.0026 
2025-04-17 21:32:17.822312: train_loss -0.9046 
2025-04-17 21:32:17.827177: val_loss -0.8448 
2025-04-17 21:32:17.827522: Pseudo dice [np.float32(0.8969), np.float32(0.9352)] 
2025-04-17 21:32:17.827869: Epoch time: 193.83 s 
2025-04-17 21:32:18.942035:  
2025-04-17 21:32:18.942653: Epoch 777 
2025-04-17 21:32:18.943014: Current learning rate: 0.00259 
2025-04-17 21:35:32.540663: train_loss -0.9008 
2025-04-17 21:35:32.541485: val_loss -0.8748 
2025-04-17 21:35:32.541760: Pseudo dice [np.float32(0.9046), np.float32(0.9472)] 
2025-04-17 21:35:32.542059: Epoch time: 193.6 s 
2025-04-17 21:35:33.671015:  
2025-04-17 21:35:33.671547: Epoch 778 
2025-04-17 21:35:33.671877: Current learning rate: 0.00258 
2025-04-17 21:38:47.294820: train_loss -0.9036 
2025-04-17 21:38:47.298679: val_loss -0.8623 
2025-04-17 21:38:47.299054: Pseudo dice [np.float32(0.8871), np.float32(0.9298)] 
2025-04-17 21:38:47.299375: Epoch time: 193.63 s 
2025-04-17 21:38:48.411675:  
2025-04-17 21:38:48.412246: Epoch 779 
2025-04-17 21:38:48.412569: Current learning rate: 0.00257 
2025-04-17 21:42:01.841933: train_loss -0.9091 
2025-04-17 21:42:01.842887: val_loss -0.8676 
2025-04-17 21:42:01.843184: Pseudo dice [np.float32(0.9026), np.float32(0.9434)] 
2025-04-17 21:42:01.843487: Epoch time: 193.43 s 
2025-04-17 21:42:03.020238:  
2025-04-17 21:42:03.020722: Epoch 780 
2025-04-17 21:42:03.021043: Current learning rate: 0.00256 
2025-04-17 21:45:16.625826: train_loss -0.9057 
2025-04-17 21:45:16.629295: val_loss -0.8686 
2025-04-17 21:45:16.629608: Pseudo dice [np.float32(0.9162), np.float32(0.9541)] 
2025-04-17 21:45:16.629907: Epoch time: 193.61 s 
2025-04-17 21:45:17.761667:  
2025-04-17 21:45:17.762151: Epoch 781 
2025-04-17 21:45:17.762468: Current learning rate: 0.00255 
2025-04-17 21:48:31.369492: train_loss -0.9132 
2025-04-17 21:48:31.370295: val_loss -0.866 
2025-04-17 21:48:31.370572: Pseudo dice [np.float32(0.9108), np.float32(0.9439)] 
2025-04-17 21:48:31.370878: Epoch time: 193.61 s 
2025-04-17 21:48:32.518694:  
2025-04-17 21:48:32.519264: Epoch 782 
2025-04-17 21:48:32.519605: Current learning rate: 0.00254 
2025-04-17 21:51:46.307297: train_loss -0.9041 
2025-04-17 21:51:46.311313: val_loss -0.8685 
2025-04-17 21:51:46.311661: Pseudo dice [np.float32(0.9103), np.float32(0.9459)] 
2025-04-17 21:51:46.312010: Epoch time: 193.79 s 
2025-04-17 21:51:47.455961:  
2025-04-17 21:51:47.456494: Epoch 783 
2025-04-17 21:51:47.456833: Current learning rate: 0.00253 
2025-04-17 21:55:01.860235: train_loss -0.9135 
2025-04-17 21:55:01.861136: val_loss -0.8673 
2025-04-17 21:55:01.861446: Pseudo dice [np.float32(0.916), np.float32(0.943)] 
2025-04-17 21:55:01.861765: Epoch time: 194.41 s 
2025-04-17 21:55:02.940322:  
2025-04-17 21:55:02.940824: Epoch 784 
2025-04-17 21:55:02.941175: Current learning rate: 0.00252 
2025-04-17 21:58:16.963304: train_loss -0.9089 
2025-04-17 21:58:16.966985: val_loss -0.852 
2025-04-17 21:58:16.967312: Pseudo dice [np.float32(0.9006), np.float32(0.9433)] 
2025-04-17 21:58:16.967623: Epoch time: 194.03 s 
2025-04-17 21:58:18.076689:  
2025-04-17 21:58:18.077215: Epoch 785 
2025-04-17 21:58:18.077541: Current learning rate: 0.00251 
2025-04-17 22:01:31.956366: train_loss -0.9086 
2025-04-17 22:01:31.957176: val_loss -0.8748 
2025-04-17 22:01:31.957470: Pseudo dice [np.float32(0.9057), np.float32(0.939)] 
2025-04-17 22:01:31.957787: Epoch time: 193.88 s 
2025-04-17 22:01:33.092621:  
2025-04-17 22:01:33.093215: Epoch 786 
2025-04-17 22:01:33.093578: Current learning rate: 0.0025 
2025-04-17 22:04:47.141415: train_loss -0.9033 
2025-04-17 22:04:47.145040: val_loss -0.8801 
2025-04-17 22:04:47.145413: Pseudo dice [np.float32(0.9142), np.float32(0.9477)] 
2025-04-17 22:04:47.145736: Epoch time: 194.05 s 
2025-04-17 22:04:48.344436:  
2025-04-17 22:04:48.345025: Epoch 787 
2025-04-17 22:04:48.345389: Current learning rate: 0.00249 
2025-04-17 22:08:02.260200: train_loss -0.9041 
2025-04-17 22:08:02.260971: val_loss -0.8707 
2025-04-17 22:08:02.261260: Pseudo dice [np.float32(0.9075), np.float32(0.9423)] 
2025-04-17 22:08:02.261541: Epoch time: 193.92 s 
2025-04-17 22:08:03.393982:  
2025-04-17 22:08:03.394448: Epoch 788 
2025-04-17 22:08:03.394768: Current learning rate: 0.00248 
2025-04-17 22:11:17.300965: train_loss -0.9166 
2025-04-17 22:11:17.304765: val_loss -0.8549 
2025-04-17 22:11:17.305120: Pseudo dice [np.float32(0.9029), np.float32(0.9476)] 
2025-04-17 22:11:17.305434: Epoch time: 193.91 s 
2025-04-17 22:11:18.482493:  
2025-04-17 22:11:18.483008: Epoch 789 
2025-04-17 22:11:18.483353: Current learning rate: 0.00247 
2025-04-17 22:14:32.222630: train_loss -0.9137 
2025-04-17 22:14:32.223493: val_loss -0.8773 
2025-04-17 22:14:32.223798: Pseudo dice [np.float32(0.9105), np.float32(0.9553)] 
2025-04-17 22:14:32.224085: Epoch time: 193.74 s 
2025-04-17 22:14:33.349377:  
2025-04-17 22:14:33.349994: Epoch 790 
2025-04-17 22:14:33.350333: Current learning rate: 0.00245 
2025-04-17 22:17:47.196367: train_loss -0.9112 
2025-04-17 22:17:47.200245: val_loss -0.8306 
2025-04-17 22:17:47.200604: Pseudo dice [np.float32(0.8976), np.float32(0.9313)] 
2025-04-17 22:17:47.200912: Epoch time: 193.85 s 
2025-04-17 22:17:48.332778:  
2025-04-17 22:17:48.333250: Epoch 791 
2025-04-17 22:17:48.333570: Current learning rate: 0.00244 
2025-04-17 22:21:02.333468: train_loss -0.9025 
2025-04-17 22:21:02.334307: val_loss -0.8367 
2025-04-17 22:21:02.334584: Pseudo dice [np.float32(0.8982), np.float32(0.9196)] 
2025-04-17 22:21:02.334891: Epoch time: 194.0 s 
2025-04-17 22:21:03.477125:  
2025-04-17 22:21:03.477753: Epoch 792 
2025-04-17 22:21:03.478099: Current learning rate: 0.00243 
2025-04-17 22:24:18.513421: train_loss -0.9132 
2025-04-17 22:24:18.516734: val_loss -0.8732 
2025-04-17 22:24:18.517577: Pseudo dice [np.float32(0.8969), np.float32(0.94)] 
2025-04-17 22:24:18.517888: Epoch time: 195.04 s 
2025-04-17 22:24:19.646451:  
2025-04-17 22:24:19.646990: Epoch 793 
2025-04-17 22:24:19.647317: Current learning rate: 0.00242 
2025-04-17 22:27:34.896071: train_loss -0.9102 
2025-04-17 22:27:34.896978: val_loss -0.8541 
2025-04-17 22:27:34.897286: Pseudo dice [np.float32(0.9011), np.float32(0.9383)] 
2025-04-17 22:27:34.897638: Epoch time: 195.25 s 
2025-04-17 22:27:36.045259:  
2025-04-17 22:27:36.045821: Epoch 794 
2025-04-17 22:27:36.046152: Current learning rate: 0.00241 
2025-04-17 22:30:53.322122: train_loss -0.9089 
2025-04-17 22:30:53.325708: val_loss -0.8823 
2025-04-17 22:30:53.326022: Pseudo dice [np.float32(0.9123), np.float32(0.9447)] 
2025-04-17 22:30:53.326311: Epoch time: 197.28 s 
2025-04-17 22:30:54.426043:  
2025-04-17 22:30:54.426566: Epoch 795 
2025-04-17 22:30:54.426892: Current learning rate: 0.0024 
2025-04-17 22:34:16.696270: train_loss -0.9128 
2025-04-17 22:34:16.697154: val_loss -0.866 
2025-04-17 22:34:16.697469: Pseudo dice [np.float32(0.9103), np.float32(0.939)] 
2025-04-17 22:34:16.697797: Epoch time: 202.27 s 
2025-04-17 22:34:17.895145:  
2025-04-17 22:34:17.895661: Epoch 796 
2025-04-17 22:34:17.896001: Current learning rate: 0.00239 
2025-04-17 22:37:37.260458: train_loss -0.9109 
2025-04-17 22:37:37.264026: val_loss -0.8856 
2025-04-17 22:37:37.264366: Pseudo dice [np.float32(0.923), np.float32(0.9483)] 
2025-04-17 22:37:37.264670: Epoch time: 199.37 s 
2025-04-17 22:37:38.419050:  
2025-04-17 22:37:38.419639: Epoch 797 
2025-04-17 22:37:38.419986: Current learning rate: 0.00238 
2025-04-17 22:40:53.187813: train_loss -0.9134 
2025-04-17 22:40:53.188599: val_loss -0.8728 
2025-04-17 22:40:53.188889: Pseudo dice [np.float32(0.9056), np.float32(0.9355)] 
2025-04-17 22:40:53.189183: Epoch time: 194.77 s 
2025-04-17 22:40:54.336771:  
2025-04-17 22:40:54.337317: Epoch 798 
2025-04-17 22:40:54.337640: Current learning rate: 0.00237 
2025-04-17 22:44:08.827942: train_loss -0.9155 
2025-04-17 22:44:08.832531: val_loss -0.8697 
2025-04-17 22:44:08.832832: Pseudo dice [np.float32(0.903), np.float32(0.9386)] 
2025-04-17 22:44:08.833126: Epoch time: 194.49 s 
2025-04-17 22:44:09.977684:  
2025-04-17 22:44:09.978171: Epoch 799 
2025-04-17 22:44:09.978512: Current learning rate: 0.00236 
2025-04-17 22:47:24.692506: train_loss -0.9146 
2025-04-17 22:47:24.693275: val_loss -0.8785 
2025-04-17 22:47:24.693561: Pseudo dice [np.float32(0.908), np.float32(0.9391)] 
2025-04-17 22:47:24.693852: Epoch time: 194.72 s 
2025-04-17 22:47:26.201037:  
2025-04-17 22:47:26.201543: Epoch 800 
2025-04-17 22:47:26.201863: Current learning rate: 0.00235 
2025-04-17 22:50:41.495175: train_loss -0.914 
2025-04-17 22:50:41.498608: val_loss -0.8847 
2025-04-17 22:50:41.498916: Pseudo dice [np.float32(0.919), np.float32(0.9512)] 
2025-04-17 22:50:41.499209: Epoch time: 195.3 s 
2025-04-17 22:50:43.443422:  
2025-04-17 22:50:43.443914: Epoch 801 
2025-04-17 22:50:43.444254: Current learning rate: 0.00234 
2025-04-17 22:53:58.507381: train_loss -0.9154 
2025-04-17 22:53:58.508243: val_loss -0.8607 
2025-04-17 22:53:58.508561: Pseudo dice [np.float32(0.8953), np.float32(0.9295)] 
2025-04-17 22:53:58.508884: Epoch time: 195.07 s 
2025-04-17 22:53:59.661333:  
2025-04-17 22:53:59.661909: Epoch 802 
2025-04-17 22:53:59.662266: Current learning rate: 0.00233 
2025-04-17 22:57:14.968668: train_loss -0.9079 
2025-04-17 22:57:14.972061: val_loss -0.8629 
2025-04-17 22:57:14.972347: Pseudo dice [np.float32(0.8968), np.float32(0.9388)] 
2025-04-17 22:57:14.972628: Epoch time: 195.31 s 
2025-04-17 22:57:16.095215:  
2025-04-17 22:57:16.095733: Epoch 803 
2025-04-17 22:57:16.096057: Current learning rate: 0.00232 
2025-04-17 23:00:31.642555: train_loss -0.9126 
2025-04-17 23:00:31.643379: val_loss -0.867 
2025-04-17 23:00:31.643654: Pseudo dice [np.float32(0.8969), np.float32(0.9428)] 
2025-04-17 23:00:31.643946: Epoch time: 195.55 s 
2025-04-17 23:00:32.757527:  
2025-04-17 23:00:32.758230: Epoch 804 
2025-04-17 23:00:32.758541: Current learning rate: 0.00231 
2025-04-17 23:03:48.238147: train_loss -0.9095 
2025-04-17 23:03:48.241928: val_loss -0.8662 
2025-04-17 23:03:48.242266: Pseudo dice [np.float32(0.9014), np.float32(0.9423)] 
2025-04-17 23:03:48.242570: Epoch time: 195.48 s 
2025-04-17 23:03:49.401575:  
2025-04-17 23:03:49.402108: Epoch 805 
2025-04-17 23:03:49.402436: Current learning rate: 0.0023 
2025-04-17 23:07:04.796090: train_loss -0.909 
2025-04-17 23:07:04.796997: val_loss -0.8668 
2025-04-17 23:07:04.797333: Pseudo dice [np.float32(0.9057), np.float32(0.9363)] 
2025-04-17 23:07:04.797655: Epoch time: 195.4 s 
2025-04-17 23:07:05.909737:  
2025-04-17 23:07:05.910335: Epoch 806 
2025-04-17 23:07:05.910703: Current learning rate: 0.00229 
2025-04-17 23:10:20.586837: train_loss -0.9143 
2025-04-17 23:10:20.590277: val_loss -0.8766 
2025-04-17 23:10:20.590592: Pseudo dice [np.float32(0.9043), np.float32(0.9428)] 
2025-04-17 23:10:20.590900: Epoch time: 194.68 s 
2025-04-17 23:10:21.746297:  
2025-04-17 23:10:21.746888: Epoch 807 
2025-04-17 23:10:21.747224: Current learning rate: 0.00228 
2025-04-17 23:13:36.378482: train_loss -0.9103 
2025-04-17 23:13:36.379309: val_loss -0.865 
2025-04-17 23:13:36.379611: Pseudo dice [np.float32(0.9134), np.float32(0.9435)] 
2025-04-17 23:13:36.379921: Epoch time: 194.63 s 
2025-04-17 23:13:37.521788:  
2025-04-17 23:13:37.522339: Epoch 808 
2025-04-17 23:13:37.522683: Current learning rate: 0.00226 
2025-04-17 23:16:51.915337: train_loss -0.9124 
2025-04-17 23:16:51.918872: val_loss -0.8472 
2025-04-17 23:16:51.919351: Pseudo dice [np.float32(0.8727), np.float32(0.9351)] 
2025-04-17 23:16:51.919685: Epoch time: 194.4 s 
2025-04-17 23:16:53.057659:  
2025-04-17 23:16:53.058228: Epoch 809 
2025-04-17 23:16:53.058582: Current learning rate: 0.00225 
2025-04-17 23:20:06.845503: train_loss -0.9084 
2025-04-17 23:20:06.846363: val_loss -0.8546 
2025-04-17 23:20:06.846667: Pseudo dice [np.float32(0.9117), np.float32(0.9302)] 
2025-04-17 23:20:06.846997: Epoch time: 193.79 s 
2025-04-17 23:20:07.973232:  
2025-04-17 23:20:07.973701: Epoch 810 
2025-04-17 23:20:07.974021: Current learning rate: 0.00224 
2025-04-17 23:23:21.867479: train_loss -0.9126 
2025-04-17 23:23:21.871099: val_loss -0.8547 
2025-04-17 23:23:21.871422: Pseudo dice [np.float32(0.9031), np.float32(0.9339)] 
2025-04-17 23:23:21.871732: Epoch time: 193.9 s 
2025-04-17 23:23:23.017888:  
2025-04-17 23:23:23.018416: Epoch 811 
2025-04-17 23:23:23.018748: Current learning rate: 0.00223 
2025-04-17 23:26:36.854572: train_loss -0.9071 
2025-04-17 23:26:36.855430: val_loss -0.8612 
2025-04-17 23:26:36.855724: Pseudo dice [np.float32(0.9162), np.float32(0.949)] 
2025-04-17 23:26:36.856021: Epoch time: 193.84 s 
2025-04-17 23:26:37.989455:  
2025-04-17 23:26:37.990027: Epoch 812 
2025-04-17 23:26:37.990378: Current learning rate: 0.00222 
2025-04-17 23:29:51.637800: train_loss -0.9136 
2025-04-17 23:29:51.641485: val_loss -0.8689 
2025-04-17 23:29:51.641816: Pseudo dice [np.float32(0.9112), np.float32(0.9346)] 
2025-04-17 23:29:51.642125: Epoch time: 193.65 s 
2025-04-17 23:29:52.766439:  
2025-04-17 23:29:52.766960: Epoch 813 
2025-04-17 23:29:52.767307: Current learning rate: 0.00221 
2025-04-17 23:33:06.577546: train_loss -0.916 
2025-04-17 23:33:06.578382: val_loss -0.8698 
2025-04-17 23:33:06.578665: Pseudo dice [np.float32(0.9099), np.float32(0.9465)] 
2025-04-17 23:33:06.578947: Epoch time: 193.81 s 
2025-04-17 23:33:07.697920:  
2025-04-17 23:33:07.698427: Epoch 814 
2025-04-17 23:33:07.698731: Current learning rate: 0.0022 
2025-04-17 23:36:21.985487: train_loss -0.9203 
2025-04-17 23:36:21.988898: val_loss -0.8857 
2025-04-17 23:36:21.989231: Pseudo dice [np.float32(0.9164), np.float32(0.9515)] 
2025-04-17 23:36:21.989534: Epoch time: 194.29 s 
2025-04-17 23:36:23.182114:  
2025-04-17 23:36:23.182756: Epoch 815 
2025-04-17 23:36:23.183114: Current learning rate: 0.00219 
2025-04-17 23:39:37.336938: train_loss -0.9114 
2025-04-17 23:39:37.337801: val_loss -0.8769 
2025-04-17 23:39:37.338115: Pseudo dice [np.float32(0.9073), np.float32(0.9469)] 
2025-04-17 23:39:37.338958: Epoch time: 194.16 s 
2025-04-17 23:39:38.468763:  
2025-04-17 23:39:38.469311: Epoch 816 
2025-04-17 23:39:38.469632: Current learning rate: 0.00218 
2025-04-17 23:42:52.855985: train_loss -0.9126 
2025-04-17 23:42:52.859525: val_loss -0.8832 
2025-04-17 23:42:52.859858: Pseudo dice [np.float32(0.9136), np.float32(0.9508)] 
2025-04-17 23:42:52.860158: Epoch time: 194.39 s 
2025-04-17 23:42:54.024654:  
2025-04-17 23:42:54.025206: Epoch 817 
2025-04-17 23:42:54.025538: Current learning rate: 0.00217 
2025-04-17 23:46:08.455809: train_loss -0.9109 
2025-04-17 23:46:08.456656: val_loss -0.8575 
2025-04-17 23:46:08.456963: Pseudo dice [np.float32(0.9022), np.float32(0.9311)] 
2025-04-17 23:46:08.457256: Epoch time: 194.43 s 
2025-04-17 23:46:09.624719:  
2025-04-17 23:46:09.625290: Epoch 818 
2025-04-17 23:46:09.625622: Current learning rate: 0.00216 
2025-04-17 23:49:23.944277: train_loss -0.9124 
2025-04-17 23:49:23.947809: val_loss -0.8793 
2025-04-17 23:49:23.948141: Pseudo dice [np.float32(0.9212), np.float32(0.9474)] 
2025-04-17 23:49:23.948457: Epoch time: 194.32 s 
2025-04-17 23:49:25.941929:  
2025-04-17 23:49:25.942448: Epoch 819 
2025-04-17 23:49:25.942791: Current learning rate: 0.00215 
2025-04-17 23:52:40.126297: train_loss -0.915 
2025-04-17 23:52:40.127302: val_loss -0.8767 
2025-04-17 23:52:40.127647: Pseudo dice [np.float32(0.9214), np.float32(0.9433)] 
2025-04-17 23:52:40.127984: Epoch time: 194.19 s 
2025-04-17 23:52:41.236779:  
2025-04-17 23:52:41.237317: Epoch 820 
2025-04-17 23:52:41.237652: Current learning rate: 0.00214 
2025-04-17 23:55:55.738903: train_loss -0.9099 
2025-04-17 23:55:55.742436: val_loss -0.8645 
2025-04-17 23:55:55.742770: Pseudo dice [np.float32(0.9016), np.float32(0.9374)] 
2025-04-17 23:55:55.743094: Epoch time: 194.5 s 
2025-04-17 23:55:56.807453:  
2025-04-17 23:55:56.807996: Epoch 821 
2025-04-17 23:55:56.808332: Current learning rate: 0.00213 
2025-04-17 23:59:10.867196: train_loss -0.9154 
2025-04-17 23:59:10.868084: val_loss -0.8762 
2025-04-17 23:59:10.868390: Pseudo dice [np.float32(0.9144), np.float32(0.9472)] 
2025-04-17 23:59:10.868705: Epoch time: 194.06 s 
2025-04-17 23:59:11.956603:  
2025-04-17 23:59:11.957231: Epoch 822 
2025-04-17 23:59:11.957585: Current learning rate: 0.00212 
2025-04-18 00:02:26.260413: train_loss -0.9144 
2025-04-18 00:02:26.264137: val_loss -0.8652 
2025-04-18 00:02:26.264434: Pseudo dice [np.float32(0.905), np.float32(0.9433)] 
2025-04-18 00:02:26.264714: Epoch time: 194.31 s 
2025-04-18 00:02:27.331267:  
2025-04-18 00:02:27.331764: Epoch 823 
2025-04-18 00:02:27.332089: Current learning rate: 0.0021 
2025-04-18 00:05:41.651484: train_loss -0.915 
2025-04-18 00:05:41.652290: val_loss -0.8666 
2025-04-18 00:05:41.652584: Pseudo dice [np.float32(0.903), np.float32(0.9363)] 
2025-04-18 00:05:41.652930: Epoch time: 194.32 s 
2025-04-18 00:05:42.720637:  
2025-04-18 00:05:42.721191: Epoch 824 
2025-04-18 00:05:42.721531: Current learning rate: 0.00209 
2025-04-18 00:08:57.287929: train_loss -0.9155 
2025-04-18 00:08:57.292159: val_loss -0.8681 
2025-04-18 00:08:57.292454: Pseudo dice [np.float32(0.8991), np.float32(0.9469)] 
2025-04-18 00:08:57.292769: Epoch time: 194.57 s 
2025-04-18 00:08:58.348181:  
2025-04-18 00:08:58.348810: Epoch 825 
2025-04-18 00:08:58.349151: Current learning rate: 0.00208 
2025-04-18 00:12:13.777830: train_loss -0.9129 
2025-04-18 00:12:13.778589: val_loss -0.8555 
2025-04-18 00:12:13.778865: Pseudo dice [np.float32(0.894), np.float32(0.935)] 
2025-04-18 00:12:13.779155: Epoch time: 195.43 s 
2025-04-18 00:12:14.871404:  
2025-04-18 00:12:14.872049: Epoch 826 
2025-04-18 00:12:14.872405: Current learning rate: 0.00207 
2025-04-18 00:15:29.258267: train_loss -0.9132 
2025-04-18 00:15:29.261484: val_loss -0.8802 
2025-04-18 00:15:29.261774: Pseudo dice [np.float32(0.908), np.float32(0.9446)] 
2025-04-18 00:15:29.262052: Epoch time: 194.39 s 
2025-04-18 00:15:30.305704:  
2025-04-18 00:15:30.306229: Epoch 827 
2025-04-18 00:15:30.306559: Current learning rate: 0.00206 
2025-04-18 00:18:44.503982: train_loss -0.9137 
2025-04-18 00:18:44.504843: val_loss -0.8669 
2025-04-18 00:18:44.505173: Pseudo dice [np.float32(0.9021), np.float32(0.9383)] 
2025-04-18 00:18:44.505475: Epoch time: 194.2 s 
2025-04-18 00:18:45.592118:  
2025-04-18 00:18:45.592633: Epoch 828 
2025-04-18 00:18:45.592972: Current learning rate: 0.00205 
2025-04-18 00:21:59.571691: train_loss -0.9095 
2025-04-18 00:21:59.575261: val_loss -0.8923 
2025-04-18 00:21:59.575593: Pseudo dice [np.float32(0.9218), np.float32(0.9625)] 
2025-04-18 00:21:59.575902: Epoch time: 193.98 s 
2025-04-18 00:22:00.643300:  
2025-04-18 00:22:00.643860: Epoch 829 
2025-04-18 00:22:00.644190: Current learning rate: 0.00204 
2025-04-18 00:25:14.456049: train_loss -0.9033 
2025-04-18 00:25:14.456897: val_loss -0.8647 
2025-04-18 00:25:14.457186: Pseudo dice [np.float32(0.9106), np.float32(0.9391)] 
2025-04-18 00:25:14.457472: Epoch time: 193.82 s 
2025-04-18 00:25:15.539904:  
2025-04-18 00:25:15.540564: Epoch 830 
2025-04-18 00:25:15.540913: Current learning rate: 0.00203 
2025-04-18 00:28:29.555690: train_loss -0.9151 
2025-04-18 00:28:29.559140: val_loss -0.8569 
2025-04-18 00:28:29.559485: Pseudo dice [np.float32(0.9083), np.float32(0.9419)] 
2025-04-18 00:28:29.559808: Epoch time: 194.02 s 
2025-04-18 00:28:30.697135:  
2025-04-18 00:28:30.697717: Epoch 831 
2025-04-18 00:28:30.698073: Current learning rate: 0.00202 
2025-04-18 00:31:44.364590: train_loss -0.9168 
2025-04-18 00:31:44.365416: val_loss -0.884 
2025-04-18 00:31:44.365708: Pseudo dice [np.float32(0.9109), np.float32(0.9479)] 
2025-04-18 00:31:44.366038: Epoch time: 193.67 s 
2025-04-18 00:31:45.453589:  
2025-04-18 00:31:45.454216: Epoch 832 
2025-04-18 00:31:45.454571: Current learning rate: 0.00201 
2025-04-18 00:34:59.262318: train_loss -0.9109 
2025-04-18 00:34:59.265591: val_loss -0.8607 
2025-04-18 00:34:59.265927: Pseudo dice [np.float32(0.9005), np.float32(0.9337)] 
2025-04-18 00:34:59.266244: Epoch time: 193.81 s 
2025-04-18 00:35:00.352141:  
2025-04-18 00:35:00.352731: Epoch 833 
2025-04-18 00:35:00.353066: Current learning rate: 0.002 
2025-04-18 00:38:14.281923: train_loss -0.914 
2025-04-18 00:38:14.282799: val_loss -0.864 
2025-04-18 00:38:14.283099: Pseudo dice [np.float32(0.8973), np.float32(0.943)] 
2025-04-18 00:38:14.283400: Epoch time: 193.93 s 
2025-04-18 00:38:15.376809:  
2025-04-18 00:38:15.377339: Epoch 834 
2025-04-18 00:38:15.377665: Current learning rate: 0.00199 
2025-04-18 00:41:30.455107: train_loss -0.9127 
2025-04-18 00:41:30.458971: val_loss -0.8586 
2025-04-18 00:41:30.459289: Pseudo dice [np.float32(0.8964), np.float32(0.9402)] 
2025-04-18 00:41:30.459595: Epoch time: 195.08 s 
2025-04-18 00:41:31.516927:  
2025-04-18 00:41:31.517448: Epoch 835 
2025-04-18 00:41:31.517788: Current learning rate: 0.00198 
2025-04-18 00:44:47.186773: train_loss -0.9112 
2025-04-18 00:44:47.187673: val_loss -0.8535 
2025-04-18 00:44:47.188005: Pseudo dice [np.float32(0.8901), np.float32(0.9377)] 
2025-04-18 00:44:47.188321: Epoch time: 195.67 s 
2025-04-18 00:44:48.278115:  
2025-04-18 00:44:48.278590: Epoch 836 
2025-04-18 00:44:48.278933: Current learning rate: 0.00196 
2025-04-18 00:48:03.781920: train_loss -0.915 
2025-04-18 00:48:03.786212: val_loss -0.8646 
2025-04-18 00:48:03.786626: Pseudo dice [np.float32(0.9147), np.float32(0.9426)] 
2025-04-18 00:48:03.786968: Epoch time: 195.51 s 
2025-04-18 00:48:04.928258:  
2025-04-18 00:48:04.928806: Epoch 837 
2025-04-18 00:48:04.929159: Current learning rate: 0.00195 
2025-04-18 00:51:19.899435: train_loss -0.9123 
2025-04-18 00:51:19.900289: val_loss -0.8527 
2025-04-18 00:51:19.900589: Pseudo dice [np.float32(0.8974), np.float32(0.941)] 
2025-04-18 00:51:19.900893: Epoch time: 194.97 s 
2025-04-18 00:51:21.005026:  
2025-04-18 00:51:21.005563: Epoch 838 
2025-04-18 00:51:21.005911: Current learning rate: 0.00194 
2025-04-18 00:54:35.936049: train_loss -0.9129 
2025-04-18 00:54:35.940016: val_loss -0.8662 
2025-04-18 00:54:35.940384: Pseudo dice [np.float32(0.9036), np.float32(0.944)] 
2025-04-18 00:54:35.941164: Epoch time: 194.93 s 
2025-04-18 00:54:37.861909:  
2025-04-18 00:54:37.862448: Epoch 839 
2025-04-18 00:54:37.862811: Current learning rate: 0.00193 
2025-04-18 00:57:52.758633: train_loss -0.9155 
2025-04-18 00:57:52.759499: val_loss -0.8546 
2025-04-18 00:57:52.759799: Pseudo dice [np.float32(0.8819), np.float32(0.942)] 
2025-04-18 00:57:52.760089: Epoch time: 194.9 s 
2025-04-18 00:57:53.834052:  
2025-04-18 00:57:53.834672: Epoch 840 
2025-04-18 00:57:53.835021: Current learning rate: 0.00192 
2025-04-18 01:01:08.599422: train_loss -0.9085 
2025-04-18 01:01:08.603010: val_loss -0.8647 
2025-04-18 01:01:08.603322: Pseudo dice [np.float32(0.8972), np.float32(0.9493)] 
2025-04-18 01:01:08.603616: Epoch time: 194.77 s 
2025-04-18 01:01:09.670390:  
2025-04-18 01:01:09.670845: Epoch 841 
2025-04-18 01:01:09.671191: Current learning rate: 0.00191 
2025-04-18 01:04:24.606691: train_loss -0.908 
2025-04-18 01:04:24.607537: val_loss -0.836 
2025-04-18 01:04:24.607854: Pseudo dice [np.float32(0.8974), np.float32(0.9322)] 
2025-04-18 01:04:24.608177: Epoch time: 194.94 s 
2025-04-18 01:04:25.662075:  
2025-04-18 01:04:25.662600: Epoch 842 
2025-04-18 01:04:25.662918: Current learning rate: 0.0019 
2025-04-18 01:07:41.448425: train_loss -0.9151 
2025-04-18 01:07:41.452298: val_loss -0.8432 
2025-04-18 01:07:41.452903: Pseudo dice [np.float32(0.8931), np.float32(0.9327)] 
2025-04-18 01:07:41.453208: Epoch time: 195.79 s 
2025-04-18 01:07:42.530200:  
2025-04-18 01:07:42.530785: Epoch 843 
2025-04-18 01:07:42.531122: Current learning rate: 0.00189 
2025-04-18 01:10:57.969453: train_loss -0.9122 
2025-04-18 01:10:57.972259: val_loss -0.8572 
2025-04-18 01:10:57.972560: Pseudo dice [np.float32(0.8928), np.float32(0.9473)] 
2025-04-18 01:10:57.972844: Epoch time: 195.44 s 
2025-04-18 01:10:59.050855:  
2025-04-18 01:10:59.051533: Epoch 844 
2025-04-18 01:10:59.051882: Current learning rate: 0.00188 
2025-04-18 01:14:13.608498: train_loss -0.9124 
2025-04-18 01:14:13.612415: val_loss -0.8636 
2025-04-18 01:14:13.612708: Pseudo dice [np.float32(0.9014), np.float32(0.9431)] 
2025-04-18 01:14:13.613019: Epoch time: 194.56 s 
2025-04-18 01:14:14.669756:  
2025-04-18 01:14:14.670276: Epoch 845 
2025-04-18 01:14:14.670588: Current learning rate: 0.00187 
2025-04-18 01:17:29.210297: train_loss -0.9174 
2025-04-18 01:17:29.211092: val_loss -0.8807 
2025-04-18 01:17:29.211367: Pseudo dice [np.float32(0.9184), np.float32(0.935)] 
2025-04-18 01:17:29.211655: Epoch time: 194.54 s 
2025-04-18 01:17:30.299465:  
2025-04-18 01:17:30.299952: Epoch 846 
2025-04-18 01:17:30.300256: Current learning rate: 0.00186 
2025-04-18 01:20:45.037500: train_loss -0.9079 
2025-04-18 01:20:45.040962: val_loss -0.8662 
2025-04-18 01:20:45.041273: Pseudo dice [np.float32(0.9163), np.float32(0.9473)] 
2025-04-18 01:20:45.041554: Epoch time: 194.74 s 
2025-04-18 01:20:46.128282:  
2025-04-18 01:20:46.128774: Epoch 847 
2025-04-18 01:20:46.129095: Current learning rate: 0.00185 
2025-04-18 01:24:00.950628: train_loss -0.9138 
2025-04-18 01:24:00.951461: val_loss -0.8541 
2025-04-18 01:24:00.951752: Pseudo dice [np.float32(0.9059), np.float32(0.9459)] 
2025-04-18 01:24:00.952041: Epoch time: 194.82 s 
2025-04-18 01:24:02.049015:  
2025-04-18 01:24:02.049663: Epoch 848 
2025-04-18 01:24:02.050021: Current learning rate: 0.00184 
2025-04-18 01:27:16.798819: train_loss -0.9169 
2025-04-18 01:27:16.802373: val_loss -0.8712 
2025-04-18 01:27:16.802702: Pseudo dice [np.float32(0.9107), np.float32(0.9403)] 
2025-04-18 01:27:16.803021: Epoch time: 194.75 s 
2025-04-18 01:27:17.882437:  
2025-04-18 01:27:17.882961: Epoch 849 
2025-04-18 01:27:17.883260: Current learning rate: 0.00182 
2025-04-18 01:30:32.939147: train_loss -0.9137 
2025-04-18 01:30:32.939967: val_loss -0.8764 
2025-04-18 01:30:32.940254: Pseudo dice [np.float32(0.9123), np.float32(0.9386)] 
2025-04-18 01:30:32.940545: Epoch time: 195.06 s 
2025-04-18 01:30:34.430402:  
2025-04-18 01:30:34.430934: Epoch 850 
2025-04-18 01:30:34.431269: Current learning rate: 0.00181 
2025-04-18 01:33:49.413081: train_loss -0.9183 
2025-04-18 01:33:49.416786: val_loss -0.8837 
2025-04-18 01:33:49.417136: Pseudo dice [np.float32(0.9173), np.float32(0.9454)] 
2025-04-18 01:33:49.417453: Epoch time: 194.98 s 
2025-04-18 01:33:50.531253:  
2025-04-18 01:33:50.531796: Epoch 851 
2025-04-18 01:33:50.532137: Current learning rate: 0.0018 
2025-04-18 01:37:05.725309: train_loss -0.9121 
2025-04-18 01:37:05.726161: val_loss -0.8623 
2025-04-18 01:37:05.726462: Pseudo dice [np.float32(0.9036), np.float32(0.9365)] 
2025-04-18 01:37:05.726773: Epoch time: 195.2 s 
2025-04-18 01:37:06.755902:  
2025-04-18 01:37:06.756568: Epoch 852 
2025-04-18 01:37:06.757185: Current learning rate: 0.00179 
2025-04-18 01:40:22.229136: train_loss -0.9138 
2025-04-18 01:40:22.232968: val_loss -0.8589 
2025-04-18 01:40:22.233270: Pseudo dice [np.float32(0.9), np.float32(0.9449)] 
2025-04-18 01:40:22.233566: Epoch time: 195.48 s 
2025-04-18 01:40:23.263256:  
2025-04-18 01:40:23.263798: Epoch 853 
2025-04-18 01:40:23.264117: Current learning rate: 0.00178 
2025-04-18 01:43:38.781972: train_loss -0.908 
2025-04-18 01:43:38.782806: val_loss -0.8837 
2025-04-18 01:43:38.783103: Pseudo dice [np.float32(0.9064), np.float32(0.9489)] 
2025-04-18 01:43:38.783408: Epoch time: 195.52 s 
2025-04-18 01:43:39.830939:  
2025-04-18 01:43:39.831451: Epoch 854 
2025-04-18 01:43:39.831789: Current learning rate: 0.00177 
2025-04-18 01:46:55.162308: train_loss -0.9167 
2025-04-18 01:46:55.166788: val_loss -0.8766 
2025-04-18 01:46:55.167092: Pseudo dice [np.float32(0.8933), np.float32(0.9469)] 
2025-04-18 01:46:55.167380: Epoch time: 195.33 s 
2025-04-18 01:46:56.214970:  
2025-04-18 01:46:56.215497: Epoch 855 
2025-04-18 01:46:56.215830: Current learning rate: 0.00176 
2025-04-18 01:50:11.353246: train_loss -0.9087 
2025-04-18 01:50:11.354091: val_loss -0.871 
2025-04-18 01:50:11.354391: Pseudo dice [np.float32(0.9017), np.float32(0.9443)] 
2025-04-18 01:50:11.354809: Epoch time: 195.14 s 
2025-04-18 01:50:12.400173:  
2025-04-18 01:50:12.400733: Epoch 856 
2025-04-18 01:50:12.401086: Current learning rate: 0.00175 
2025-04-18 01:53:27.306039: train_loss -0.9174 
2025-04-18 01:53:27.309961: val_loss -0.8884 
2025-04-18 01:53:27.310389: Pseudo dice [np.float32(0.9134), np.float32(0.9516)] 
2025-04-18 01:53:27.310755: Epoch time: 194.91 s 
2025-04-18 01:53:28.383126:  
2025-04-18 01:53:28.383774: Epoch 857 
2025-04-18 01:53:28.384137: Current learning rate: 0.00174 
2025-04-18 01:56:43.238131: train_loss -0.9168 
2025-04-18 01:56:43.238947: val_loss -0.8824 
2025-04-18 01:56:43.239246: Pseudo dice [np.float32(0.9074), np.float32(0.9493)] 
2025-04-18 01:56:43.239549: Epoch time: 194.86 s 
2025-04-18 01:56:44.321841:  
2025-04-18 01:56:44.322387: Epoch 858 
2025-04-18 01:56:44.322704: Current learning rate: 0.00173 
2025-04-18 01:59:58.870872: train_loss -0.9168 
2025-04-18 01:59:58.874415: val_loss -0.8658 
2025-04-18 01:59:58.874764: Pseudo dice [np.float32(0.8977), np.float32(0.935)] 
2025-04-18 01:59:58.875072: Epoch time: 194.55 s 
2025-04-18 02:00:00.852622:  
2025-04-18 02:00:00.853226: Epoch 859 
2025-04-18 02:00:00.853567: Current learning rate: 0.00172 
2025-04-18 02:03:15.218226: train_loss -0.9157 
2025-04-18 02:03:15.219099: val_loss -0.8894 
2025-04-18 02:03:15.219431: Pseudo dice [np.float32(0.9297), np.float32(0.9539)] 
2025-04-18 02:03:15.219755: Epoch time: 194.37 s 
2025-04-18 02:03:16.287083:  
2025-04-18 02:03:16.287665: Epoch 860 
2025-04-18 02:03:16.288020: Current learning rate: 0.0017 
2025-04-18 02:06:30.888296: train_loss -0.9123 
2025-04-18 02:06:30.891954: val_loss -0.8642 
2025-04-18 02:06:30.892294: Pseudo dice [np.float32(0.9069), np.float32(0.9396)] 
2025-04-18 02:06:30.892614: Epoch time: 194.6 s 
2025-04-18 02:06:31.935846:  
2025-04-18 02:06:31.936797: Epoch 861 
2025-04-18 02:06:31.937158: Current learning rate: 0.00169 
2025-04-18 02:09:46.709259: train_loss -0.9103 
2025-04-18 02:09:46.710092: val_loss -0.8799 
2025-04-18 02:09:46.710397: Pseudo dice [np.float32(0.9158), np.float32(0.9537)] 
2025-04-18 02:09:46.710710: Epoch time: 194.78 s 
2025-04-18 02:09:47.770882:  
2025-04-18 02:09:47.771780: Epoch 862 
2025-04-18 02:09:47.772107: Current learning rate: 0.00168 
2025-04-18 02:13:02.260405: train_loss -0.9121 
2025-04-18 02:13:02.264709: val_loss -0.8698 
2025-04-18 02:13:02.265105: Pseudo dice [np.float32(0.9111), np.float32(0.9496)] 
2025-04-18 02:13:02.265434: Epoch time: 194.49 s 
2025-04-18 02:13:03.332713:  
2025-04-18 02:13:03.333785: Epoch 863 
2025-04-18 02:13:03.334146: Current learning rate: 0.00167 
2025-04-18 02:16:17.163568: train_loss -0.9158 
2025-04-18 02:16:17.164376: val_loss -0.8622 
2025-04-18 02:16:17.164677: Pseudo dice [np.float32(0.9089), np.float32(0.9376)] 
2025-04-18 02:16:17.164982: Epoch time: 193.83 s 
2025-04-18 02:16:18.204398:  
2025-04-18 02:16:18.205375: Epoch 864 
2025-04-18 02:16:18.205725: Current learning rate: 0.00166 
2025-04-18 02:19:32.349562: train_loss -0.9124 
2025-04-18 02:19:32.353109: val_loss -0.8632 
2025-04-18 02:19:32.353434: Pseudo dice [np.float32(0.8905), np.float32(0.939)] 
2025-04-18 02:19:32.353734: Epoch time: 194.15 s 
2025-04-18 02:19:33.428552:  
2025-04-18 02:19:33.429493: Epoch 865 
2025-04-18 02:19:33.429837: Current learning rate: 0.00165 
2025-04-18 02:22:47.641096: train_loss -0.9163 
2025-04-18 02:22:47.641991: val_loss -0.8718 
2025-04-18 02:22:47.642301: Pseudo dice [np.float32(0.9145), np.float32(0.9452)] 
2025-04-18 02:22:47.642612: Epoch time: 194.21 s 
2025-04-18 02:22:48.724290:  
2025-04-18 02:22:48.725261: Epoch 866 
2025-04-18 02:22:48.725612: Current learning rate: 0.00164 
2025-04-18 02:26:03.683007: train_loss -0.9134 
2025-04-18 02:26:03.686517: val_loss -0.8857 
2025-04-18 02:26:03.686860: Pseudo dice [np.float32(0.9219), np.float32(0.9462)] 
2025-04-18 02:26:03.687177: Epoch time: 194.96 s 
2025-04-18 02:26:04.721405:  
2025-04-18 02:26:04.722364: Epoch 867 
2025-04-18 02:26:04.722691: Current learning rate: 0.00163 
2025-04-18 02:29:19.611496: train_loss -0.9151 
2025-04-18 02:29:19.612377: val_loss -0.8804 
2025-04-18 02:29:19.612660: Pseudo dice [np.float32(0.9265), np.float32(0.9488)] 
2025-04-18 02:29:19.612975: Epoch time: 194.89 s 
2025-04-18 02:29:20.644475:  
2025-04-18 02:29:20.645418: Epoch 868 
2025-04-18 02:29:20.645760: Current learning rate: 0.00162 
2025-04-18 02:33:53.503911: train_loss -0.9118 
2025-04-18 02:33:53.507705: val_loss -0.8629 
2025-04-18 02:33:53.508026: Pseudo dice [np.float32(0.9034), np.float32(0.9422)] 
2025-04-18 02:33:53.508327: Epoch time: 272.86 s 
2025-04-18 02:33:54.562222:  
2025-04-18 02:33:54.563315: Epoch 869 
2025-04-18 02:33:54.563669: Current learning rate: 0.00161 
2025-04-18 02:37:34.566875: train_loss -0.915 
2025-04-18 02:37:34.567704: val_loss -0.8748 
2025-04-18 02:37:34.568012: Pseudo dice [np.float32(0.9115), np.float32(0.9535)] 
2025-04-18 02:37:34.568309: Epoch time: 220.01 s 
2025-04-18 02:37:35.591086:  
2025-04-18 02:37:35.591948: Epoch 870 
2025-04-18 02:37:35.592262: Current learning rate: 0.00159 
2025-04-18 02:40:44.002700: train_loss -0.908 
2025-04-18 02:40:44.030413: val_loss -0.8881 
2025-04-18 02:40:44.030866: Pseudo dice [np.float32(0.92), np.float32(0.9509)] 
2025-04-18 02:40:44.031224: Epoch time: 188.41 s 
2025-04-18 02:40:45.091757:  
2025-04-18 02:40:45.092785: Epoch 871 
2025-04-18 02:40:45.093126: Current learning rate: 0.00158 
2025-04-18 02:43:58.190497: train_loss -0.9083 
2025-04-18 02:43:58.191376: val_loss -0.8855 
2025-04-18 02:43:58.191664: Pseudo dice [np.float32(0.9154), np.float32(0.945)] 
2025-04-18 02:43:58.191961: Epoch time: 193.1 s 
2025-04-18 02:43:59.251187:  
2025-04-18 02:43:59.252143: Epoch 872 
2025-04-18 02:43:59.252467: Current learning rate: 0.00157 
2025-04-18 02:47:13.076141: train_loss -0.9154 
2025-04-18 02:47:13.080916: val_loss -0.8694 
2025-04-18 02:47:13.081380: Pseudo dice [np.float32(0.9059), np.float32(0.9416)] 
2025-04-18 02:47:13.081728: Epoch time: 193.83 s 
2025-04-18 02:47:14.128698:  
2025-04-18 02:47:14.129701: Epoch 873 
2025-04-18 02:47:14.130092: Current learning rate: 0.00156 
2025-04-18 02:50:28.286630: train_loss -0.9135 
2025-04-18 02:50:28.287953: val_loss -0.8622 
2025-04-18 02:50:28.288250: Pseudo dice [np.float32(0.9143), np.float32(0.9447)] 
2025-04-18 02:50:28.288539: Epoch time: 194.16 s 
2025-04-18 02:50:29.335156:  
2025-04-18 02:50:29.336160: Epoch 874 
2025-04-18 02:50:29.336502: Current learning rate: 0.00155 
2025-04-18 02:53:43.789891: train_loss -0.9155 
2025-04-18 02:53:43.794278: val_loss -0.8671 
2025-04-18 02:53:43.794653: Pseudo dice [np.float32(0.8944), np.float32(0.9431)] 
2025-04-18 02:53:43.794986: Epoch time: 194.46 s 
2025-04-18 02:53:44.844578:  
2025-04-18 02:53:44.845463: Epoch 875 
2025-04-18 02:53:44.845812: Current learning rate: 0.00154 
2025-04-18 02:56:59.642127: train_loss -0.9132 
2025-04-18 02:56:59.643003: val_loss -0.8699 
2025-04-18 02:56:59.643314: Pseudo dice [np.float32(0.9058), np.float32(0.9436)] 
2025-04-18 02:56:59.643651: Epoch time: 194.8 s 
2025-04-18 02:57:00.699708:  
2025-04-18 02:57:00.700766: Epoch 876 
2025-04-18 02:57:00.701112: Current learning rate: 0.00153 
2025-04-18 03:00:15.791480: train_loss -0.9155 
2025-04-18 03:00:15.795574: val_loss -0.8701 
2025-04-18 03:00:15.795964: Pseudo dice [np.float32(0.9035), np.float32(0.9249)] 
2025-04-18 03:00:15.796292: Epoch time: 195.09 s 
2025-04-18 03:00:16.881813:  
2025-04-18 03:00:16.882880: Epoch 877 
2025-04-18 03:00:16.883246: Current learning rate: 0.00152 
2025-04-18 03:03:32.006177: train_loss -0.9161 
2025-04-18 03:03:32.006967: val_loss -0.8723 
2025-04-18 03:03:32.007261: Pseudo dice [np.float32(0.9092), np.float32(0.9523)] 
2025-04-18 03:03:32.007591: Epoch time: 195.13 s 
2025-04-18 03:03:33.063242:  
2025-04-18 03:03:33.063709: Epoch 878 
2025-04-18 03:03:33.064043: Current learning rate: 0.00151 
2025-04-18 03:06:48.146923: train_loss -0.92 
2025-04-18 03:06:48.150281: val_loss -0.8524 
2025-04-18 03:06:48.150580: Pseudo dice [np.float32(0.9001), np.float32(0.9377)] 
2025-04-18 03:06:48.150875: Epoch time: 195.09 s 
2025-04-18 03:06:50.082090:  
2025-04-18 03:06:50.082577: Epoch 879 
2025-04-18 03:06:50.082894: Current learning rate: 0.00149 
2025-04-18 03:10:05.788275: train_loss -0.9146 
2025-04-18 03:10:05.789185: val_loss -0.8743 
2025-04-18 03:10:05.789515: Pseudo dice [np.float32(0.9238), np.float32(0.9451)] 
2025-04-18 03:10:05.789882: Epoch time: 195.71 s 
2025-04-18 03:10:06.837751:  
2025-04-18 03:10:06.838330: Epoch 880 
2025-04-18 03:10:06.838688: Current learning rate: 0.00148 
2025-04-18 03:13:22.701406: train_loss -0.9187 
2025-04-18 03:13:22.705375: val_loss -0.881 
2025-04-18 03:13:22.705698: Pseudo dice [np.float32(0.9074), np.float32(0.9523)] 
2025-04-18 03:13:22.706018: Epoch time: 195.87 s 
2025-04-18 03:13:23.753382:  
2025-04-18 03:13:23.753899: Epoch 881 
2025-04-18 03:13:23.754238: Current learning rate: 0.00147 
2025-04-18 03:16:40.029790: train_loss -0.9188 
2025-04-18 03:16:40.030666: val_loss -0.8661 
2025-04-18 03:16:40.030999: Pseudo dice [np.float32(0.9118), np.float32(0.9395)] 
2025-04-18 03:16:40.031326: Epoch time: 196.28 s 
2025-04-18 03:16:41.091202:  
2025-04-18 03:16:41.091862: Epoch 882 
2025-04-18 03:16:41.092226: Current learning rate: 0.00146 
2025-04-18 03:19:56.193145: train_loss -0.9208 
2025-04-18 03:19:56.196803: val_loss -0.8691 
2025-04-18 03:19:56.197133: Pseudo dice [np.float32(0.9117), np.float32(0.9394)] 
2025-04-18 03:19:56.197436: Epoch time: 195.1 s 
2025-04-18 03:19:57.243000:  
2025-04-18 03:19:57.243554: Epoch 883 
2025-04-18 03:19:57.243897: Current learning rate: 0.00145 
2025-04-18 03:23:11.735995: train_loss -0.9126 
2025-04-18 03:23:11.736867: val_loss -0.8695 
2025-04-18 03:23:11.737159: Pseudo dice [np.float32(0.9177), np.float32(0.9458)] 
2025-04-18 03:23:11.737464: Epoch time: 194.5 s 
2025-04-18 03:23:12.788676:  
2025-04-18 03:23:12.789298: Epoch 884 
2025-04-18 03:23:12.789639: Current learning rate: 0.00144 
2025-04-18 03:26:27.216059: train_loss -0.9153 
2025-04-18 03:26:27.219694: val_loss -0.8891 
2025-04-18 03:26:27.220048: Pseudo dice [np.float32(0.92), np.float32(0.9533)] 
2025-04-18 03:26:27.220366: Epoch time: 194.43 s 
2025-04-18 03:26:28.298278:  
2025-04-18 03:26:28.299127: Epoch 885 
2025-04-18 03:26:28.299462: Current learning rate: 0.00143 
2025-04-18 03:29:42.625102: train_loss -0.9157 
2025-04-18 03:29:42.625933: val_loss -0.8689 
2025-04-18 03:29:42.626236: Pseudo dice [np.float32(0.91), np.float32(0.9374)] 
2025-04-18 03:29:42.626523: Epoch time: 194.33 s 
2025-04-18 03:29:43.681734:  
2025-04-18 03:29:43.682251: Epoch 886 
2025-04-18 03:29:43.682573: Current learning rate: 0.00142 
2025-04-18 03:32:58.240248: train_loss -0.9123 
2025-04-18 03:32:58.244355: val_loss -0.8393 
2025-04-18 03:32:58.244727: Pseudo dice [np.float32(0.8872), np.float32(0.9218)] 
2025-04-18 03:32:58.245069: Epoch time: 194.56 s 
2025-04-18 03:32:59.328651:  
2025-04-18 03:32:59.329178: Epoch 887 
2025-04-18 03:32:59.329511: Current learning rate: 0.00141 
2025-04-18 03:36:13.505898: train_loss -0.9148 
2025-04-18 03:36:13.506701: val_loss -0.8785 
2025-04-18 03:36:13.507016: Pseudo dice [np.float32(0.9141), np.float32(0.9507)] 
2025-04-18 03:36:13.507305: Epoch time: 194.18 s 
2025-04-18 03:36:14.569154:  
2025-04-18 03:36:14.569696: Epoch 888 
2025-04-18 03:36:14.570040: Current learning rate: 0.00139 
2025-04-18 03:39:28.403631: train_loss -0.9169 
2025-04-18 03:39:28.407010: val_loss -0.868 
2025-04-18 03:39:28.407329: Pseudo dice [np.float32(0.9034), np.float32(0.9393)] 
2025-04-18 03:39:28.407629: Epoch time: 193.84 s 
2025-04-18 03:39:29.455714:  
2025-04-18 03:39:29.456290: Epoch 889 
2025-04-18 03:39:29.456635: Current learning rate: 0.00138 
2025-04-18 03:42:43.221138: train_loss -0.9195 
2025-04-18 03:42:43.221971: val_loss -0.8853 
2025-04-18 03:42:43.222267: Pseudo dice [np.float32(0.9119), np.float32(0.9507)] 
2025-04-18 03:42:43.222558: Epoch time: 193.77 s 
2025-04-18 03:42:44.253478:  
2025-04-18 03:42:44.254036: Epoch 890 
2025-04-18 03:42:44.254369: Current learning rate: 0.00137 
2025-04-18 03:45:58.076077: train_loss -0.9028 
2025-04-18 03:45:58.079509: val_loss -0.8813 
2025-04-18 03:45:58.079827: Pseudo dice [np.float32(0.9133), np.float32(0.9478)] 
2025-04-18 03:45:58.080126: Epoch time: 193.82 s 
2025-04-18 03:45:59.158549:  
2025-04-18 03:45:59.159101: Epoch 891 
2025-04-18 03:45:59.159427: Current learning rate: 0.00136 
2025-04-18 03:49:13.574096: train_loss -0.9234 
2025-04-18 03:49:13.574931: val_loss -0.8836 
2025-04-18 03:49:13.575205: Pseudo dice [np.float32(0.9161), np.float32(0.9476)] 
2025-04-18 03:49:13.575485: Epoch time: 194.42 s 
2025-04-18 03:49:14.635338:  
2025-04-18 03:49:14.635839: Epoch 892 
2025-04-18 03:49:14.636161: Current learning rate: 0.00135 
2025-04-18 03:52:28.803874: train_loss -0.9217 
2025-04-18 03:52:28.807414: val_loss -0.8662 
2025-04-18 03:52:28.807724: Pseudo dice [np.float32(0.9085), np.float32(0.94)] 
2025-04-18 03:52:28.808027: Epoch time: 194.17 s 
2025-04-18 03:52:29.844980:  
2025-04-18 03:52:29.845639: Epoch 893 
2025-04-18 03:52:29.846004: Current learning rate: 0.00134 
2025-04-18 03:55:44.407060: train_loss -0.9213 
2025-04-18 03:55:44.407874: val_loss -0.8728 
2025-04-18 03:55:44.408185: Pseudo dice [np.float32(0.9167), np.float32(0.9482)] 
2025-04-18 03:55:44.408498: Epoch time: 194.56 s 
2025-04-18 03:55:45.467053:  
2025-04-18 03:55:45.467602: Epoch 894 
2025-04-18 03:55:45.467942: Current learning rate: 0.00133 
2025-04-18 03:58:59.694015: train_loss -0.9206 
2025-04-18 03:58:59.697643: val_loss -0.8733 
2025-04-18 03:58:59.697977: Pseudo dice [np.float32(0.907), np.float32(0.9481)] 
2025-04-18 03:58:59.698313: Epoch time: 194.23 s 
2025-04-18 03:59:00.747548:  
2025-04-18 03:59:00.748073: Epoch 895 
2025-04-18 03:59:00.748409: Current learning rate: 0.00132 
2025-04-18 04:02:14.653304: train_loss -0.9108 
2025-04-18 04:02:14.654096: val_loss -0.8703 
2025-04-18 04:02:14.654383: Pseudo dice [np.float32(0.9149), np.float32(0.9491)] 
2025-04-18 04:02:14.654676: Epoch time: 193.91 s 
2025-04-18 04:02:15.717450:  
2025-04-18 04:02:15.717969: Epoch 896 
2025-04-18 04:02:15.718299: Current learning rate: 0.0013 
2025-04-18 04:05:29.735250: train_loss -0.9187 
2025-04-18 04:05:29.738880: val_loss -0.8559 
2025-04-18 04:05:29.739405: Pseudo dice [np.float32(0.8944), np.float32(0.9288)] 
2025-04-18 04:05:29.739696: Epoch time: 194.02 s 
2025-04-18 04:05:30.799381:  
2025-04-18 04:05:30.799973: Epoch 897 
2025-04-18 04:05:30.800295: Current learning rate: 0.00129 
2025-04-18 04:08:44.737396: train_loss -0.9208 
2025-04-18 04:08:44.738279: val_loss -0.8786 
2025-04-18 04:08:44.738577: Pseudo dice [np.float32(0.9195), np.float32(0.9423)] 
2025-04-18 04:08:44.738864: Epoch time: 193.94 s 
2025-04-18 04:08:45.802273:  
2025-04-18 04:08:45.802760: Epoch 898 
2025-04-18 04:08:45.803072: Current learning rate: 0.00128 
2025-04-18 04:12:00.092196: train_loss -0.9195 
2025-04-18 04:12:00.096097: val_loss -0.8754 
2025-04-18 04:12:00.096436: Pseudo dice [np.float32(0.9159), np.float32(0.9547)] 
2025-04-18 04:12:00.096782: Epoch time: 194.29 s 
2025-04-18 04:12:01.193195:  
2025-04-18 04:12:01.193755: Epoch 899 
2025-04-18 04:12:01.194103: Current learning rate: 0.00127 
2025-04-18 04:15:15.479945: train_loss -0.9161 
2025-04-18 04:15:15.480772: val_loss -0.8341 
2025-04-18 04:15:15.481063: Pseudo dice [np.float32(0.8826), np.float32(0.928)] 
2025-04-18 04:15:15.481359: Epoch time: 194.29 s 
2025-04-18 04:15:18.037838:  
2025-04-18 04:15:18.038357: Epoch 900 
2025-04-18 04:15:18.038687: Current learning rate: 0.00126 
2025-04-18 04:18:31.989767: train_loss -0.9123 
2025-04-18 04:18:31.993219: val_loss -0.878 
2025-04-18 04:18:31.993527: Pseudo dice [np.float32(0.9119), np.float32(0.9466)] 
2025-04-18 04:18:31.993834: Epoch time: 193.95 s 
2025-04-18 04:18:33.039287:  
2025-04-18 04:18:33.039802: Epoch 901 
2025-04-18 04:18:33.040128: Current learning rate: 0.00125 
2025-04-18 04:21:47.263609: train_loss -0.9126 
2025-04-18 04:21:47.264532: val_loss -0.8844 
2025-04-18 04:21:47.264859: Pseudo dice [np.float32(0.9155), np.float32(0.9485)] 
2025-04-18 04:21:47.265191: Epoch time: 194.23 s 
2025-04-18 04:21:48.324306:  
2025-04-18 04:21:48.324856: Epoch 902 
2025-04-18 04:21:48.325208: Current learning rate: 0.00124 
2025-04-18 04:25:02.353966: train_loss -0.9203 
2025-04-18 04:25:02.357683: val_loss -0.8596 
2025-04-18 04:25:02.358055: Pseudo dice [np.float32(0.9039), np.float32(0.948)] 
2025-04-18 04:25:02.358500: Epoch time: 194.03 s 
2025-04-18 04:25:03.441141:  
2025-04-18 04:25:03.441616: Epoch 903 
2025-04-18 04:25:03.441965: Current learning rate: 0.00122 
2025-04-18 04:28:17.712955: train_loss -0.9129 
2025-04-18 04:28:17.713746: val_loss -0.8718 
2025-04-18 04:28:17.714028: Pseudo dice [np.float32(0.9177), np.float32(0.9444)] 
2025-04-18 04:28:17.714308: Epoch time: 194.27 s 
2025-04-18 04:28:18.755525:  
2025-04-18 04:28:18.756063: Epoch 904 
2025-04-18 04:28:18.756385: Current learning rate: 0.00121 
2025-04-18 04:31:32.859400: train_loss -0.922 
2025-04-18 04:31:32.863046: val_loss -0.8811 
2025-04-18 04:31:32.863381: Pseudo dice [np.float32(0.9208), np.float32(0.9399)] 
2025-04-18 04:31:32.863688: Epoch time: 194.11 s 
2025-04-18 04:31:33.925718:  
2025-04-18 04:31:33.926264: Epoch 905 
2025-04-18 04:31:33.926587: Current learning rate: 0.0012 
2025-04-18 04:34:48.043538: train_loss -0.9189 
2025-04-18 04:34:48.044403: val_loss -0.868 
2025-04-18 04:34:48.044724: Pseudo dice [np.float32(0.91), np.float32(0.9513)] 
2025-04-18 04:34:48.045040: Epoch time: 194.12 s 
2025-04-18 04:34:49.101229:  
2025-04-18 04:34:49.101782: Epoch 906 
2025-04-18 04:34:49.102120: Current learning rate: 0.00119 
2025-04-18 04:38:03.329689: train_loss -0.918 
2025-04-18 04:38:03.333207: val_loss -0.8976 
2025-04-18 04:38:03.333542: Pseudo dice [np.float32(0.9242), np.float32(0.9599)] 
2025-04-18 04:38:03.333867: Epoch time: 194.23 s 
2025-04-18 04:38:04.424559:  
2025-04-18 04:38:04.425077: Epoch 907 
2025-04-18 04:38:04.425422: Current learning rate: 0.00118 
2025-04-18 04:41:18.949484: train_loss -0.9157 
2025-04-18 04:41:18.950310: val_loss -0.876 
2025-04-18 04:41:18.950613: Pseudo dice [np.float32(0.9133), np.float32(0.9463)] 
2025-04-18 04:41:18.950949: Epoch time: 194.53 s 
2025-04-18 04:41:20.005764:  
2025-04-18 04:41:20.006326: Epoch 908 
2025-04-18 04:41:20.007024: Current learning rate: 0.00117 
2025-04-18 04:44:34.966334: train_loss -0.918 
2025-04-18 04:44:34.969852: val_loss -0.8715 
2025-04-18 04:44:34.970209: Pseudo dice [np.float32(0.9107), np.float32(0.9393)] 
2025-04-18 04:44:34.970537: Epoch time: 194.96 s 
2025-04-18 04:44:36.068607:  
2025-04-18 04:44:36.069205: Epoch 909 
2025-04-18 04:44:36.069575: Current learning rate: 0.00116 
2025-04-18 04:47:51.047943: train_loss -0.9199 
2025-04-18 04:47:51.048855: val_loss -0.8726 
2025-04-18 04:47:51.049190: Pseudo dice [np.float32(0.9079), np.float32(0.936)] 
2025-04-18 04:47:51.049518: Epoch time: 194.98 s 
2025-04-18 04:47:52.147377:  
2025-04-18 04:47:52.148023: Epoch 910 
2025-04-18 04:47:52.148391: Current learning rate: 0.00115 
2025-04-18 04:51:07.243377: train_loss -0.9194 
2025-04-18 04:51:07.247434: val_loss -0.8939 
2025-04-18 04:51:07.247922: Pseudo dice [np.float32(0.9208), np.float32(0.9557)] 
2025-04-18 04:51:07.248329: Epoch time: 195.1 s 
2025-04-18 04:51:08.373883:  
2025-04-18 04:51:08.374386: Epoch 911 
2025-04-18 04:51:08.374778: Current learning rate: 0.00113 
2025-04-18 04:54:23.534216: train_loss -0.9188 
2025-04-18 04:54:23.535052: val_loss -0.8774 
2025-04-18 04:54:23.535347: Pseudo dice [np.float32(0.9119), np.float32(0.9493)] 
2025-04-18 04:54:23.535650: Epoch time: 195.16 s 
2025-04-18 04:54:24.590411:  
2025-04-18 04:54:24.590931: Epoch 912 
2025-04-18 04:54:24.591245: Current learning rate: 0.00112 
2025-04-18 04:57:38.692269: train_loss -0.916 
2025-04-18 04:57:38.695943: val_loss -0.882 
2025-04-18 04:57:38.696240: Pseudo dice [np.float32(0.9045), np.float32(0.9518)] 
2025-04-18 04:57:38.696528: Epoch time: 194.1 s 
2025-04-18 04:57:39.742795:  
2025-04-18 04:57:39.743273: Epoch 913 
2025-04-18 04:57:39.743588: Current learning rate: 0.00111 
2025-04-18 05:00:53.296766: train_loss -0.9186 
2025-04-18 05:00:53.297517: val_loss -0.8711 
2025-04-18 05:00:53.297803: Pseudo dice [np.float32(0.9178), np.float32(0.9419)] 
2025-04-18 05:00:53.298097: Epoch time: 193.56 s 
2025-04-18 05:00:54.365968:  
2025-04-18 05:00:54.366435: Epoch 914 
2025-04-18 05:00:54.366753: Current learning rate: 0.0011 
2025-04-18 05:04:08.193056: train_loss -0.9121 
2025-04-18 05:04:08.196902: val_loss -0.8601 
2025-04-18 05:04:08.197244: Pseudo dice [np.float32(0.908), np.float32(0.9464)] 
2025-04-18 05:04:08.197579: Epoch time: 193.83 s 
2025-04-18 05:04:09.284634:  
2025-04-18 05:04:09.285138: Epoch 915 
2025-04-18 05:04:09.285486: Current learning rate: 0.00109 
2025-04-18 05:07:22.894070: train_loss -0.9151 
2025-04-18 05:07:22.894860: val_loss -0.8643 
2025-04-18 05:07:22.895162: Pseudo dice [np.float32(0.916), np.float32(0.9449)] 
2025-04-18 05:07:22.895456: Epoch time: 193.61 s 
2025-04-18 05:07:23.963205:  
2025-04-18 05:07:23.963685: Epoch 916 
2025-04-18 05:07:23.964009: Current learning rate: 0.00108 
2025-04-18 05:10:37.567841: train_loss -0.916 
2025-04-18 05:10:37.571469: val_loss -0.8741 
2025-04-18 05:10:37.571820: Pseudo dice [np.float32(0.9109), np.float32(0.9372)] 
2025-04-18 05:10:37.572119: Epoch time: 193.61 s 
2025-04-18 05:10:38.628335:  
2025-04-18 05:10:38.628808: Epoch 917 
2025-04-18 05:10:38.629131: Current learning rate: 0.00106 
2025-04-18 05:13:52.220216: train_loss -0.9152 
2025-04-18 05:13:52.220993: val_loss -0.8629 
2025-04-18 05:13:52.221281: Pseudo dice [np.float32(0.8973), np.float32(0.9427)] 
2025-04-18 05:13:52.221564: Epoch time: 193.59 s 
2025-04-18 05:13:53.264781:  
2025-04-18 05:13:53.265224: Epoch 918 
2025-04-18 05:13:53.265538: Current learning rate: 0.00105 
2025-04-18 05:17:06.909802: train_loss -0.9204 
2025-04-18 05:17:06.912987: val_loss -0.8913 
2025-04-18 05:17:06.913287: Pseudo dice [np.float32(0.9144), np.float32(0.9451)] 
2025-04-18 05:17:06.913577: Epoch time: 193.65 s 
2025-04-18 05:17:07.963095:  
2025-04-18 05:17:07.963562: Epoch 919 
2025-04-18 05:17:07.963892: Current learning rate: 0.00104 
2025-04-18 05:20:21.618596: train_loss -0.9168 
2025-04-18 05:20:21.619357: val_loss -0.8738 
2025-04-18 05:20:21.619637: Pseudo dice [np.float32(0.916), np.float32(0.9439)] 
2025-04-18 05:20:21.620290: Epoch time: 193.66 s 
2025-04-18 05:20:23.479474:  
2025-04-18 05:20:23.479913: Epoch 920 
2025-04-18 05:20:23.480225: Current learning rate: 0.00103 
2025-04-18 05:23:37.212086: train_loss -0.9144 
2025-04-18 05:23:37.215599: val_loss -0.8689 
2025-04-18 05:23:37.215916: Pseudo dice [np.float32(0.8938), np.float32(0.9451)] 
2025-04-18 05:23:37.216217: Epoch time: 193.73 s 
2025-04-18 05:23:38.257853:  
2025-04-18 05:23:38.258307: Epoch 921 
2025-04-18 05:23:38.258622: Current learning rate: 0.00102 
2025-04-18 05:26:51.894394: train_loss -0.9173 
2025-04-18 05:26:51.895165: val_loss -0.8657 
2025-04-18 05:26:51.895442: Pseudo dice [np.float32(0.8982), np.float32(0.9496)] 
2025-04-18 05:26:51.895718: Epoch time: 193.64 s 
2025-04-18 05:26:52.934874:  
2025-04-18 05:26:52.935331: Epoch 922 
2025-04-18 05:26:52.935661: Current learning rate: 0.00101 
2025-04-18 05:30:06.482071: train_loss -0.9134 
2025-04-18 05:30:06.485409: val_loss -0.8587 
2025-04-18 05:30:06.485714: Pseudo dice [np.float32(0.8961), np.float32(0.9406)] 
2025-04-18 05:30:06.486015: Epoch time: 193.55 s 
2025-04-18 05:30:07.504506:  
2025-04-18 05:30:07.504916: Epoch 923 
2025-04-18 05:30:07.505235: Current learning rate: 0.001 
2025-04-18 05:33:21.492077: train_loss -0.9146 
2025-04-18 05:33:21.492828: val_loss -0.8672 
2025-04-18 05:33:21.493114: Pseudo dice [np.float32(0.8931), np.float32(0.9373)] 
2025-04-18 05:33:21.493394: Epoch time: 193.99 s 
2025-04-18 05:33:22.552289:  
2025-04-18 05:33:22.552709: Epoch 924 
2025-04-18 05:33:22.553025: Current learning rate: 0.00098 
2025-04-18 05:36:36.371641: train_loss -0.9173 
2025-04-18 05:36:36.374890: val_loss -0.8589 
2025-04-18 05:36:36.375178: Pseudo dice [np.float32(0.8905), np.float32(0.9413)] 
2025-04-18 05:36:36.375457: Epoch time: 193.82 s 
2025-04-18 05:36:37.402706:  
2025-04-18 05:36:37.403125: Epoch 925 
2025-04-18 05:36:37.403428: Current learning rate: 0.00097 
2025-04-18 05:39:50.894859: train_loss -0.9161 
2025-04-18 05:39:50.895543: val_loss -0.8607 
2025-04-18 05:39:50.895828: Pseudo dice [np.float32(0.9096), np.float32(0.9468)] 
2025-04-18 05:39:50.896112: Epoch time: 193.49 s 
2025-04-18 05:39:51.916577:  
2025-04-18 05:39:51.917012: Epoch 926 
2025-04-18 05:39:51.917334: Current learning rate: 0.00096 
2025-04-18 05:43:05.425425: train_loss -0.923 
2025-04-18 05:43:05.428746: val_loss -0.8554 
2025-04-18 05:43:05.429049: Pseudo dice [np.float32(0.9041), np.float32(0.9425)] 
2025-04-18 05:43:05.429332: Epoch time: 193.51 s 
2025-04-18 05:43:06.475189:  
2025-04-18 05:43:06.475618: Epoch 927 
2025-04-18 05:43:06.475941: Current learning rate: 0.00095 
2025-04-18 05:46:18.644317: train_loss -0.9223 
2025-04-18 05:46:18.644997: val_loss -0.8666 
2025-04-18 05:46:18.645276: Pseudo dice [np.float32(0.9015), np.float32(0.9519)] 
2025-04-18 05:46:18.645549: Epoch time: 192.17 s 
2025-04-18 05:46:19.681635:  
2025-04-18 05:46:19.682057: Epoch 928 
2025-04-18 05:46:19.682354: Current learning rate: 0.00094 
2025-04-18 05:49:30.403376: train_loss -0.9194 
2025-04-18 05:49:30.406563: val_loss -0.8661 
2025-04-18 05:49:30.406858: Pseudo dice [np.float32(0.9054), np.float32(0.9443)] 
2025-04-18 05:49:30.407147: Epoch time: 190.72 s 
2025-04-18 05:49:31.435504:  
2025-04-18 05:49:31.435949: Epoch 929 
2025-04-18 05:49:31.436266: Current learning rate: 0.00092 
2025-04-18 05:52:42.474496: train_loss -0.9151 
2025-04-18 05:52:42.475277: val_loss -0.87 
2025-04-18 05:52:42.475582: Pseudo dice [np.float32(0.9161), np.float32(0.9503)] 
2025-04-18 05:52:42.475873: Epoch time: 191.04 s 
2025-04-18 05:52:43.545923:  
2025-04-18 05:52:43.546345: Epoch 930 
2025-04-18 05:52:43.546675: Current learning rate: 0.00091 
2025-04-18 05:55:56.346463: train_loss -0.9088 
2025-04-18 05:55:56.349792: val_loss -0.881 
2025-04-18 05:55:56.350125: Pseudo dice [np.float32(0.916), np.float32(0.9467)] 
2025-04-18 05:55:56.350428: Epoch time: 192.8 s 
2025-04-18 05:55:57.451316:  
2025-04-18 05:55:57.451800: Epoch 931 
2025-04-18 05:55:57.452135: Current learning rate: 0.0009 
2025-04-18 05:59:11.324944: train_loss -0.9199 
2025-04-18 05:59:11.325634: val_loss -0.8578 
2025-04-18 05:59:11.325939: Pseudo dice [np.float32(0.9034), np.float32(0.94)] 
2025-04-18 05:59:11.326244: Epoch time: 193.88 s 
2025-04-18 05:59:12.410295:  
2025-04-18 05:59:12.410709: Epoch 932 
2025-04-18 05:59:12.411049: Current learning rate: 0.00089 
2025-04-18 06:02:26.792309: train_loss -0.9182 
2025-04-18 06:02:26.795638: val_loss -0.8828 
2025-04-18 06:02:26.795994: Pseudo dice [np.float32(0.9022), np.float32(0.9492)] 
2025-04-18 06:02:26.796304: Epoch time: 194.38 s 
2025-04-18 06:02:27.854752:  
2025-04-18 06:02:27.855222: Epoch 933 
2025-04-18 06:02:27.855558: Current learning rate: 0.00088 
2025-04-18 06:05:42.165084: train_loss -0.9126 
2025-04-18 06:05:42.165772: val_loss -0.8678 
2025-04-18 06:05:42.166089: Pseudo dice [np.float32(0.9092), np.float32(0.9476)] 
2025-04-18 06:05:42.166408: Epoch time: 194.31 s 
2025-04-18 06:05:43.266964:  
2025-04-18 06:05:43.267384: Epoch 934 
2025-04-18 06:05:43.267718: Current learning rate: 0.00087 
2025-04-18 06:08:57.366756: train_loss -0.9177 
2025-04-18 06:08:57.370236: val_loss -0.8726 
2025-04-18 06:08:57.370557: Pseudo dice [np.float32(0.9077), np.float32(0.9524)] 
2025-04-18 06:08:57.370848: Epoch time: 194.1 s 
2025-04-18 06:08:58.433664:  
2025-04-18 06:08:58.434087: Epoch 935 
2025-04-18 06:08:58.434397: Current learning rate: 0.00085 
2025-04-18 06:12:12.745596: train_loss -0.9125 
2025-04-18 06:12:12.746325: val_loss -0.8517 
2025-04-18 06:12:12.746711: Pseudo dice [np.float32(0.8997), np.float32(0.9324)] 
2025-04-18 06:12:12.747006: Epoch time: 194.31 s 
2025-04-18 06:12:13.811070:  
2025-04-18 06:12:13.811539: Epoch 936 
2025-04-18 06:12:13.811891: Current learning rate: 0.00084 
2025-04-18 06:15:27.452985: train_loss -0.912 
2025-04-18 06:15:27.456021: val_loss -0.8859 
2025-04-18 06:15:27.456316: Pseudo dice [np.float32(0.9172), np.float32(0.9486)] 
2025-04-18 06:15:27.456599: Epoch time: 193.64 s 
2025-04-18 06:15:28.518262:  
2025-04-18 06:15:28.518723: Epoch 937 
2025-04-18 06:15:28.519059: Current learning rate: 0.00083 
2025-04-18 06:18:42.330618: train_loss -0.9224 
2025-04-18 06:18:42.331286: val_loss -0.8804 
2025-04-18 06:18:42.331573: Pseudo dice [np.float32(0.9248), np.float32(0.9519)] 
2025-04-18 06:18:42.331865: Epoch time: 193.81 s 
2025-04-18 06:18:43.412707:  
2025-04-18 06:18:43.413140: Epoch 938 
2025-04-18 06:18:43.413449: Current learning rate: 0.00082 
2025-04-18 06:21:57.115899: train_loss -0.9204 
2025-04-18 06:21:57.118968: val_loss -0.8682 
2025-04-18 06:21:57.119299: Pseudo dice [np.float32(0.9034), np.float32(0.9439)] 
2025-04-18 06:21:57.119584: Epoch time: 193.71 s 
2025-04-18 06:21:58.172870:  
2025-04-18 06:21:58.173298: Epoch 939 
2025-04-18 06:21:58.173611: Current learning rate: 0.00081 
2025-04-18 06:25:12.135761: train_loss -0.9211 
2025-04-18 06:25:12.136451: val_loss -0.8698 
2025-04-18 06:25:12.136747: Pseudo dice [np.float32(0.9211), np.float32(0.9436)] 
2025-04-18 06:25:12.137036: Epoch time: 193.97 s 
2025-04-18 06:25:14.051427:  
2025-04-18 06:25:14.051889: Epoch 940 
2025-04-18 06:25:14.052215: Current learning rate: 0.00079 
2025-04-18 06:28:28.145568: train_loss -0.9165 
2025-04-18 06:28:28.148886: val_loss -0.8418 
2025-04-18 06:28:28.149201: Pseudo dice [np.float32(0.9032), np.float32(0.9367)] 
2025-04-18 06:28:28.149475: Epoch time: 194.1 s 
2025-04-18 06:28:29.181161:  
2025-04-18 06:28:29.181585: Epoch 941 
2025-04-18 06:28:29.181887: Current learning rate: 0.00078 
2025-04-18 06:31:43.064171: train_loss -0.9152 
2025-04-18 06:31:43.064959: val_loss -0.8853 
2025-04-18 06:31:43.065267: Pseudo dice [np.float32(0.9152), np.float32(0.9541)] 
2025-04-18 06:31:43.065559: Epoch time: 193.89 s 
2025-04-18 06:31:44.139455:  
2025-04-18 06:31:44.139874: Epoch 942 
2025-04-18 06:31:44.140196: Current learning rate: 0.00077 
2025-04-18 06:34:57.688093: train_loss -0.9213 
2025-04-18 06:34:57.691362: val_loss -0.8762 
2025-04-18 06:34:57.691664: Pseudo dice [np.float32(0.9081), np.float32(0.9369)] 
2025-04-18 06:34:57.692117: Epoch time: 193.55 s 
2025-04-18 06:34:58.737058:  
2025-04-18 06:34:58.737525: Epoch 943 
2025-04-18 06:34:58.737880: Current learning rate: 0.00076 
2025-04-18 06:38:12.145485: train_loss -0.9146 
2025-04-18 06:38:12.146153: val_loss -0.869 
2025-04-18 06:38:12.146454: Pseudo dice [np.float32(0.9091), np.float32(0.9388)] 
2025-04-18 06:38:12.146752: Epoch time: 193.41 s 
2025-04-18 06:38:13.206914:  
2025-04-18 06:38:13.207409: Epoch 944 
2025-04-18 06:38:13.207738: Current learning rate: 0.00075 
2025-04-18 06:41:26.768519: train_loss -0.9186 
2025-04-18 06:41:26.772005: val_loss -0.8696 
2025-04-18 06:41:26.772302: Pseudo dice [np.float32(0.9119), np.float32(0.9403)] 
2025-04-18 06:41:26.772675: Epoch time: 193.56 s 
2025-04-18 06:41:27.809220:  
2025-04-18 06:41:27.809671: Epoch 945 
2025-04-18 06:41:27.810026: Current learning rate: 0.00074 
2025-04-18 06:44:41.350696: train_loss -0.9217 
2025-04-18 06:44:41.351382: val_loss -0.8581 
2025-04-18 06:44:41.351669: Pseudo dice [np.float32(0.8966), np.float32(0.942)] 
2025-04-18 06:44:41.351964: Epoch time: 193.54 s 
2025-04-18 06:44:42.419888:  
2025-04-18 06:44:42.420327: Epoch 946 
2025-04-18 06:44:42.420631: Current learning rate: 0.00072 
2025-04-18 06:47:55.939285: train_loss -0.9155 
2025-04-18 06:47:55.942789: val_loss -0.8718 
2025-04-18 06:47:55.943095: Pseudo dice [np.float32(0.9057), np.float32(0.9445)] 
2025-04-18 06:47:55.943386: Epoch time: 193.52 s 
2025-04-18 06:47:56.982191:  
2025-04-18 06:47:56.982648: Epoch 947 
2025-04-18 06:47:56.982980: Current learning rate: 0.00071 
2025-04-18 06:51:10.757385: train_loss -0.9174 
2025-04-18 06:51:10.758039: val_loss -0.8838 
2025-04-18 06:51:10.758340: Pseudo dice [np.float32(0.9175), np.float32(0.9514)] 
2025-04-18 06:51:10.758636: Epoch time: 193.78 s 
2025-04-18 06:51:11.828241:  
2025-04-18 06:51:11.828706: Epoch 948 
2025-04-18 06:51:11.829047: Current learning rate: 0.0007 
2025-04-18 06:54:25.437254: train_loss -0.9184 
2025-04-18 06:54:25.440747: val_loss -0.8766 
2025-04-18 06:54:25.441051: Pseudo dice [np.float32(0.9105), np.float32(0.9468)] 
2025-04-18 06:54:25.441334: Epoch time: 193.61 s 
2025-04-18 06:54:26.532178:  
2025-04-18 06:54:26.532631: Epoch 949 
2025-04-18 06:54:26.532951: Current learning rate: 0.00069 
2025-04-18 06:57:40.429535: train_loss -0.9228 
2025-04-18 06:57:40.430267: val_loss -0.8516 
2025-04-18 06:57:40.430558: Pseudo dice [np.float32(0.9102), np.float32(0.9467)] 
2025-04-18 06:57:40.430964: Epoch time: 193.9 s 
2025-04-18 06:57:41.921444:  
2025-04-18 06:57:41.921903: Epoch 950 
2025-04-18 06:57:41.922217: Current learning rate: 0.00067 
2025-04-18 07:00:55.663782: train_loss -0.9164 
2025-04-18 07:00:55.667067: val_loss -0.8549 
2025-04-18 07:00:55.667370: Pseudo dice [np.float32(0.8935), np.float32(0.9271)] 
2025-04-18 07:00:55.667660: Epoch time: 193.74 s 
2025-04-18 07:00:56.725622:  
2025-04-18 07:00:56.726139: Epoch 951 
2025-04-18 07:00:56.726458: Current learning rate: 0.00066 
2025-04-18 07:04:10.596845: train_loss -0.9144 
2025-04-18 07:04:10.597465: val_loss -0.874 
2025-04-18 07:04:10.597750: Pseudo dice [np.float32(0.9198), np.float32(0.9463)] 
2025-04-18 07:04:10.598024: Epoch time: 193.87 s 
2025-04-18 07:04:11.647293:  
2025-04-18 07:04:11.647758: Epoch 952 
2025-04-18 07:04:11.648062: Current learning rate: 0.00065 
2025-04-18 07:07:25.371979: train_loss -0.9178 
2025-04-18 07:07:25.375401: val_loss -0.8504 
2025-04-18 07:07:25.375692: Pseudo dice [np.float32(0.8897), np.float32(0.9308)] 
2025-04-18 07:07:25.375988: Epoch time: 193.73 s 
2025-04-18 07:07:26.454255:  
2025-04-18 07:07:26.454704: Epoch 953 
2025-04-18 07:07:26.455038: Current learning rate: 0.00064 
2025-04-18 07:10:40.080704: train_loss -0.9171 
2025-04-18 07:10:40.081392: val_loss -0.8631 
2025-04-18 07:10:40.081667: Pseudo dice [np.float32(0.9044), np.float32(0.9394)] 
2025-04-18 07:10:40.081967: Epoch time: 193.63 s 
2025-04-18 07:10:41.138634:  
2025-04-18 07:10:41.139065: Epoch 954 
2025-04-18 07:10:41.139398: Current learning rate: 0.00063 
2025-04-18 07:13:54.790316: train_loss -0.9237 
2025-04-18 07:13:54.793842: val_loss -0.8658 
2025-04-18 07:13:54.794181: Pseudo dice [np.float32(0.9063), np.float32(0.9404)] 
2025-04-18 07:13:54.794471: Epoch time: 193.65 s 
2025-04-18 07:13:55.863836:  
2025-04-18 07:13:55.864307: Epoch 955 
2025-04-18 07:13:55.864614: Current learning rate: 0.00061 
2025-04-18 07:17:09.573541: train_loss -0.9217 
2025-04-18 07:17:09.574179: val_loss -0.8647 
2025-04-18 07:17:09.574458: Pseudo dice [np.float32(0.9103), np.float32(0.9478)] 
2025-04-18 07:17:09.574732: Epoch time: 193.71 s 
2025-04-18 07:17:10.623672:  
2025-04-18 07:17:10.624144: Epoch 956 
2025-04-18 07:17:10.624465: Current learning rate: 0.0006 
2025-04-18 07:20:24.362696: train_loss -0.9199 
2025-04-18 07:20:24.366316: val_loss -0.8747 
2025-04-18 07:20:24.366810: Pseudo dice [np.float32(0.914), np.float32(0.9465)] 
2025-04-18 07:20:24.367270: Epoch time: 193.74 s 
2025-04-18 07:20:25.435698:  
2025-04-18 07:20:25.436164: Epoch 957 
2025-04-18 07:20:25.436498: Current learning rate: 0.00059 
2025-04-18 07:23:38.900036: train_loss -0.9239 
2025-04-18 07:23:38.900677: val_loss -0.8704 
2025-04-18 07:23:38.900968: Pseudo dice [np.float32(0.9125), np.float32(0.9469)] 
2025-04-18 07:23:38.901252: Epoch time: 193.47 s 
2025-04-18 07:23:39.969210:  
2025-04-18 07:23:39.969656: Epoch 958 
2025-04-18 07:23:39.970000: Current learning rate: 0.00058 
2025-04-18 07:26:53.476830: train_loss -0.9247 
2025-04-18 07:26:53.479883: val_loss -0.8649 
2025-04-18 07:26:53.480184: Pseudo dice [np.float32(0.9152), np.float32(0.9495)] 
2025-04-18 07:26:53.480465: Epoch time: 193.51 s 
2025-04-18 07:26:54.559018:  
2025-04-18 07:26:54.559485: Epoch 959 
2025-04-18 07:26:54.559834: Current learning rate: 0.00056 
2025-04-18 07:30:08.004140: train_loss -0.9186 
2025-04-18 07:30:08.004810: val_loss -0.8692 
2025-04-18 07:30:08.005121: Pseudo dice [np.float32(0.9063), np.float32(0.9502)] 
2025-04-18 07:30:08.005432: Epoch time: 193.45 s 
2025-04-18 07:30:09.971618:  
2025-04-18 07:30:09.972069: Epoch 960 
2025-04-18 07:30:09.972399: Current learning rate: 0.00055 
2025-04-18 07:33:23.405082: train_loss -0.9206 
2025-04-18 07:33:23.408639: val_loss -0.867 
2025-04-18 07:33:23.408955: Pseudo dice [np.float32(0.9149), np.float32(0.9444)] 
2025-04-18 07:33:23.409238: Epoch time: 193.44 s 
2025-04-18 07:33:24.479574:  
2025-04-18 07:33:24.480016: Epoch 961 
2025-04-18 07:33:24.480335: Current learning rate: 0.00054 
2025-04-18 07:36:37.929406: train_loss -0.9198 
2025-04-18 07:36:37.930197: val_loss -0.8492 
2025-04-18 07:36:37.930483: Pseudo dice [np.float32(0.8905), np.float32(0.9362)] 
2025-04-18 07:36:37.930782: Epoch time: 193.45 s 
2025-04-18 07:36:39.007169:  
2025-04-18 07:36:39.007634: Epoch 962 
2025-04-18 07:36:39.007963: Current learning rate: 0.00053 
2025-04-18 07:39:52.358499: train_loss -0.9175 
2025-04-18 07:39:52.361827: val_loss -0.8766 
2025-04-18 07:39:52.362120: Pseudo dice [np.float32(0.9051), np.float32(0.9426)] 
2025-04-18 07:39:52.362403: Epoch time: 193.35 s 
2025-04-18 07:39:53.445212:  
2025-04-18 07:39:53.445622: Epoch 963 
2025-04-18 07:39:53.445930: Current learning rate: 0.00051 
2025-04-18 07:43:06.896610: train_loss -0.9198 
2025-04-18 07:43:06.897338: val_loss -0.8702 
2025-04-18 07:43:06.897625: Pseudo dice [np.float32(0.9079), np.float32(0.9364)] 
2025-04-18 07:43:06.897918: Epoch time: 193.45 s 
2025-04-18 07:43:07.986413:  
2025-04-18 07:43:07.986846: Epoch 964 
2025-04-18 07:43:07.987157: Current learning rate: 0.0005 
2025-04-18 07:46:21.424553: train_loss -0.9172 
2025-04-18 07:46:21.427640: val_loss -0.865 
2025-04-18 07:46:21.427926: Pseudo dice [np.float32(0.9094), np.float32(0.9449)] 
2025-04-18 07:46:21.428193: Epoch time: 193.44 s 
2025-04-18 07:46:22.502700:  
2025-04-18 07:46:22.503150: Epoch 965 
2025-04-18 07:46:22.503453: Current learning rate: 0.00049 
2025-04-18 07:49:36.028508: train_loss -0.9196 
2025-04-18 07:49:36.029224: val_loss -0.8785 
2025-04-18 07:49:36.029524: Pseudo dice [np.float32(0.9095), np.float32(0.9414)] 
2025-04-18 07:49:36.029838: Epoch time: 193.53 s 
2025-04-18 07:49:37.116263:  
2025-04-18 07:49:37.116725: Epoch 966 
2025-04-18 07:49:37.117050: Current learning rate: 0.00048 
2025-04-18 07:52:50.703385: train_loss -0.92 
2025-04-18 07:52:50.706861: val_loss -0.8839 
2025-04-18 07:52:50.707164: Pseudo dice [np.float32(0.9163), np.float32(0.9467)] 
2025-04-18 07:52:50.707444: Epoch time: 193.59 s 
2025-04-18 07:52:51.805232:  
2025-04-18 07:52:51.805684: Epoch 967 
2025-04-18 07:52:51.806006: Current learning rate: 0.00046 
2025-04-18 07:56:05.500976: train_loss -0.9177 
2025-04-18 07:56:05.501650: val_loss -0.8654 
2025-04-18 07:56:05.501980: Pseudo dice [np.float32(0.9111), np.float32(0.9423)] 
2025-04-18 07:56:05.502287: Epoch time: 193.7 s 
2025-04-18 07:56:06.590944:  
2025-04-18 07:56:06.591379: Epoch 968 
2025-04-18 07:56:06.591707: Current learning rate: 0.00045 
2025-04-18 07:59:20.283033: train_loss -0.921 
2025-04-18 07:59:20.286430: val_loss -0.8749 
2025-04-18 07:59:20.286719: Pseudo dice [np.float32(0.9013), np.float32(0.9501)] 
2025-04-18 07:59:20.287013: Epoch time: 193.69 s 
2025-04-18 07:59:21.361612:  
2025-04-18 07:59:21.362159: Epoch 969 
2025-04-18 07:59:21.362469: Current learning rate: 0.00044 
2025-04-18 08:02:34.976257: train_loss -0.9206 
2025-04-18 08:02:34.977090: val_loss -0.8557 
2025-04-18 08:02:34.977419: Pseudo dice [np.float32(0.9129), np.float32(0.943)] 
2025-04-18 08:02:34.977726: Epoch time: 193.62 s 
2025-04-18 08:02:36.118255:  
2025-04-18 08:02:36.118738: Epoch 970 
2025-04-18 08:02:36.119087: Current learning rate: 0.00043 
2025-04-18 08:05:49.685500: train_loss -0.9176 
2025-04-18 08:05:49.688945: val_loss -0.8773 
2025-04-18 08:05:49.689292: Pseudo dice [np.float32(0.9195), np.float32(0.9508)] 
2025-04-18 08:05:49.689582: Epoch time: 193.57 s 
2025-04-18 08:05:50.788504:  
2025-04-18 08:05:50.789008: Epoch 971 
2025-04-18 08:05:50.789335: Current learning rate: 0.00041 
2025-04-18 08:09:04.375809: train_loss -0.9174 
2025-04-18 08:09:04.376464: val_loss -0.874 
2025-04-18 08:09:04.376739: Pseudo dice [np.float32(0.9095), np.float32(0.9468)] 
2025-04-18 08:09:04.377024: Epoch time: 193.59 s 
2025-04-18 08:09:05.462891:  
2025-04-18 08:09:05.463328: Epoch 972 
2025-04-18 08:09:05.463621: Current learning rate: 0.0004 
2025-04-18 08:12:18.989845: train_loss -0.9185 
2025-04-18 08:12:18.993021: val_loss -0.8766 
2025-04-18 08:12:18.993335: Pseudo dice [np.float32(0.9117), np.float32(0.9462)] 
2025-04-18 08:12:18.993621: Epoch time: 193.53 s 
2025-04-18 08:12:20.112093:  
2025-04-18 08:12:20.112544: Epoch 973 
2025-04-18 08:12:20.112884: Current learning rate: 0.00039 
2025-04-18 08:15:33.727073: train_loss -0.9236 
2025-04-18 08:15:33.727902: val_loss -0.8831 
2025-04-18 08:15:33.728198: Pseudo dice [np.float32(0.9024), np.float32(0.9462)] 
2025-04-18 08:15:33.728484: Epoch time: 193.62 s 
2025-04-18 08:15:34.828408:  
2025-04-18 08:15:34.828855: Epoch 974 
2025-04-18 08:15:34.829167: Current learning rate: 0.00037 
2025-04-18 08:18:48.641782: train_loss -0.9205 
2025-04-18 08:18:48.645053: val_loss -0.8812 
2025-04-18 08:18:48.645350: Pseudo dice [np.float32(0.9132), np.float32(0.9437)] 
2025-04-18 08:18:48.645631: Epoch time: 193.82 s 
2025-04-18 08:18:49.733640:  
2025-04-18 08:18:49.734064: Epoch 975 
2025-04-18 08:18:49.734378: Current learning rate: 0.00036 
2025-04-18 08:22:03.610115: train_loss -0.9215 
2025-04-18 08:22:03.610805: val_loss -0.8772 
2025-04-18 08:22:03.611077: Pseudo dice [np.float32(0.9028), np.float32(0.9437)] 
2025-04-18 08:22:03.611350: Epoch time: 193.88 s 
2025-04-18 08:22:04.699553:  
2025-04-18 08:22:04.700005: Epoch 976 
2025-04-18 08:22:04.700305: Current learning rate: 0.00035 
2025-04-18 08:25:18.816206: train_loss -0.9243 
2025-04-18 08:25:18.819480: val_loss -0.8717 
2025-04-18 08:25:18.819815: Pseudo dice [np.float32(0.9188), np.float32(0.9377)] 
2025-04-18 08:25:18.820102: Epoch time: 194.12 s 
2025-04-18 08:25:19.970090:  
2025-04-18 08:25:19.970523: Epoch 977 
2025-04-18 08:25:19.970845: Current learning rate: 0.00034 
2025-04-18 08:28:33.835818: train_loss -0.9187 
2025-04-18 08:28:33.836895: val_loss -0.8559 
2025-04-18 08:28:33.837188: Pseudo dice [np.float32(0.9053), np.float32(0.9375)] 
2025-04-18 08:28:33.837476: Epoch time: 193.87 s 
2025-04-18 08:28:34.919903:  
2025-04-18 08:28:34.920416: Epoch 978 
2025-04-18 08:28:34.920751: Current learning rate: 0.00032 
2025-04-18 08:31:48.999810: train_loss -0.9216 
2025-04-18 08:31:49.003289: val_loss -0.8685 
2025-04-18 08:31:49.003592: Pseudo dice [np.float32(0.9146), np.float32(0.9407)] 
2025-04-18 08:31:49.003884: Epoch time: 194.08 s 
2025-04-18 08:31:50.083895:  
2025-04-18 08:31:50.084295: Epoch 979 
2025-04-18 08:31:50.084607: Current learning rate: 0.00031 
2025-04-18 08:35:04.014712: train_loss -0.9207 
2025-04-18 08:35:04.015426: val_loss -0.8811 
2025-04-18 08:35:04.015746: Pseudo dice [np.float32(0.9077), np.float32(0.9415)] 
2025-04-18 08:35:04.016042: Epoch time: 193.93 s 
2025-04-18 08:35:06.026188:  
2025-04-18 08:35:06.026654: Epoch 980 
2025-04-18 08:35:06.026990: Current learning rate: 0.0003 
2025-04-18 08:38:20.101385: train_loss -0.9184 
2025-04-18 08:38:20.104515: val_loss -0.8724 
2025-04-18 08:38:20.104809: Pseudo dice [np.float32(0.9126), np.float32(0.9464)] 
2025-04-18 08:38:20.105089: Epoch time: 194.08 s 
2025-04-18 08:38:21.174769:  
2025-04-18 08:38:21.175237: Epoch 981 
2025-04-18 08:38:21.175550: Current learning rate: 0.00028 
2025-04-18 08:41:35.965513: train_loss -0.9195 
2025-04-18 08:41:35.966227: val_loss -0.8727 
2025-04-18 08:41:35.966509: Pseudo dice [np.float32(0.9205), np.float32(0.9482)] 
2025-04-18 08:41:35.966796: Epoch time: 194.79 s 
2025-04-18 08:41:37.038053:  
2025-04-18 08:41:37.038465: Epoch 982 
2025-04-18 08:41:37.038779: Current learning rate: 0.00027 
2025-04-18 08:44:51.734691: train_loss -0.916 
2025-04-18 08:44:51.738041: val_loss -0.8808 
2025-04-18 08:44:51.738351: Pseudo dice [np.float32(0.9128), np.float32(0.9501)] 
2025-04-18 08:44:51.738639: Epoch time: 194.7 s 
2025-04-18 08:44:52.806778:  
2025-04-18 08:44:52.807218: Epoch 983 
2025-04-18 08:44:52.807532: Current learning rate: 0.00026 
2025-04-18 08:48:07.188425: train_loss -0.9229 
2025-04-18 08:48:07.189116: val_loss -0.8547 
2025-04-18 08:48:07.189394: Pseudo dice [np.float32(0.9062), np.float32(0.9455)] 
2025-04-18 08:48:07.189686: Epoch time: 194.38 s 
2025-04-18 08:48:08.270170:  
2025-04-18 08:48:08.270686: Epoch 984 
2025-04-18 08:48:08.271024: Current learning rate: 0.00024 
2025-04-18 08:51:22.531248: train_loss -0.9261 
2025-04-18 08:51:22.534637: val_loss -0.8902 
2025-04-18 08:51:22.534957: Pseudo dice [np.float32(0.9184), np.float32(0.9529)] 
2025-04-18 08:51:22.535247: Epoch time: 194.26 s 
2025-04-18 08:51:23.613774:  
2025-04-18 08:51:23.614296: Epoch 985 
2025-04-18 08:51:23.614617: Current learning rate: 0.00023 
2025-04-18 08:54:37.906112: train_loss -0.9214 
2025-04-18 08:54:37.906860: val_loss -0.8668 
2025-04-18 08:54:37.907179: Pseudo dice [np.float32(0.9224), np.float32(0.9466)] 
2025-04-18 08:54:37.907466: Epoch time: 194.29 s 
2025-04-18 08:54:38.985517:  
2025-04-18 08:54:38.986033: Epoch 986 
2025-04-18 08:54:38.986356: Current learning rate: 0.00021 
2025-04-18 08:57:53.343813: train_loss -0.922 
2025-04-18 08:57:53.346820: val_loss -0.8596 
2025-04-18 08:57:53.347139: Pseudo dice [np.float32(0.9089), np.float32(0.9487)] 
2025-04-18 08:57:53.347432: Epoch time: 194.36 s 
2025-04-18 08:57:54.420431:  
2025-04-18 08:57:54.420851: Epoch 987 
2025-04-18 08:57:54.421174: Current learning rate: 0.0002 
2025-04-18 09:01:09.259890: train_loss -0.9251 
2025-04-18 09:01:09.260611: val_loss -0.8559 
2025-04-18 09:01:09.260912: Pseudo dice [np.float32(0.9034), np.float32(0.9378)] 
2025-04-18 09:01:09.261234: Epoch time: 194.84 s 
2025-04-18 09:01:10.347111:  
2025-04-18 09:01:10.347564: Epoch 988 
2025-04-18 09:01:10.347909: Current learning rate: 0.00019 
2025-04-18 09:04:25.290270: train_loss -0.9277 
2025-04-18 09:04:25.293144: val_loss -0.8686 
2025-04-18 09:04:25.293439: Pseudo dice [np.float32(0.9029), np.float32(0.9483)] 
2025-04-18 09:04:25.293718: Epoch time: 194.95 s 
2025-04-18 09:04:26.360254:  
2025-04-18 09:04:26.360973: Epoch 989 
2025-04-18 09:04:26.361301: Current learning rate: 0.00017 
2025-04-18 09:07:41.817006: train_loss -0.9242 
2025-04-18 09:07:41.817768: val_loss -0.8816 
2025-04-18 09:07:41.818054: Pseudo dice [np.float32(0.9157), np.float32(0.9433)] 
2025-04-18 09:07:41.818336: Epoch time: 195.46 s 
2025-04-18 09:07:42.874058:  
2025-04-18 09:07:42.874493: Epoch 990 
2025-04-18 09:07:42.874840: Current learning rate: 0.00016 
2025-04-18 09:10:57.957019: train_loss -0.9239 
2025-04-18 09:10:57.960499: val_loss -0.8762 
2025-04-18 09:10:57.960812: Pseudo dice [np.float32(0.9087), np.float32(0.9412)] 
2025-04-18 09:10:57.961114: Epoch time: 195.09 s 
2025-04-18 09:10:59.020512:  
2025-04-18 09:10:59.020998: Epoch 991 
2025-04-18 09:10:59.021312: Current learning rate: 0.00014 
2025-04-18 09:14:13.878890: train_loss -0.9248 
2025-04-18 09:14:13.879534: val_loss -0.8549 
2025-04-18 09:14:13.879822: Pseudo dice [np.float32(0.9062), np.float32(0.934)] 
2025-04-18 09:14:13.880123: Epoch time: 194.86 s 
2025-04-18 09:14:14.970050:  
2025-04-18 09:14:14.970500: Epoch 992 
2025-04-18 09:14:14.970830: Current learning rate: 0.00013 
2025-04-18 09:17:29.577486: train_loss -0.9213 
2025-04-18 09:17:29.580700: val_loss -0.893 
2025-04-18 09:17:29.581030: Pseudo dice [np.float32(0.9262), np.float32(0.951)] 
2025-04-18 09:17:29.581327: Epoch time: 194.61 s 
2025-04-18 09:17:30.661293:  
2025-04-18 09:17:30.661707: Epoch 993 
2025-04-18 09:17:30.662030: Current learning rate: 0.00011 
2025-04-18 09:20:45.151803: train_loss -0.9258 
2025-04-18 09:20:45.152439: val_loss -0.8878 
2025-04-18 09:20:45.152718: Pseudo dice [np.float32(0.9316), np.float32(0.9493)] 
2025-04-18 09:20:45.153016: Epoch time: 194.49 s 
2025-04-18 09:20:46.240660:  
2025-04-18 09:20:46.241107: Epoch 994 
2025-04-18 09:20:46.241433: Current learning rate: 0.0001 
2025-04-18 09:24:00.486404: train_loss -0.9265 
2025-04-18 09:24:00.489645: val_loss -0.8852 
2025-04-18 09:24:00.489987: Pseudo dice [np.float32(0.9138), np.float32(0.9515)] 
2025-04-18 09:24:00.490286: Epoch time: 194.25 s 
2025-04-18 09:24:01.563661:  
2025-04-18 09:24:01.564086: Epoch 995 
2025-04-18 09:24:01.564401: Current learning rate: 8e-05 
2025-04-18 09:27:16.197821: train_loss -0.9203 
2025-04-18 09:27:16.198604: val_loss -0.8581 
2025-04-18 09:27:16.198903: Pseudo dice [np.float32(0.8992), np.float32(0.937)] 
2025-04-18 09:27:16.199189: Epoch time: 194.64 s 
2025-04-18 09:27:17.317750:  
2025-04-18 09:27:17.318217: Epoch 996 
2025-04-18 09:27:17.318529: Current learning rate: 7e-05 
2025-04-18 09:30:31.554271: train_loss -0.924 
2025-04-18 09:30:31.557384: val_loss -0.869 
2025-04-18 09:30:31.557665: Pseudo dice [np.float32(0.8986), np.float32(0.9302)] 
2025-04-18 09:30:31.557953: Epoch time: 194.24 s 
2025-04-18 09:30:32.627423:  
2025-04-18 09:30:32.627940: Epoch 997 
2025-04-18 09:30:32.628292: Current learning rate: 5e-05 
2025-04-18 09:33:47.023471: train_loss -0.9244 
2025-04-18 09:33:47.024201: val_loss -0.8794 
2025-04-18 09:33:47.024501: Pseudo dice [np.float32(0.9222), np.float32(0.9502)] 
2025-04-18 09:33:47.024791: Epoch time: 194.4 s 
2025-04-18 09:33:48.095531:  
2025-04-18 09:33:48.095986: Epoch 998 
2025-04-18 09:33:48.096312: Current learning rate: 4e-05 
2025-04-18 09:37:02.741236: train_loss -0.9263 
2025-04-18 09:37:02.744399: val_loss -0.8782 
2025-04-18 09:37:02.744680: Pseudo dice [np.float32(0.9138), np.float32(0.9472)] 
2025-04-18 09:37:02.744964: Epoch time: 194.65 s 
2025-04-18 09:37:03.825806:  
2025-04-18 09:37:03.826231: Epoch 999 
2025-04-18 09:37:03.826538: Current learning rate: 2e-05 
2025-04-18 09:40:17.756659: train_loss -0.922 
2025-04-18 09:40:17.757328: val_loss -0.8806 
2025-04-18 09:40:17.757609: Pseudo dice [np.float32(0.9134), np.float32(0.9465)] 
2025-04-18 09:40:17.757881: Epoch time: 193.93 s 
2025-04-18 09:40:20.201078: Training done. 
2025-04-18 09:40:20.247387: Using splits from existing split file: /physical_sciences/DEEP-PSMA/GTRC_Baseline/nnUNet_data/preprocessed/Dataset801_PSMA_PET/splits_final.json 
2025-04-18 09:40:20.248062: The split file contains 5 splits. 
2025-04-18 09:40:20.248637: Desired fold for training: 0 
2025-04-18 09:40:20.248935: This split has 80 training and 20 validation cases. 
2025-04-18 09:40:20.249410: predicting train_0005 
2025-04-18 09:40:20.403323: train_0005, shape torch.Size([2, 144, 335, 144]), rank 0 
2025-04-18 09:40:58.818968: predicting train_0010 
2025-04-18 09:40:59.125823: train_0010, shape torch.Size([2, 213, 336, 213]), rank 0 
2025-04-18 09:41:21.844601: predicting train_0014 
2025-04-18 09:41:22.128665: train_0014, shape torch.Size([2, 213, 308, 213]), rank 0 
2025-04-18 09:41:44.993356: predicting train_0021 
2025-04-18 09:41:45.112190: train_0021, shape torch.Size([2, 144, 335, 144]), rank 0 
2025-04-18 09:41:55.358186: predicting train_0026 
2025-04-18 09:41:55.479408: train_0026, shape torch.Size([2, 144, 335, 144]), rank 0 
2025-04-18 09:42:05.741360: predicting train_0029 
2025-04-18 09:42:06.004227: train_0029, shape torch.Size([2, 213, 306, 213]), rank 0 
2025-04-18 09:42:28.987133: predicting train_0034 
2025-04-18 09:42:29.124256: train_0034, shape torch.Size([2, 151, 312, 151]), rank 0 
2025-04-18 09:42:39.441303: predicting train_0036 
2025-04-18 09:42:39.559923: train_0036, shape torch.Size([2, 144, 335, 144]), rank 0 
2025-04-18 09:42:49.875071: predicting train_0041 
2025-04-18 09:42:50.218846: train_0041, shape torch.Size([2, 213, 309, 213]), rank 0 
2025-04-18 09:43:13.341311: predicting train_0043 
2025-04-18 09:43:13.590868: train_0043, shape torch.Size([2, 194, 323, 194]), rank 0 
2025-04-18 09:43:36.770915: predicting train_0050 
2025-04-18 09:43:36.892619: train_0050, shape torch.Size([2, 144, 335, 144]), rank 0 
2025-04-18 09:43:47.258722: predicting train_0052 
2025-04-18 09:43:47.387926: train_0052, shape torch.Size([2, 144, 335, 144]), rank 0 
2025-04-18 09:43:57.743109: predicting train_0061 
2025-04-18 09:43:57.887010: train_0061, shape torch.Size([2, 144, 371, 144]), rank 0 
2025-04-18 09:44:08.228364: predicting train_0064 
2025-04-18 09:44:08.518510: train_0064, shape torch.Size([2, 183, 429, 183]), rank 0 
2025-04-18 09:44:39.520482: predicting train_0066 
2025-04-18 09:44:39.651197: train_0066, shape torch.Size([2, 144, 335, 144]), rank 0 
2025-04-18 09:44:50.023151: predicting train_0070 
2025-04-18 09:44:50.141233: train_0070, shape torch.Size([2, 144, 335, 144]), rank 0 
2025-04-18 09:45:00.509715: predicting train_0076 
2025-04-18 09:45:00.629341: train_0076, shape torch.Size([2, 144, 335, 144]), rank 0 
2025-04-18 09:45:11.000575: predicting train_0079 
2025-04-18 09:45:11.294682: train_0079, shape torch.Size([2, 213, 330, 213]), rank 0 
2025-04-18 09:45:34.529310: predicting train_0087 
2025-04-18 09:45:34.846942: train_0087, shape torch.Size([2, 213, 336, 213]), rank 0 
2025-04-18 09:45:58.099211: predicting train_0089 
2025-04-18 09:45:58.389082: train_0089, shape torch.Size([2, 213, 298, 213]), rank 0 
2025-04-18 09:46:33.294232: Validation complete 
2025-04-18 09:46:33.294595: Mean Validation Dice:  0.8988925085068847 
