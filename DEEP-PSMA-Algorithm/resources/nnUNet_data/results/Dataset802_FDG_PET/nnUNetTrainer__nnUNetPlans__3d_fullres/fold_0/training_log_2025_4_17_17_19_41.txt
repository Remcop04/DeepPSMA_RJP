
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-04-17 17:19:43.105689: Using torch.compile... 
2025-04-17 17:19:46.395440: do_dummy_2d_data_aug: False 
2025-04-17 17:19:46.397070: Using splits from existing split file: /physical_sciences/DEEP-PSMA/GTRC_Baseline/nnUNet_data/preprocessed/Dataset802_FDG_PET/splits_final.json 
2025-04-17 17:19:46.410599: The split file contains 5 splits. 
2025-04-17 17:19:46.410704: Desired fold for training: 0 
2025-04-17 17:19:46.410801: This split has 80 training and 20 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 192, 112], 'median_image_size_in_voxels': [192.0, 335.0, 192.0], 'spacing': [3.6458332538604736, 3.2699999809265137, 3.6458332538604736], 'normalization_schemes': ['NoNormalization', 'CTNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset802_FDG_PET', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.6458332538604736, 3.2699999809265137, 3.6458332538604736], 'original_median_shape_after_transp': [192, 335, 192], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 107.86343383789062, 'mean': 2.1329498291015625, 'median': 1.7018816471099854, 'min': 1.0, 'percentile_00_5': 1.0032026767730713, 'percentile_99_5': 14.15305233001709, 'std': 2.004286766052246}, '1': {'max': 3071.0, 'mean': 73.27325439453125, 'median': 39.0, 'min': -2352.0, 'percentile_00_5': -294.0, 'percentile_99_5': 1039.0, 'std': 170.28688049316406}}} 
 
2025-04-17 17:20:03.860328: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-04-17 17:20:03.894435:  
2025-04-17 17:20:03.895132: Epoch 800 
2025-04-17 17:20:03.895695: Current learning rate: 0.00235 
2025-04-17 17:24:55.968280: train_loss -0.8279 
2025-04-17 17:24:55.973055: val_loss -0.7791 
2025-04-17 17:24:55.973370: Pseudo dice [np.float32(0.8785), np.float32(0.9231)] 
2025-04-17 17:24:55.973656: Epoch time: 292.08 s 
2025-04-17 17:24:57.147076:  
2025-04-17 17:24:57.147602: Epoch 801 
2025-04-17 17:24:57.147933: Current learning rate: 0.00234 
2025-04-17 17:28:29.245428: train_loss -0.8235 
2025-04-17 17:28:29.246166: val_loss -0.7681 
2025-04-17 17:28:29.246468: Pseudo dice [np.float32(0.808), np.float32(0.9202)] 
2025-04-17 17:28:29.246778: Epoch time: 212.1 s 
2025-04-17 17:28:30.390607:  
2025-04-17 17:28:30.391062: Epoch 802 
2025-04-17 17:28:30.391374: Current learning rate: 0.00233 
2025-04-17 17:32:03.858984: train_loss -0.8271 
2025-04-17 17:32:03.862613: val_loss -0.7683 
2025-04-17 17:32:03.862983: Pseudo dice [np.float32(0.8482), np.float32(0.9242)] 
2025-04-17 17:32:03.863309: Epoch time: 213.47 s 
2025-04-17 17:32:05.031779:  
2025-04-17 17:32:05.032296: Epoch 803 
2025-04-17 17:32:05.032629: Current learning rate: 0.00232 
2025-04-17 17:35:42.913892: train_loss -0.8211 
2025-04-17 17:35:42.914728: val_loss -0.7761 
2025-04-17 17:35:42.915025: Pseudo dice [np.float32(0.8595), np.float32(0.9165)] 
2025-04-17 17:35:42.915324: Epoch time: 217.88 s 
2025-04-17 17:35:44.085802:  
2025-04-17 17:35:44.086363: Epoch 804 
2025-04-17 17:35:44.086683: Current learning rate: 0.00231 
2025-04-17 17:39:23.130503: train_loss -0.8242 
2025-04-17 17:39:23.134049: val_loss -0.7765 
2025-04-17 17:39:23.134347: Pseudo dice [np.float32(0.8838), np.float32(0.9181)] 
2025-04-17 17:39:23.134634: Epoch time: 219.05 s 
2025-04-17 17:39:24.294132:  
2025-04-17 17:39:24.294604: Epoch 805 
2025-04-17 17:39:24.294931: Current learning rate: 0.0023 
2025-04-17 17:43:02.970782: train_loss -0.8299 
2025-04-17 17:43:02.971549: val_loss -0.7848 
2025-04-17 17:43:02.971830: Pseudo dice [np.float32(0.8877), np.float32(0.9144)] 
2025-04-17 17:43:02.972114: Epoch time: 218.68 s 
2025-04-17 17:43:04.112531:  
2025-04-17 17:43:04.113148: Epoch 806 
2025-04-17 17:43:04.113480: Current learning rate: 0.00229 
2025-04-17 17:46:42.771526: train_loss -0.8232 
2025-04-17 17:46:42.774965: val_loss -0.7577 
2025-04-17 17:46:42.775295: Pseudo dice [np.float32(0.8621), np.float32(0.9104)] 
2025-04-17 17:46:42.775584: Epoch time: 218.66 s 
2025-04-17 17:46:43.936233:  
2025-04-17 17:46:43.936810: Epoch 807 
2025-04-17 17:46:43.937149: Current learning rate: 0.00228 
2025-04-17 17:50:22.932080: train_loss -0.8227 
2025-04-17 17:50:22.932878: val_loss -0.7781 
2025-04-17 17:50:22.933162: Pseudo dice [np.float32(0.8625), np.float32(0.9299)] 
2025-04-17 17:50:22.933432: Epoch time: 219.0 s 
2025-04-17 17:50:24.080129:  
2025-04-17 17:50:24.080663: Epoch 808 
2025-04-17 17:50:24.080987: Current learning rate: 0.00226 
2025-04-17 17:54:03.585912: train_loss -0.8284 
2025-04-17 17:54:03.590209: val_loss -0.7821 
2025-04-17 17:54:03.590516: Pseudo dice [np.float32(0.8708), np.float32(0.9084)] 
2025-04-17 17:54:03.590842: Epoch time: 219.51 s 
2025-04-17 17:54:04.757697:  
2025-04-17 17:54:04.758264: Epoch 809 
2025-04-17 17:54:04.758584: Current learning rate: 0.00225 
2025-04-17 17:57:43.630008: train_loss -0.8353 
2025-04-17 17:57:43.630870: val_loss -0.7821 
2025-04-17 17:57:43.631149: Pseudo dice [np.float32(0.8664), np.float32(0.9288)] 
2025-04-17 17:57:43.631417: Epoch time: 218.87 s 
2025-04-17 17:57:44.785397:  
2025-04-17 17:57:44.785862: Epoch 810 
2025-04-17 17:57:44.786167: Current learning rate: 0.00224 
2025-04-17 18:01:23.580512: train_loss -0.8324 
2025-04-17 18:01:23.584263: val_loss -0.8043 
2025-04-17 18:01:23.584614: Pseudo dice [np.float32(0.8767), np.float32(0.9304)] 
2025-04-17 18:01:23.584919: Epoch time: 218.8 s 
2025-04-17 18:01:25.482781:  
2025-04-17 18:01:25.483265: Epoch 811 
2025-04-17 18:01:25.483577: Current learning rate: 0.00223 
2025-04-17 18:05:03.974847: train_loss -0.8355 
2025-04-17 18:05:03.975686: val_loss -0.7272 
2025-04-17 18:05:03.975986: Pseudo dice [np.float32(0.8435), np.float32(0.9018)] 
2025-04-17 18:05:03.976310: Epoch time: 218.49 s 
2025-04-17 18:05:05.173450:  
2025-04-17 18:05:05.174027: Epoch 812 
2025-04-17 18:05:05.174359: Current learning rate: 0.00222 
2025-04-17 18:08:44.033559: train_loss -0.8305 
2025-04-17 18:08:44.034377: val_loss -0.7273 
2025-04-17 18:08:44.034660: Pseudo dice [np.float32(0.8284), np.float32(0.9116)] 
2025-04-17 18:08:44.034997: Epoch time: 218.86 s 
2025-04-17 18:08:45.218947:  
2025-04-17 18:08:45.219475: Epoch 813 
2025-04-17 18:08:45.219809: Current learning rate: 0.00221 
2025-04-17 18:12:24.339810: train_loss -0.8293 
2025-04-17 18:12:24.340665: val_loss -0.7681 
2025-04-17 18:12:24.340991: Pseudo dice [np.float32(0.8704), np.float32(0.8999)] 
2025-04-17 18:12:24.341307: Epoch time: 219.12 s 
2025-04-17 18:12:25.484474:  
2025-04-17 18:12:25.485037: Epoch 814 
2025-04-17 18:12:25.485368: Current learning rate: 0.0022 
2025-04-17 18:16:04.285849: train_loss -0.8308 
2025-04-17 18:16:04.286626: val_loss -0.781 
2025-04-17 18:16:04.286919: Pseudo dice [np.float32(0.8605), np.float32(0.9245)] 
2025-04-17 18:16:04.287225: Epoch time: 218.8 s 
2025-04-17 18:16:05.413956:  
2025-04-17 18:16:05.414559: Epoch 815 
2025-04-17 18:16:05.414908: Current learning rate: 0.00219 
2025-04-17 18:19:44.094601: train_loss -0.8356 
2025-04-17 18:19:44.095475: val_loss -0.7854 
2025-04-17 18:19:44.095779: Pseudo dice [np.float32(0.8697), np.float32(0.9169)] 
2025-04-17 18:19:44.096162: Epoch time: 218.68 s 
2025-04-17 18:19:45.250530:  
2025-04-17 18:19:45.251067: Epoch 816 
2025-04-17 18:19:45.251394: Current learning rate: 0.00218 
2025-04-17 18:23:24.170620: train_loss -0.8312 
2025-04-17 18:23:24.174111: val_loss -0.7783 
2025-04-17 18:23:24.174407: Pseudo dice [np.float32(0.8361), np.float32(0.9134)] 
2025-04-17 18:23:24.174689: Epoch time: 218.92 s 
2025-04-17 18:23:25.324823:  
2025-04-17 18:23:25.325360: Epoch 817 
2025-04-17 18:23:25.325680: Current learning rate: 0.00217 
2025-04-17 18:27:04.223233: train_loss -0.835 
2025-04-17 18:27:04.224217: val_loss -0.7619 
2025-04-17 18:27:04.224553: Pseudo dice [np.float32(0.8422), np.float32(0.8946)] 
2025-04-17 18:27:04.224873: Epoch time: 218.9 s 
2025-04-17 18:27:05.363217:  
2025-04-17 18:27:05.363705: Epoch 818 
2025-04-17 18:27:05.364036: Current learning rate: 0.00216 
2025-04-17 18:30:44.286546: train_loss -0.8158 
2025-04-17 18:30:44.290138: val_loss -0.7626 
2025-04-17 18:30:44.290429: Pseudo dice [np.float32(0.8738), np.float32(0.9044)] 
2025-04-17 18:30:44.290703: Epoch time: 218.93 s 
2025-04-17 18:30:45.440372:  
2025-04-17 18:30:45.440844: Epoch 819 
2025-04-17 18:30:45.441192: Current learning rate: 0.00215 
2025-04-17 18:34:24.091634: train_loss -0.8337 
2025-04-17 18:34:24.092460: val_loss -0.7566 
2025-04-17 18:34:24.092760: Pseudo dice [np.float32(0.8297), np.float32(0.9054)] 
2025-04-17 18:34:24.093056: Epoch time: 218.65 s 
2025-04-17 18:34:25.157554:  
2025-04-17 18:34:25.158025: Epoch 820 
2025-04-17 18:34:25.158333: Current learning rate: 0.00214 
2025-04-17 18:38:03.917401: train_loss -0.8323 
2025-04-17 18:38:03.921232: val_loss -0.7838 
2025-04-17 18:38:03.921545: Pseudo dice [np.float32(0.879), np.float32(0.9229)] 
2025-04-17 18:38:03.921852: Epoch time: 218.76 s 
2025-04-17 18:38:05.035423:  
2025-04-17 18:38:05.035944: Epoch 821 
2025-04-17 18:38:05.036297: Current learning rate: 0.00213 
2025-04-17 18:41:43.850711: train_loss -0.8255 
2025-04-17 18:41:43.851544: val_loss -0.7607 
2025-04-17 18:41:43.851841: Pseudo dice [np.float32(0.8448), np.float32(0.9278)] 
2025-04-17 18:41:43.852133: Epoch time: 218.82 s 
2025-04-17 18:41:44.931118:  
2025-04-17 18:41:44.931650: Epoch 822 
2025-04-17 18:41:44.931988: Current learning rate: 0.00212 
2025-04-17 18:45:23.705721: train_loss -0.8335 
2025-04-17 18:45:23.709278: val_loss -0.7824 
2025-04-17 18:45:23.709595: Pseudo dice [np.float32(0.8625), np.float32(0.9249)] 
2025-04-17 18:45:23.709906: Epoch time: 218.78 s 
2025-04-17 18:45:24.791291:  
2025-04-17 18:45:24.791871: Epoch 823 
2025-04-17 18:45:24.792232: Current learning rate: 0.0021 
2025-04-17 18:49:03.500619: train_loss -0.825 
2025-04-17 18:49:03.501295: val_loss -0.7768 
2025-04-17 18:49:03.501580: Pseudo dice [np.float32(0.8499), np.float32(0.9189)] 
2025-04-17 18:49:03.501864: Epoch time: 218.71 s 
2025-04-17 18:49:04.569865:  
2025-04-17 18:49:04.570362: Epoch 824 
2025-04-17 18:49:04.570687: Current learning rate: 0.00209 
2025-04-17 18:52:43.496820: train_loss -0.8312 
2025-04-17 18:52:43.500630: val_loss -0.7544 
2025-04-17 18:52:43.501349: Pseudo dice [np.float32(0.8299), np.float32(0.907)] 
2025-04-17 18:52:43.501655: Epoch time: 218.93 s 
2025-04-17 18:52:44.561117:  
2025-04-17 18:52:44.561581: Epoch 825 
2025-04-17 18:52:44.561905: Current learning rate: 0.00208 
2025-04-17 18:56:24.191960: train_loss -0.8327 
2025-04-17 18:56:24.192783: val_loss -0.807 
2025-04-17 18:56:24.193088: Pseudo dice [np.float32(0.8837), np.float32(0.9172)] 
2025-04-17 18:56:24.193398: Epoch time: 219.63 s 
2025-04-17 18:56:25.258466:  
2025-04-17 18:56:25.259009: Epoch 826 
2025-04-17 18:56:25.259345: Current learning rate: 0.00207 
2025-04-17 19:00:04.620841: train_loss -0.8355 
2025-04-17 19:00:04.624446: val_loss -0.7877 
2025-04-17 19:00:04.624780: Pseudo dice [np.float32(0.9047), np.float32(0.9301)] 
2025-04-17 19:00:04.625084: Epoch time: 219.36 s 
2025-04-17 19:00:05.734910:  
2025-04-17 19:00:05.735529: Epoch 827 
2025-04-17 19:00:05.735898: Current learning rate: 0.00206 
2025-04-17 19:03:44.405917: train_loss -0.8388 
2025-04-17 19:03:44.406778: val_loss -0.7712 
2025-04-17 19:03:44.407060: Pseudo dice [np.float32(0.8715), np.float32(0.9116)] 
2025-04-17 19:03:44.407357: Epoch time: 218.67 s 
2025-04-17 19:03:45.472240:  
2025-04-17 19:03:45.472698: Epoch 828 
2025-04-17 19:03:45.473016: Current learning rate: 0.00205 
2025-04-17 19:07:24.161661: train_loss -0.829 
2025-04-17 19:07:24.165259: val_loss -0.767 
2025-04-17 19:07:24.165548: Pseudo dice [np.float32(0.8221), np.float32(0.9208)] 
2025-04-17 19:07:24.165864: Epoch time: 218.69 s 
2025-04-17 19:07:26.088780:  
2025-04-17 19:07:26.089345: Epoch 829 
2025-04-17 19:07:26.089763: Current learning rate: 0.00204 
2025-04-17 19:11:04.270622: train_loss -0.8321 
2025-04-17 19:11:04.271510: val_loss -0.7829 
2025-04-17 19:11:04.271818: Pseudo dice [np.float32(0.8644), np.float32(0.9145)] 
2025-04-17 19:11:04.272110: Epoch time: 218.18 s 
2025-04-17 19:11:05.329044:  
2025-04-17 19:11:05.329618: Epoch 830 
2025-04-17 19:11:05.329948: Current learning rate: 0.00203 
2025-04-17 19:14:43.741328: train_loss -0.8309 
2025-04-17 19:14:43.745193: val_loss -0.7783 
2025-04-17 19:14:43.745523: Pseudo dice [np.float32(0.8878), np.float32(0.9209)] 
2025-04-17 19:14:43.745863: Epoch time: 218.41 s 
2025-04-17 19:14:44.801283:  
2025-04-17 19:14:44.801794: Epoch 831 
2025-04-17 19:14:44.802128: Current learning rate: 0.00202 
2025-04-17 19:18:23.184586: train_loss -0.8338 
2025-04-17 19:18:23.185468: val_loss -0.7935 
2025-04-17 19:18:23.185789: Pseudo dice [np.float32(0.893), np.float32(0.9212)] 
2025-04-17 19:18:23.186091: Epoch time: 218.39 s 
2025-04-17 19:18:24.235885:  
2025-04-17 19:18:24.236357: Epoch 832 
2025-04-17 19:18:24.236676: Current learning rate: 0.00201 
2025-04-17 19:22:03.369389: train_loss -0.8479 
2025-04-17 19:22:03.373092: val_loss -0.7742 
2025-04-17 19:22:03.373405: Pseudo dice [np.float32(0.8711), np.float32(0.9029)] 
2025-04-17 19:22:03.373708: Epoch time: 219.14 s 
2025-04-17 19:22:04.446790:  
2025-04-17 19:22:04.447372: Epoch 833 
2025-04-17 19:22:04.447712: Current learning rate: 0.002 
2025-04-17 19:25:44.209482: train_loss -0.8312 
2025-04-17 19:25:44.210196: val_loss -0.7861 
2025-04-17 19:25:44.210497: Pseudo dice [np.float32(0.8823), np.float32(0.9221)] 
2025-04-17 19:25:44.210804: Epoch time: 219.76 s 
2025-04-17 19:25:45.286822:  
2025-04-17 19:25:45.287333: Epoch 834 
2025-04-17 19:25:45.287666: Current learning rate: 0.00199 
2025-04-17 19:29:25.586686: train_loss -0.8307 
2025-04-17 19:29:25.590473: val_loss -0.8068 
2025-04-17 19:29:25.590768: Pseudo dice [np.float32(0.8867), np.float32(0.9241)] 
2025-04-17 19:29:25.591048: Epoch time: 220.3 s 
2025-04-17 19:29:26.665228:  
2025-04-17 19:29:26.665710: Epoch 835 
2025-04-17 19:29:26.666045: Current learning rate: 0.00198 
2025-04-17 19:33:07.507818: train_loss -0.8342 
2025-04-17 19:33:07.508548: val_loss -0.7732 
2025-04-17 19:33:07.508838: Pseudo dice [np.float32(0.8541), np.float32(0.9057)] 
2025-04-17 19:33:07.509123: Epoch time: 220.84 s 
2025-04-17 19:33:08.588995:  
2025-04-17 19:33:08.590210: Epoch 836 
2025-04-17 19:33:08.590529: Current learning rate: 0.00196 
2025-04-17 19:36:48.438857: train_loss -0.835 
2025-04-17 19:36:48.442906: val_loss -0.7972 
2025-04-17 19:36:48.443269: Pseudo dice [np.float32(0.868), np.float32(0.9153)] 
2025-04-17 19:36:48.443590: Epoch time: 219.85 s 
2025-04-17 19:36:49.536465:  
2025-04-17 19:36:49.537121: Epoch 837 
2025-04-17 19:36:49.537526: Current learning rate: 0.00195 
2025-04-17 19:40:29.042727: train_loss -0.8277 
2025-04-17 19:40:29.043548: val_loss -0.7706 
2025-04-17 19:40:29.043866: Pseudo dice [np.float32(0.8552), np.float32(0.9303)] 
2025-04-17 19:40:29.044163: Epoch time: 219.51 s 
2025-04-17 19:40:30.116199:  
2025-04-17 19:40:30.116767: Epoch 838 
2025-04-17 19:40:30.117099: Current learning rate: 0.00194 
2025-04-17 19:44:08.541225: train_loss -0.8463 
2025-04-17 19:44:08.545271: val_loss -0.7936 
2025-04-17 19:44:08.545568: Pseudo dice [np.float32(0.8779), np.float32(0.9174)] 
2025-04-17 19:44:08.545856: Epoch time: 218.43 s 
2025-04-17 19:44:09.626758:  
2025-04-17 19:44:09.627249: Epoch 839 
2025-04-17 19:44:09.627569: Current learning rate: 0.00193 
2025-04-17 19:47:48.455642: train_loss -0.8371 
2025-04-17 19:47:48.456335: val_loss -0.7969 
2025-04-17 19:47:48.456630: Pseudo dice [np.float32(0.88), np.float32(0.9097)] 
2025-04-17 19:47:48.456923: Epoch time: 218.83 s 
2025-04-17 19:47:49.624842:  
2025-04-17 19:47:49.625309: Epoch 840 
2025-04-17 19:47:49.625626: Current learning rate: 0.00192 
2025-04-17 19:51:28.981314: train_loss -0.8422 
2025-04-17 19:51:28.986035: val_loss -0.7616 
2025-04-17 19:51:28.986395: Pseudo dice [np.float32(0.8694), np.float32(0.9291)] 
2025-04-17 19:51:28.986691: Epoch time: 219.36 s 
2025-04-17 19:51:30.058282:  
2025-04-17 19:51:30.058779: Epoch 841 
2025-04-17 19:51:30.059096: Current learning rate: 0.00191 
2025-04-17 19:55:09.619523: train_loss -0.8374 
2025-04-17 19:55:09.620432: val_loss -0.7442 
2025-04-17 19:55:09.620747: Pseudo dice [np.float32(0.819), np.float32(0.8977)] 
2025-04-17 19:55:09.621050: Epoch time: 219.56 s 
2025-04-17 19:55:10.725227:  
2025-04-17 19:55:10.725831: Epoch 842 
2025-04-17 19:55:10.726202: Current learning rate: 0.0019 
2025-04-17 19:58:50.474724: train_loss -0.8257 
2025-04-17 19:58:50.478355: val_loss -0.77 
2025-04-17 19:58:50.478671: Pseudo dice [np.float32(0.8474), np.float32(0.9237)] 
2025-04-17 19:58:50.479002: Epoch time: 219.75 s 
2025-04-17 19:58:51.592337:  
2025-04-17 19:58:51.592929: Epoch 843 
2025-04-17 19:58:51.593263: Current learning rate: 0.00189 
2025-04-17 20:02:31.302649: train_loss -0.8327 
2025-04-17 20:02:31.303504: val_loss -0.7688 
2025-04-17 20:02:31.303826: Pseudo dice [np.float32(0.8635), np.float32(0.918)] 
2025-04-17 20:02:31.304125: Epoch time: 219.71 s 
2025-04-17 20:02:32.399817:  
2025-04-17 20:02:32.400449: Epoch 844 
2025-04-17 20:02:32.400787: Current learning rate: 0.00188 
2025-04-17 20:06:12.315837: train_loss -0.8318 
2025-04-17 20:06:12.319588: val_loss -0.7895 
2025-04-17 20:06:12.319926: Pseudo dice [np.float32(0.8744), np.float32(0.9258)] 
2025-04-17 20:06:12.320217: Epoch time: 219.92 s 
2025-04-17 20:06:13.394849:  
2025-04-17 20:06:13.395326: Epoch 845 
2025-04-17 20:06:13.395647: Current learning rate: 0.00187 
2025-04-17 20:09:53.287689: train_loss -0.8198 
2025-04-17 20:09:53.288487: val_loss -0.7646 
2025-04-17 20:09:53.288805: Pseudo dice [np.float32(0.8483), np.float32(0.9155)] 
2025-04-17 20:09:53.289104: Epoch time: 219.9 s 
2025-04-17 20:09:54.351416:  
2025-04-17 20:09:54.351923: Epoch 846 
2025-04-17 20:09:54.352253: Current learning rate: 0.00186 
2025-04-17 20:13:34.690073: train_loss -0.8294 
2025-04-17 20:13:34.693867: val_loss -0.7481 
2025-04-17 20:13:34.694233: Pseudo dice [np.float32(0.8445), np.float32(0.9164)] 
2025-04-17 20:13:34.694584: Epoch time: 220.34 s 
2025-04-17 20:13:35.828218:  
2025-04-17 20:13:35.828720: Epoch 847 
2025-04-17 20:13:35.829056: Current learning rate: 0.00185 
2025-04-17 20:17:15.780053: train_loss -0.8355 
2025-04-17 20:17:15.780957: val_loss -0.7469 
2025-04-17 20:17:15.781260: Pseudo dice [np.float32(0.8628), np.float32(0.9234)] 
2025-04-17 20:17:15.782079: Epoch time: 219.95 s 
2025-04-17 20:17:17.732282:  
2025-04-17 20:17:17.732808: Epoch 848 
2025-04-17 20:17:17.733150: Current learning rate: 0.00184 
2025-04-17 20:20:56.295437: train_loss -0.8384 
2025-04-17 20:20:56.299089: val_loss -0.7703 
2025-04-17 20:20:56.299428: Pseudo dice [np.float32(0.8463), np.float32(0.9077)] 
2025-04-17 20:20:56.299774: Epoch time: 218.57 s 
2025-04-17 20:20:57.360349:  
2025-04-17 20:20:57.360885: Epoch 849 
2025-04-17 20:20:57.361230: Current learning rate: 0.00182 
2025-04-17 20:24:35.767162: train_loss -0.8471 
2025-04-17 20:24:35.767976: val_loss -0.7522 
2025-04-17 20:24:35.768269: Pseudo dice [np.float32(0.8427), np.float32(0.9236)] 
2025-04-17 20:24:35.768564: Epoch time: 218.41 s 
2025-04-17 20:24:37.234215:  
2025-04-17 20:24:37.234707: Epoch 850 
2025-04-17 20:24:37.235031: Current learning rate: 0.00181 
2025-04-17 20:28:15.436288: train_loss -0.8416 
2025-04-17 20:28:15.439944: val_loss -0.7874 
2025-04-17 20:28:15.440240: Pseudo dice [np.float32(0.8558), np.float32(0.9188)] 
2025-04-17 20:28:15.440521: Epoch time: 218.2 s 
2025-04-17 20:28:16.484194:  
2025-04-17 20:28:16.484711: Epoch 851 
2025-04-17 20:28:16.485038: Current learning rate: 0.0018 
2025-04-17 20:31:57.107536: train_loss -0.8304 
2025-04-17 20:31:57.108349: val_loss -0.7531 
2025-04-17 20:31:57.108652: Pseudo dice [np.float32(0.8289), np.float32(0.9306)] 
2025-04-17 20:31:57.108970: Epoch time: 220.63 s 
2025-04-17 20:31:58.169562:  
2025-04-17 20:31:58.170065: Epoch 852 
2025-04-17 20:31:58.170396: Current learning rate: 0.00179 
2025-04-17 20:35:39.699445: train_loss -0.8385 
2025-04-17 20:35:39.703336: val_loss -0.7562 
2025-04-17 20:35:39.703642: Pseudo dice [np.float32(0.8706), np.float32(0.9244)] 
2025-04-17 20:35:39.703934: Epoch time: 221.53 s 
2025-04-17 20:35:40.733371:  
2025-04-17 20:35:40.733836: Epoch 853 
2025-04-17 20:35:40.734156: Current learning rate: 0.00178 
2025-04-17 20:39:18.351765: train_loss -0.8465 
2025-04-17 20:39:18.352646: val_loss -0.7939 
2025-04-17 20:39:18.352947: Pseudo dice [np.float32(0.8716), np.float32(0.9154)] 
2025-04-17 20:39:18.353254: Epoch time: 217.62 s 
2025-04-17 20:39:19.385945:  
2025-04-17 20:39:19.386427: Epoch 854 
2025-04-17 20:39:19.386757: Current learning rate: 0.00177 
2025-04-17 20:42:57.845912: train_loss -0.8409 
2025-04-17 20:42:57.849746: val_loss -0.7951 
2025-04-17 20:42:57.850074: Pseudo dice [np.float32(0.8927), np.float32(0.9287)] 
2025-04-17 20:42:57.850410: Epoch time: 218.46 s 
2025-04-17 20:42:58.901693:  
2025-04-17 20:42:58.902245: Epoch 855 
2025-04-17 20:42:58.902615: Current learning rate: 0.00176 
2025-04-17 20:46:38.342777: train_loss -0.8457 
2025-04-17 20:46:38.343508: val_loss -0.805 
2025-04-17 20:46:38.343796: Pseudo dice [np.float32(0.8862), np.float32(0.9261)] 
2025-04-17 20:46:38.344082: Epoch time: 219.44 s 
2025-04-17 20:46:39.387906:  
2025-04-17 20:46:39.388363: Epoch 856 
2025-04-17 20:46:39.388666: Current learning rate: 0.00175 
2025-04-17 20:50:20.026498: train_loss -0.8368 
2025-04-17 20:50:20.030211: val_loss -0.7832 
2025-04-17 20:50:20.030540: Pseudo dice [np.float32(0.9063), np.float32(0.9133)] 
2025-04-17 20:50:20.030855: Epoch time: 220.64 s 
2025-04-17 20:50:21.098580:  
2025-04-17 20:50:21.099090: Epoch 857 
2025-04-17 20:50:21.099423: Current learning rate: 0.00174 
2025-04-17 20:54:00.678474: train_loss -0.841 
2025-04-17 20:54:00.679219: val_loss -0.7725 
2025-04-17 20:54:00.679503: Pseudo dice [np.float32(0.8711), np.float32(0.918)] 
2025-04-17 20:54:00.679797: Epoch time: 219.58 s 
2025-04-17 20:54:01.735453:  
2025-04-17 20:54:01.736023: Epoch 858 
2025-04-17 20:54:01.736351: Current learning rate: 0.00173 
2025-04-17 20:57:40.134765: train_loss -0.825 
2025-04-17 20:57:40.138412: val_loss -0.783 
2025-04-17 20:57:40.138726: Pseudo dice [np.float32(0.8752), np.float32(0.9015)] 
2025-04-17 20:57:40.139034: Epoch time: 218.4 s 
2025-04-17 20:57:41.171688:  
2025-04-17 20:57:41.172341: Epoch 859 
2025-04-17 20:57:41.172677: Current learning rate: 0.00172 
2025-04-17 21:01:18.550836: train_loss -0.8462 
2025-04-17 21:01:18.551659: val_loss -0.7737 
2025-04-17 21:01:18.551949: Pseudo dice [np.float32(0.8606), np.float32(0.923)] 
2025-04-17 21:01:18.552257: Epoch time: 217.38 s 
2025-04-17 21:01:19.618268:  
2025-04-17 21:01:19.618840: Epoch 860 
2025-04-17 21:01:19.619178: Current learning rate: 0.0017 
2025-04-17 21:04:56.743952: train_loss -0.8313 
2025-04-17 21:04:56.747412: val_loss -0.7661 
2025-04-17 21:04:56.747729: Pseudo dice [np.float32(0.8517), np.float32(0.9175)] 
2025-04-17 21:04:56.748052: Epoch time: 217.13 s 
2025-04-17 21:04:57.792370:  
2025-04-17 21:04:57.792918: Epoch 861 
2025-04-17 21:04:57.793259: Current learning rate: 0.00169 
2025-04-17 21:08:35.089760: train_loss -0.8415 
2025-04-17 21:08:35.090590: val_loss -0.7885 
2025-04-17 21:08:35.090888: Pseudo dice [np.float32(0.8865), np.float32(0.9274)] 
2025-04-17 21:08:35.091198: Epoch time: 217.3 s 
2025-04-17 21:08:36.165599:  
2025-04-17 21:08:36.166132: Epoch 862 
2025-04-17 21:08:36.166455: Current learning rate: 0.00168 
2025-04-17 21:12:13.899450: train_loss -0.8374 
2025-04-17 21:12:13.903111: val_loss -0.7647 
2025-04-17 21:12:13.903421: Pseudo dice [np.float32(0.8439), np.float32(0.9029)] 
2025-04-17 21:12:13.903821: Epoch time: 217.74 s 
2025-04-17 21:12:14.974797:  
2025-04-17 21:12:14.975275: Epoch 863 
2025-04-17 21:12:14.975595: Current learning rate: 0.00167 
2025-04-17 21:15:53.415477: train_loss -0.8364 
2025-04-17 21:15:53.416209: val_loss -0.7915 
2025-04-17 21:15:53.416494: Pseudo dice [np.float32(0.8603), np.float32(0.9197)] 
2025-04-17 21:15:53.416779: Epoch time: 218.44 s 
2025-04-17 21:15:54.469513:  
2025-04-17 21:15:54.470078: Epoch 864 
2025-04-17 21:15:54.470416: Current learning rate: 0.00166 
2025-04-17 21:19:33.128644: train_loss -0.8343 
2025-04-17 21:19:33.132357: val_loss -0.8113 
2025-04-17 21:19:33.132716: Pseudo dice [np.float32(0.9055), np.float32(0.9225)] 
2025-04-17 21:19:33.133095: Epoch time: 218.66 s 
2025-04-17 21:19:34.187216:  
2025-04-17 21:19:34.187707: Epoch 865 
2025-04-17 21:19:34.188056: Current learning rate: 0.00165 
2025-04-17 21:23:12.603808: train_loss -0.8425 
2025-04-17 21:23:12.604641: val_loss -0.8191 
2025-04-17 21:23:12.604942: Pseudo dice [np.float32(0.8874), np.float32(0.9252)] 
2025-04-17 21:23:12.605245: Epoch time: 218.42 s 
2025-04-17 21:23:12.605517: Yayy! New best EMA pseudo Dice: 0.8950999975204468 
2025-04-17 21:23:14.081100:  
2025-04-17 21:23:14.081696: Epoch 866 
2025-04-17 21:23:14.082059: Current learning rate: 0.00164 
2025-04-17 21:26:53.138843: train_loss -0.8445 
2025-04-17 21:26:53.142370: val_loss -0.7791 
2025-04-17 21:26:53.142672: Pseudo dice [np.float32(0.8516), np.float32(0.9185)] 
2025-04-17 21:26:53.142969: Epoch time: 219.06 s 
2025-04-17 21:26:54.233706:  
2025-04-17 21:26:54.234311: Epoch 867 
2025-04-17 21:26:54.234666: Current learning rate: 0.00163 
2025-04-17 21:30:33.826643: train_loss -0.8337 
2025-04-17 21:30:33.827498: val_loss -0.7566 
2025-04-17 21:30:33.827794: Pseudo dice [np.float32(0.8457), np.float32(0.9181)] 
2025-04-17 21:30:33.828098: Epoch time: 219.6 s 
2025-04-17 21:30:35.698140:  
2025-04-17 21:30:35.698711: Epoch 868 
2025-04-17 21:30:35.699052: Current learning rate: 0.00162 
2025-04-17 21:34:14.873491: train_loss -0.8303 
2025-04-17 21:34:14.877038: val_loss -0.7738 
2025-04-17 21:34:14.877366: Pseudo dice [np.float32(0.8763), np.float32(0.9149)] 
2025-04-17 21:34:14.877665: Epoch time: 219.18 s 
2025-04-17 21:34:15.929516:  
2025-04-17 21:34:15.930013: Epoch 869 
2025-04-17 21:34:15.930339: Current learning rate: 0.00161 
2025-04-17 21:37:54.386131: train_loss -0.8442 
2025-04-17 21:37:54.387044: val_loss -0.774 
2025-04-17 21:37:54.387353: Pseudo dice [np.float32(0.8783), np.float32(0.9165)] 
2025-04-17 21:37:54.387677: Epoch time: 218.46 s 
2025-04-17 21:37:55.436676:  
2025-04-17 21:37:55.437209: Epoch 870 
2025-04-17 21:37:55.437551: Current learning rate: 0.00159 
2025-04-17 21:41:33.346003: train_loss -0.8299 
2025-04-17 21:41:33.349522: val_loss -0.768 
2025-04-17 21:41:33.350285: Pseudo dice [np.float32(0.83), np.float32(0.9208)] 
2025-04-17 21:41:33.350589: Epoch time: 217.91 s 
2025-04-17 21:41:34.421977:  
2025-04-17 21:41:34.422461: Epoch 871 
2025-04-17 21:41:34.422784: Current learning rate: 0.00158 
2025-04-17 21:45:12.784234: train_loss -0.8409 
2025-04-17 21:45:12.785020: val_loss -0.7921 
2025-04-17 21:45:12.785297: Pseudo dice [np.float32(0.8815), np.float32(0.9234)] 
2025-04-17 21:45:12.785578: Epoch time: 218.36 s 
2025-04-17 21:45:13.837167:  
2025-04-17 21:45:13.837642: Epoch 872 
2025-04-17 21:45:13.837973: Current learning rate: 0.00157 
2025-04-17 21:48:53.150672: train_loss -0.8449 
2025-04-17 21:48:53.154379: val_loss -0.791 
2025-04-17 21:48:53.155870: Pseudo dice [np.float32(0.888), np.float32(0.9216)] 
2025-04-17 21:48:53.156191: Epoch time: 219.32 s 
2025-04-17 21:48:54.180966:  
2025-04-17 21:48:54.181436: Epoch 873 
2025-04-17 21:48:54.181758: Current learning rate: 0.00156 
2025-04-17 21:52:33.886514: train_loss -0.8419 
2025-04-17 21:52:33.887448: val_loss -0.7761 
2025-04-17 21:52:33.887767: Pseudo dice [np.float32(0.8671), np.float32(0.9301)] 
2025-04-17 21:52:33.888079: Epoch time: 219.71 s 
2025-04-17 21:52:34.928057:  
2025-04-17 21:52:34.928518: Epoch 874 
2025-04-17 21:52:34.928837: Current learning rate: 0.00155 
2025-04-17 21:56:13.692297: train_loss -0.8377 
2025-04-17 21:56:13.695921: val_loss -0.7667 
2025-04-17 21:56:13.696217: Pseudo dice [np.float32(0.8584), np.float32(0.9238)] 
2025-04-17 21:56:13.696498: Epoch time: 218.77 s 
2025-04-17 21:56:14.746594:  
2025-04-17 21:56:14.747050: Epoch 875 
2025-04-17 21:56:14.747383: Current learning rate: 0.00154 
2025-04-17 21:59:52.876624: train_loss -0.8415 
2025-04-17 21:59:52.877421: val_loss -0.8056 
2025-04-17 21:59:52.877700: Pseudo dice [np.float32(0.8811), np.float32(0.9225)] 
2025-04-17 21:59:52.878000: Epoch time: 218.13 s 
2025-04-17 21:59:53.958327:  
2025-04-17 21:59:53.958803: Epoch 876 
2025-04-17 21:59:53.959122: Current learning rate: 0.00153 
2025-04-17 22:03:31.400862: train_loss -0.8311 
2025-04-17 22:03:31.404556: val_loss -0.7831 
2025-04-17 22:03:31.404913: Pseudo dice [np.float32(0.8611), np.float32(0.9287)] 
2025-04-17 22:03:31.405206: Epoch time: 217.44 s 
2025-04-17 22:03:32.497782:  
2025-04-17 22:03:32.498258: Epoch 877 
2025-04-17 22:03:32.498579: Current learning rate: 0.00152 
2025-04-17 22:07:09.888670: train_loss -0.844 
2025-04-17 22:07:09.889478: val_loss -0.7575 
2025-04-17 22:07:09.889764: Pseudo dice [np.float32(0.8257), np.float32(0.9172)] 
2025-04-17 22:07:09.890064: Epoch time: 217.39 s 
2025-04-17 22:07:10.938015:  
2025-04-17 22:07:10.938549: Epoch 878 
2025-04-17 22:07:10.938876: Current learning rate: 0.00151 
2025-04-17 22:10:48.078026: train_loss -0.8414 
2025-04-17 22:10:48.082771: val_loss -0.7734 
2025-04-17 22:10:48.083107: Pseudo dice [np.float32(0.8545), np.float32(0.921)] 
2025-04-17 22:10:48.083414: Epoch time: 217.14 s 
2025-04-17 22:10:49.135684:  
2025-04-17 22:10:49.136308: Epoch 879 
2025-04-17 22:10:49.136650: Current learning rate: 0.00149 
2025-04-17 22:14:26.525925: train_loss -0.8307 
2025-04-17 22:14:26.526684: val_loss -0.7781 
2025-04-17 22:14:26.527002: Pseudo dice [np.float32(0.8539), np.float32(0.918)] 
2025-04-17 22:14:26.527285: Epoch time: 217.39 s 
2025-04-17 22:14:27.585426:  
2025-04-17 22:14:27.585873: Epoch 880 
2025-04-17 22:14:27.586194: Current learning rate: 0.00148 
2025-04-17 22:18:05.012202: train_loss -0.8164 
2025-04-17 22:18:05.015792: val_loss -0.7743 
2025-04-17 22:18:05.016091: Pseudo dice [np.float32(0.8632), np.float32(0.9211)] 
2025-04-17 22:18:05.016380: Epoch time: 217.43 s 
2025-04-17 22:18:06.082934:  
2025-04-17 22:18:06.083518: Epoch 881 
2025-04-17 22:18:06.083848: Current learning rate: 0.00147 
2025-04-17 22:21:43.766435: train_loss -0.8275 
2025-04-17 22:21:43.767222: val_loss -0.7638 
2025-04-17 22:21:43.767500: Pseudo dice [np.float32(0.832), np.float32(0.9083)] 
2025-04-17 22:21:43.767795: Epoch time: 217.69 s 
2025-04-17 22:21:44.836141:  
2025-04-17 22:21:44.836684: Epoch 882 
2025-04-17 22:21:44.837414: Current learning rate: 0.00146 
2025-04-17 22:25:23.899256: train_loss -0.8315 
2025-04-17 22:25:23.903046: val_loss -0.8006 
2025-04-17 22:25:23.903397: Pseudo dice [np.float32(0.8577), np.float32(0.925)] 
2025-04-17 22:25:23.903703: Epoch time: 219.07 s 
2025-04-17 22:25:24.952540:  
2025-04-17 22:25:24.953152: Epoch 883 
2025-04-17 22:25:24.953485: Current learning rate: 0.00145 
2025-04-17 22:29:04.626049: train_loss -0.8365 
2025-04-17 22:29:04.626842: val_loss -0.7959 
2025-04-17 22:29:04.627137: Pseudo dice [np.float32(0.8697), np.float32(0.9221)] 
2025-04-17 22:29:04.627451: Epoch time: 219.68 s 
2025-04-17 22:29:05.704736:  
2025-04-17 22:29:05.705238: Epoch 884 
2025-04-17 22:29:05.705554: Current learning rate: 0.00144 
2025-04-17 22:32:48.466509: train_loss -0.8437 
2025-04-17 22:32:48.470131: val_loss -0.7633 
2025-04-17 22:32:48.470463: Pseudo dice [np.float32(0.8614), np.float32(0.92)] 
2025-04-17 22:32:48.470779: Epoch time: 222.76 s 
2025-04-17 22:32:49.508768:  
2025-04-17 22:32:49.509268: Epoch 885 
2025-04-17 22:32:49.509581: Current learning rate: 0.00143 
2025-04-17 22:36:31.668142: train_loss -0.8327 
2025-04-17 22:36:31.668962: val_loss -0.7744 
2025-04-17 22:36:31.669262: Pseudo dice [np.float32(0.8657), np.float32(0.917)] 
2025-04-17 22:36:31.669572: Epoch time: 222.16 s 
2025-04-17 22:36:32.717300:  
2025-04-17 22:36:32.717835: Epoch 886 
2025-04-17 22:36:32.718242: Current learning rate: 0.00142 
2025-04-17 22:40:11.581297: train_loss -0.8349 
2025-04-17 22:40:11.584548: val_loss -0.7743 
2025-04-17 22:40:11.584857: Pseudo dice [np.float32(0.8508), np.float32(0.9222)] 
2025-04-17 22:40:11.585145: Epoch time: 218.87 s 
2025-04-17 22:40:12.629020:  
2025-04-17 22:40:12.629524: Epoch 887 
2025-04-17 22:40:12.629846: Current learning rate: 0.00141 
2025-04-17 22:43:51.619731: train_loss -0.8428 
2025-04-17 22:43:51.620547: val_loss -0.765 
2025-04-17 22:43:51.620850: Pseudo dice [np.float32(0.867), np.float32(0.9042)] 
2025-04-17 22:43:51.621137: Epoch time: 218.99 s 
2025-04-17 22:43:53.573341:  
2025-04-17 22:43:53.573880: Epoch 888 
2025-04-17 22:43:53.574206: Current learning rate: 0.00139 
2025-04-17 22:47:32.339318: train_loss -0.8283 
2025-04-17 22:47:32.342892: val_loss -0.7825 
2025-04-17 22:47:32.343209: Pseudo dice [np.float32(0.8571), np.float32(0.9177)] 
2025-04-17 22:47:32.343508: Epoch time: 218.77 s 
2025-04-17 22:47:33.396502:  
2025-04-17 22:47:33.397004: Epoch 889 
2025-04-17 22:47:33.397334: Current learning rate: 0.00138 
2025-04-17 22:51:12.232918: train_loss -0.8336 
2025-04-17 22:51:12.233675: val_loss -0.796 
2025-04-17 22:51:12.234002: Pseudo dice [np.float32(0.873), np.float32(0.9081)] 
2025-04-17 22:51:12.234303: Epoch time: 218.84 s 
2025-04-17 22:51:13.259019:  
2025-04-17 22:51:13.259610: Epoch 890 
2025-04-17 22:51:13.259953: Current learning rate: 0.00137 
2025-04-17 22:54:52.141356: train_loss -0.8433 
2025-04-17 22:54:52.145247: val_loss -0.8178 
2025-04-17 22:54:52.145585: Pseudo dice [np.float32(0.904), np.float32(0.9296)] 
2025-04-17 22:54:52.145896: Epoch time: 218.88 s 
2025-04-17 22:54:53.178259:  
2025-04-17 22:54:53.178826: Epoch 891 
2025-04-17 22:54:53.179167: Current learning rate: 0.00136 
2025-04-17 22:58:31.980470: train_loss -0.8389 
2025-04-17 22:58:31.981419: val_loss -0.7785 
2025-04-17 22:58:31.981734: Pseudo dice [np.float32(0.8936), np.float32(0.9289)] 
2025-04-17 22:58:31.982056: Epoch time: 218.8 s 
2025-04-17 22:58:33.049464:  
2025-04-17 22:58:33.050072: Epoch 892 
2025-04-17 22:58:33.050420: Current learning rate: 0.00135 
2025-04-17 23:02:11.735603: train_loss -0.8325 
2025-04-17 23:02:11.739436: val_loss -0.7686 
2025-04-17 23:02:11.739789: Pseudo dice [np.float32(0.8573), np.float32(0.9111)] 
2025-04-17 23:02:11.740124: Epoch time: 218.69 s 
2025-04-17 23:02:12.801941:  
2025-04-17 23:02:12.802582: Epoch 893 
2025-04-17 23:02:12.802943: Current learning rate: 0.00134 
2025-04-17 23:05:51.406297: train_loss -0.838 
2025-04-17 23:05:51.407118: val_loss -0.7671 
2025-04-17 23:05:51.407442: Pseudo dice [np.float32(0.8512), np.float32(0.9085)] 
2025-04-17 23:05:51.408207: Epoch time: 218.61 s 
2025-04-17 23:05:52.462961:  
2025-04-17 23:05:52.463461: Epoch 894 
2025-04-17 23:05:52.463799: Current learning rate: 0.00133 
2025-04-17 23:09:31.157360: train_loss -0.8365 
2025-04-17 23:09:31.161156: val_loss -0.7783 
2025-04-17 23:09:31.161505: Pseudo dice [np.float32(0.8803), np.float32(0.9242)] 
2025-04-17 23:09:31.161837: Epoch time: 218.7 s 
2025-04-17 23:09:32.195679:  
2025-04-17 23:09:32.196251: Epoch 895 
2025-04-17 23:09:32.196599: Current learning rate: 0.00132 
2025-04-17 23:13:10.839539: train_loss -0.8411 
2025-04-17 23:13:10.840405: val_loss -0.7965 
2025-04-17 23:13:10.840724: Pseudo dice [np.float32(0.8757), np.float32(0.9165)] 
2025-04-17 23:13:10.841045: Epoch time: 218.65 s 
2025-04-17 23:13:11.902809:  
2025-04-17 23:13:11.903456: Epoch 896 
2025-04-17 23:13:11.903818: Current learning rate: 0.0013 
2025-04-17 23:16:49.229359: train_loss -0.8421 
2025-04-17 23:16:49.233280: val_loss -0.7825 
2025-04-17 23:16:49.233602: Pseudo dice [np.float32(0.8389), np.float32(0.92)] 
2025-04-17 23:16:49.233926: Epoch time: 217.33 s 
2025-04-17 23:16:50.293362:  
2025-04-17 23:16:50.293919: Epoch 897 
2025-04-17 23:16:50.294290: Current learning rate: 0.00129 
2025-04-17 23:20:27.764725: train_loss -0.8413 
2025-04-17 23:20:27.765568: val_loss -0.7902 
2025-04-17 23:20:27.765852: Pseudo dice [np.float32(0.8718), np.float32(0.9216)] 
2025-04-17 23:20:27.766145: Epoch time: 217.47 s 
2025-04-17 23:20:28.818038:  
2025-04-17 23:20:28.818594: Epoch 898 
2025-04-17 23:20:28.818929: Current learning rate: 0.00128 
2025-04-17 23:24:05.783110: train_loss -0.8429 
2025-04-17 23:24:05.786702: val_loss -0.7826 
2025-04-17 23:24:05.787064: Pseudo dice [np.float32(0.87), np.float32(0.9194)] 
2025-04-17 23:24:05.787379: Epoch time: 216.97 s 
2025-04-17 23:24:06.874984:  
2025-04-17 23:24:06.875586: Epoch 899 
2025-04-17 23:24:06.875913: Current learning rate: 0.00127 
2025-04-17 23:27:44.042306: train_loss -0.8411 
2025-04-17 23:27:44.043146: val_loss -0.7572 
2025-04-17 23:27:44.043437: Pseudo dice [np.float32(0.8393), np.float32(0.9204)] 
2025-04-17 23:27:44.043720: Epoch time: 217.17 s 
2025-04-17 23:27:45.579898:  
2025-04-17 23:27:45.580358: Epoch 900 
2025-04-17 23:27:45.580680: Current learning rate: 0.00126 
2025-04-17 23:31:22.578389: train_loss -0.838 
2025-04-17 23:31:22.582090: val_loss -0.7939 
2025-04-17 23:31:22.582397: Pseudo dice [np.float32(0.8852), np.float32(0.9159)] 
2025-04-17 23:31:22.582693: Epoch time: 217.0 s 
2025-04-17 23:31:23.693586:  
2025-04-17 23:31:23.694159: Epoch 901 
2025-04-17 23:31:23.694568: Current learning rate: 0.00125 
2025-04-17 23:35:01.574554: train_loss -0.8501 
2025-04-17 23:35:01.575471: val_loss -0.741 
2025-04-17 23:35:01.575772: Pseudo dice [np.float32(0.8595), np.float32(0.9076)] 
2025-04-17 23:35:01.576063: Epoch time: 217.88 s 
2025-04-17 23:35:02.642952:  
2025-04-17 23:35:02.643427: Epoch 902 
2025-04-17 23:35:02.643752: Current learning rate: 0.00124 
2025-04-17 23:38:40.974830: train_loss -0.8431 
2025-04-17 23:38:40.978738: val_loss -0.7749 
2025-04-17 23:38:40.979119: Pseudo dice [np.float32(0.8554), np.float32(0.9294)] 
2025-04-17 23:38:40.979551: Epoch time: 218.33 s 
2025-04-17 23:38:42.047376:  
2025-04-17 23:38:42.047929: Epoch 903 
2025-04-17 23:38:42.048286: Current learning rate: 0.00122 
2025-04-17 23:42:20.567555: train_loss -0.8418 
2025-04-17 23:42:20.568481: val_loss -0.7633 
2025-04-17 23:42:20.568822: Pseudo dice [np.float32(0.8643), np.float32(0.9134)] 
2025-04-17 23:42:20.569148: Epoch time: 218.52 s 
2025-04-17 23:42:21.667571:  
2025-04-17 23:42:21.668139: Epoch 904 
2025-04-17 23:42:21.668476: Current learning rate: 0.00121 
2025-04-17 23:46:01.230073: train_loss -0.8421 
2025-04-17 23:46:01.234160: val_loss -0.7625 
2025-04-17 23:46:01.234464: Pseudo dice [np.float32(0.8622), np.float32(0.9161)] 
2025-04-17 23:46:01.234779: Epoch time: 219.56 s 
2025-04-17 23:46:02.288230:  
2025-04-17 23:46:02.288797: Epoch 905 
2025-04-17 23:46:02.289128: Current learning rate: 0.0012 
2025-04-17 23:49:41.867633: train_loss -0.8317 
2025-04-17 23:49:41.868533: val_loss -0.7722 
2025-04-17 23:49:41.868853: Pseudo dice [np.float32(0.8799), np.float32(0.9153)] 
2025-04-17 23:49:41.869246: Epoch time: 219.58 s 
2025-04-17 23:49:42.917533:  
2025-04-17 23:49:42.918084: Epoch 906 
2025-04-17 23:49:42.918421: Current learning rate: 0.00119 
2025-04-17 23:53:22.777086: train_loss -0.8281 
2025-04-17 23:53:22.780887: val_loss -0.8004 
2025-04-17 23:53:22.781219: Pseudo dice [np.float32(0.8704), np.float32(0.9244)] 
2025-04-17 23:53:22.781517: Epoch time: 219.86 s 
2025-04-17 23:53:23.850048:  
2025-04-17 23:53:23.850560: Epoch 907 
2025-04-17 23:53:23.850890: Current learning rate: 0.00118 
2025-04-17 23:57:03.613552: train_loss -0.8436 
2025-04-17 23:57:03.614387: val_loss -0.7843 
2025-04-17 23:57:03.614667: Pseudo dice [np.float32(0.8911), np.float32(0.9267)] 
2025-04-17 23:57:03.614964: Epoch time: 219.77 s 
2025-04-17 23:57:05.602535:  
2025-04-17 23:57:05.603034: Epoch 908 
2025-04-17 23:57:05.603335: Current learning rate: 0.00117 
2025-04-18 00:00:44.967854: train_loss -0.8435 
2025-04-18 00:00:44.972366: val_loss -0.7684 
2025-04-18 00:00:44.972696: Pseudo dice [np.float32(0.8304), np.float32(0.9277)] 
2025-04-18 00:00:44.973011: Epoch time: 219.37 s 
2025-04-18 00:00:46.006810:  
2025-04-18 00:00:46.007352: Epoch 909 
2025-04-18 00:00:46.007688: Current learning rate: 0.00116 
2025-04-18 00:04:25.814015: train_loss -0.8447 
2025-04-18 00:04:25.814760: val_loss -0.7888 
2025-04-18 00:04:25.815064: Pseudo dice [np.float32(0.8771), np.float32(0.9189)] 
2025-04-18 00:04:25.815448: Epoch time: 219.81 s 
2025-04-18 00:04:26.846655:  
2025-04-18 00:04:26.847176: Epoch 910 
2025-04-18 00:04:26.847498: Current learning rate: 0.00115 
2025-04-18 00:08:06.590831: train_loss -0.8381 
2025-04-18 00:08:06.595111: val_loss -0.7836 
2025-04-18 00:08:06.595474: Pseudo dice [np.float32(0.8529), np.float32(0.9182)] 
2025-04-18 00:08:06.595794: Epoch time: 219.75 s 
2025-04-18 00:08:07.630374:  
2025-04-18 00:08:07.630859: Epoch 911 
2025-04-18 00:08:07.631193: Current learning rate: 0.00113 
2025-04-18 00:11:47.523470: train_loss -0.8432 
2025-04-18 00:11:47.524275: val_loss -0.7836 
2025-04-18 00:11:47.524572: Pseudo dice [np.float32(0.8449), np.float32(0.9312)] 
2025-04-18 00:11:47.524897: Epoch time: 219.9 s 
2025-04-18 00:11:48.584877:  
2025-04-18 00:11:48.585366: Epoch 912 
2025-04-18 00:11:48.585695: Current learning rate: 0.00112 
2025-04-18 00:15:29.182765: train_loss -0.8473 
2025-04-18 00:15:29.187110: val_loss -0.7825 
2025-04-18 00:15:29.187440: Pseudo dice [np.float32(0.8502), np.float32(0.9192)] 
2025-04-18 00:15:29.187769: Epoch time: 220.6 s 
2025-04-18 00:15:30.203858:  
2025-04-18 00:15:30.204310: Epoch 913 
2025-04-18 00:15:30.204634: Current learning rate: 0.00111 
2025-04-18 00:19:10.118861: train_loss -0.8498 
2025-04-18 00:19:10.119727: val_loss -0.7975 
2025-04-18 00:19:10.120022: Pseudo dice [np.float32(0.8878), np.float32(0.9336)] 
2025-04-18 00:19:10.120312: Epoch time: 219.92 s 
2025-04-18 00:19:11.173415:  
2025-04-18 00:19:11.173913: Epoch 914 
2025-04-18 00:19:11.174232: Current learning rate: 0.0011 
2025-04-18 00:22:50.030246: train_loss -0.8572 
2025-04-18 00:22:50.034271: val_loss -0.7837 
2025-04-18 00:22:50.034573: Pseudo dice [np.float32(0.8918), np.float32(0.9206)] 
2025-04-18 00:22:50.034864: Epoch time: 218.86 s 
2025-04-18 00:22:51.079548:  
2025-04-18 00:22:51.080041: Epoch 915 
2025-04-18 00:22:51.080370: Current learning rate: 0.00109 
2025-04-18 00:26:29.667081: train_loss -0.8456 
2025-04-18 00:26:29.667908: val_loss -0.7761 
2025-04-18 00:26:29.668220: Pseudo dice [np.float32(0.8566), np.float32(0.9097)] 
2025-04-18 00:26:29.668521: Epoch time: 218.59 s 
2025-04-18 00:26:30.708735:  
2025-04-18 00:26:30.709263: Epoch 916 
2025-04-18 00:26:30.709598: Current learning rate: 0.00108 
2025-04-18 00:30:09.005827: train_loss -0.8474 
2025-04-18 00:30:09.009399: val_loss -0.7974 
2025-04-18 00:30:09.009723: Pseudo dice [np.float32(0.866), np.float32(0.9178)] 
2025-04-18 00:30:09.010424: Epoch time: 218.3 s 
2025-04-18 00:30:10.078460:  
2025-04-18 00:30:10.078961: Epoch 917 
2025-04-18 00:30:10.079307: Current learning rate: 0.00106 
2025-04-18 00:33:48.254936: train_loss -0.8369 
2025-04-18 00:33:48.255964: val_loss -0.7901 
2025-04-18 00:33:48.256261: Pseudo dice [np.float32(0.8683), np.float32(0.9237)] 
2025-04-18 00:33:48.256555: Epoch time: 218.18 s 
2025-04-18 00:33:49.318327:  
2025-04-18 00:33:49.318858: Epoch 918 
2025-04-18 00:33:49.319176: Current learning rate: 0.00105 
2025-04-18 00:37:27.272140: train_loss -0.8481 
2025-04-18 00:37:27.276824: val_loss -0.8108 
2025-04-18 00:37:27.277133: Pseudo dice [np.float32(0.8977), np.float32(0.9282)] 
2025-04-18 00:37:27.277424: Epoch time: 217.96 s 
2025-04-18 00:37:27.277692: Yayy! New best EMA pseudo Dice: 0.8953999876976013 
2025-04-18 00:37:28.777651:  
2025-04-18 00:37:28.778263: Epoch 919 
2025-04-18 00:37:28.778600: Current learning rate: 0.00104 
2025-04-18 00:41:06.817198: train_loss -0.8392 
2025-04-18 00:41:06.817887: val_loss -0.7838 
2025-04-18 00:41:06.818177: Pseudo dice [np.float32(0.8805), np.float32(0.9266)] 
2025-04-18 00:41:06.818470: Epoch time: 218.04 s 
2025-04-18 00:41:06.818737: Yayy! New best EMA pseudo Dice: 0.8962000012397766 
2025-04-18 00:41:08.290444:  
2025-04-18 00:41:08.290928: Epoch 920 
2025-04-18 00:41:08.291273: Current learning rate: 0.00103 
2025-04-18 00:44:47.288543: train_loss -0.8439 
2025-04-18 00:44:47.292001: val_loss -0.7745 
2025-04-18 00:44:47.292304: Pseudo dice [np.float32(0.8979), np.float32(0.9136)] 
2025-04-18 00:44:47.292594: Epoch time: 219.0 s 
2025-04-18 00:44:47.292872: Yayy! New best EMA pseudo Dice: 0.8970999717712402 
2025-04-18 00:44:48.756469:  
2025-04-18 00:44:48.757033: Epoch 921 
2025-04-18 00:44:48.757362: Current learning rate: 0.00102 
2025-04-18 00:48:27.124990: train_loss -0.8502 
2025-04-18 00:48:27.125732: val_loss -0.8072 
2025-04-18 00:48:27.126034: Pseudo dice [np.float32(0.907), np.float32(0.9338)] 
2025-04-18 00:48:27.126334: Epoch time: 218.37 s 
2025-04-18 00:48:27.126611: Yayy! New best EMA pseudo Dice: 0.8995000123977661 
2025-04-18 00:48:28.669287:  
2025-04-18 00:48:28.669902: Epoch 922 
2025-04-18 00:48:28.670246: Current learning rate: 0.00101 
2025-04-18 00:52:06.716950: train_loss -0.8564 
2025-04-18 00:52:06.720670: val_loss -0.7805 
2025-04-18 00:52:06.720997: Pseudo dice [np.float32(0.8725), np.float32(0.9221)] 
2025-04-18 00:52:06.721310: Epoch time: 218.05 s 
2025-04-18 00:52:07.776552:  
2025-04-18 00:52:07.777046: Epoch 923 
2025-04-18 00:52:07.777367: Current learning rate: 0.001 
2025-04-18 00:55:45.484329: train_loss -0.8447 
2025-04-18 00:55:45.485179: val_loss -0.8039 
2025-04-18 00:55:45.485472: Pseudo dice [np.float32(0.8764), np.float32(0.9305)] 
2025-04-18 00:55:45.485776: Epoch time: 217.71 s 
2025-04-18 00:55:45.486146: Yayy! New best EMA pseudo Dice: 0.8996999859809875 
2025-04-18 00:55:46.988484:  
2025-04-18 00:55:46.989007: Epoch 924 
2025-04-18 00:55:46.989346: Current learning rate: 0.00098 
2025-04-18 00:59:24.418705: train_loss -0.8413 
2025-04-18 00:59:24.422734: val_loss -0.7623 
2025-04-18 00:59:24.423082: Pseudo dice [np.float32(0.8312), np.float32(0.9168)] 
2025-04-18 00:59:24.423389: Epoch time: 217.43 s 
2025-04-18 00:59:25.467976:  
2025-04-18 00:59:25.468521: Epoch 925 
2025-04-18 00:59:25.468867: Current learning rate: 0.00097 
2025-04-18 01:03:03.639142: train_loss -0.8339 
2025-04-18 01:03:03.640040: val_loss -0.7552 
2025-04-18 01:03:03.640340: Pseudo dice [np.float32(0.8272), np.float32(0.9087)] 
2025-04-18 01:03:03.640645: Epoch time: 218.17 s 
2025-04-18 01:03:04.687663:  
2025-04-18 01:03:04.688154: Epoch 926 
2025-04-18 01:03:04.688494: Current learning rate: 0.00096 
2025-04-18 01:06:43.091078: train_loss -0.8484 
2025-04-18 01:06:43.094919: val_loss -0.768 
2025-04-18 01:06:43.095264: Pseudo dice [np.float32(0.8593), np.float32(0.9142)] 
2025-04-18 01:06:43.095576: Epoch time: 218.41 s 
2025-04-18 01:06:44.995903:  
2025-04-18 01:06:44.996422: Epoch 927 
2025-04-18 01:06:44.996759: Current learning rate: 0.00095 
2025-04-18 01:10:23.792079: train_loss -0.8455 
2025-04-18 01:10:23.798197: val_loss -0.7787 
2025-04-18 01:10:23.798607: Pseudo dice [np.float32(0.861), np.float32(0.9151)] 
2025-04-18 01:10:23.798922: Epoch time: 218.8 s 
2025-04-18 01:10:24.881860:  
2025-04-18 01:10:24.882362: Epoch 928 
2025-04-18 01:10:24.882672: Current learning rate: 0.00094 
2025-04-18 01:14:03.848009: train_loss -0.8493 
2025-04-18 01:14:03.852424: val_loss -0.7782 
2025-04-18 01:14:03.852766: Pseudo dice [np.float32(0.8726), np.float32(0.9059)] 
2025-04-18 01:14:03.853066: Epoch time: 218.97 s 
2025-04-18 01:14:04.904250:  
2025-04-18 01:14:04.904755: Epoch 929 
2025-04-18 01:14:04.905067: Current learning rate: 0.00092 
2025-04-18 01:17:43.517565: train_loss -0.8482 
2025-04-18 01:17:43.518254: val_loss -0.8021 
2025-04-18 01:17:43.518520: Pseudo dice [np.float32(0.8685), np.float32(0.9304)] 
2025-04-18 01:17:43.518900: Epoch time: 218.62 s 
2025-04-18 01:17:44.567467:  
2025-04-18 01:17:44.567967: Epoch 930 
2025-04-18 01:17:44.568281: Current learning rate: 0.00091 
2025-04-18 01:21:21.859295: train_loss -0.8416 
2025-04-18 01:21:21.863128: val_loss -0.7963 
2025-04-18 01:21:21.863478: Pseudo dice [np.float32(0.8812), np.float32(0.9266)] 
2025-04-18 01:21:21.863824: Epoch time: 217.29 s 
2025-04-18 01:21:22.914108:  
2025-04-18 01:21:22.914537: Epoch 931 
2025-04-18 01:21:22.914840: Current learning rate: 0.0009 
2025-04-18 01:25:00.715161: train_loss -0.852 
2025-04-18 01:25:00.715971: val_loss -0.7853 
2025-04-18 01:25:00.716268: Pseudo dice [np.float32(0.8713), np.float32(0.9085)] 
2025-04-18 01:25:00.716562: Epoch time: 217.8 s 
2025-04-18 01:25:01.779681:  
2025-04-18 01:25:01.780366: Epoch 932 
2025-04-18 01:25:01.780711: Current learning rate: 0.00089 
2025-04-18 01:28:39.642477: train_loss -0.8429 
2025-04-18 01:28:39.646014: val_loss -0.8024 
2025-04-18 01:28:39.646329: Pseudo dice [np.float32(0.8894), np.float32(0.9138)] 
2025-04-18 01:28:39.646612: Epoch time: 217.87 s 
2025-04-18 01:28:40.701577:  
2025-04-18 01:28:40.702023: Epoch 933 
2025-04-18 01:28:40.702329: Current learning rate: 0.00088 
2025-04-18 01:32:18.354110: train_loss -0.8403 
2025-04-18 01:32:18.354920: val_loss -0.7902 
2025-04-18 01:32:18.355199: Pseudo dice [np.float32(0.8825), np.float32(0.9214)] 
2025-04-18 01:32:18.355483: Epoch time: 217.65 s 
2025-04-18 01:32:19.390889:  
2025-04-18 01:32:19.391390: Epoch 934 
2025-04-18 01:32:19.391715: Current learning rate: 0.00087 
2025-04-18 01:35:57.773896: train_loss -0.8455 
2025-04-18 01:35:57.777541: val_loss -0.7648 
2025-04-18 01:35:57.777899: Pseudo dice [np.float32(0.8504), np.float32(0.9192)] 
2025-04-18 01:35:57.778225: Epoch time: 218.39 s 
2025-04-18 01:35:58.808764:  
2025-04-18 01:35:58.809344: Epoch 935 
2025-04-18 01:35:58.809677: Current learning rate: 0.00085 
2025-04-18 01:39:37.883842: train_loss -0.8391 
2025-04-18 01:39:37.884637: val_loss -0.7811 
2025-04-18 01:39:37.884928: Pseudo dice [np.float32(0.8677), np.float32(0.9158)] 
2025-04-18 01:39:37.885222: Epoch time: 219.08 s 
2025-04-18 01:39:38.972769:  
2025-04-18 01:39:38.973303: Epoch 936 
2025-04-18 01:39:38.973607: Current learning rate: 0.00084 
2025-04-18 01:43:17.709286: train_loss -0.8419 
2025-04-18 01:43:17.712765: val_loss -0.778 
2025-04-18 01:43:17.713069: Pseudo dice [np.float32(0.8658), np.float32(0.9224)] 
2025-04-18 01:43:17.713342: Epoch time: 218.74 s 
2025-04-18 01:43:18.789835:  
2025-04-18 01:43:18.790368: Epoch 937 
2025-04-18 01:43:18.790710: Current learning rate: 0.00083 
2025-04-18 01:46:58.137164: train_loss -0.8438 
2025-04-18 01:46:58.137966: val_loss -0.7898 
2025-04-18 01:46:58.138241: Pseudo dice [np.float32(0.882), np.float32(0.9203)] 
2025-04-18 01:46:58.138527: Epoch time: 219.35 s 
2025-04-18 01:46:59.195259:  
2025-04-18 01:46:59.195709: Epoch 938 
2025-04-18 01:46:59.196022: Current learning rate: 0.00082 
2025-04-18 01:50:38.452716: train_loss -0.8476 
2025-04-18 01:50:38.456245: val_loss -0.7926 
2025-04-18 01:50:38.456564: Pseudo dice [np.float32(0.8821), np.float32(0.9315)] 
2025-04-18 01:50:38.457330: Epoch time: 219.26 s 
2025-04-18 01:50:39.523092:  
2025-04-18 01:50:39.523566: Epoch 939 
2025-04-18 01:50:39.523871: Current learning rate: 0.00081 
2025-04-18 01:54:18.563094: train_loss -0.8525 
2025-04-18 01:54:18.563903: val_loss -0.7862 
2025-04-18 01:54:18.564175: Pseudo dice [np.float32(0.876), np.float32(0.9278)] 
2025-04-18 01:54:18.564459: Epoch time: 219.04 s 
2025-04-18 01:54:19.614321:  
2025-04-18 01:54:19.614779: Epoch 940 
2025-04-18 01:54:19.615092: Current learning rate: 0.00079 
2025-04-18 01:57:58.133790: train_loss -0.8395 
2025-04-18 01:57:58.137537: val_loss -0.78 
2025-04-18 01:57:58.137871: Pseudo dice [np.float32(0.8834), np.float32(0.9239)] 
2025-04-18 01:57:58.138158: Epoch time: 218.52 s 
2025-04-18 01:57:59.198800:  
2025-04-18 01:57:59.199293: Epoch 941 
2025-04-18 01:57:59.199608: Current learning rate: 0.00078 
2025-04-18 02:01:37.645460: train_loss -0.848 
2025-04-18 02:01:37.646294: val_loss -0.8125 
2025-04-18 02:01:37.646573: Pseudo dice [np.float32(0.8664), np.float32(0.916)] 
2025-04-18 02:01:37.646868: Epoch time: 218.45 s 
2025-04-18 02:01:38.718010:  
2025-04-18 02:01:38.718548: Epoch 942 
2025-04-18 02:01:38.718874: Current learning rate: 0.00077 
2025-04-18 02:05:16.942765: train_loss -0.8557 
2025-04-18 02:05:16.948065: val_loss -0.784 
2025-04-18 02:05:16.948388: Pseudo dice [np.float32(0.8789), np.float32(0.9214)] 
2025-04-18 02:05:16.948667: Epoch time: 218.23 s 
2025-04-18 02:05:18.023558:  
2025-04-18 02:05:18.024163: Epoch 943 
2025-04-18 02:05:18.024483: Current learning rate: 0.00076 
2025-04-18 02:08:56.263173: train_loss -0.841 
2025-04-18 02:08:56.264000: val_loss -0.776 
2025-04-18 02:08:56.264277: Pseudo dice [np.float32(0.8573), np.float32(0.9307)] 
2025-04-18 02:08:56.264565: Epoch time: 218.24 s 
2025-04-18 02:08:57.317003:  
2025-04-18 02:08:57.317526: Epoch 944 
2025-04-18 02:08:57.317863: Current learning rate: 0.00075 
2025-04-18 02:12:35.746814: train_loss -0.8429 
2025-04-18 02:12:35.750279: val_loss -0.7947 
2025-04-18 02:12:35.750573: Pseudo dice [np.float32(0.8886), np.float32(0.9158)] 
2025-04-18 02:12:35.750851: Epoch time: 218.43 s 
2025-04-18 02:12:36.822137:  
2025-04-18 02:12:36.822628: Epoch 945 
2025-04-18 02:12:36.822934: Current learning rate: 0.00074 
2025-04-18 02:16:14.187004: train_loss -0.8385 
2025-04-18 02:16:14.187755: val_loss -0.7891 
2025-04-18 02:16:14.188040: Pseudo dice [np.float32(0.8936), np.float32(0.9275)] 
2025-04-18 02:16:14.188330: Epoch time: 217.37 s 
2025-04-18 02:16:15.256417:  
2025-04-18 02:16:15.256857: Epoch 946 
2025-04-18 02:16:15.257175: Current learning rate: 0.00072 
2025-04-18 02:19:53.713478: train_loss -0.8434 
2025-04-18 02:19:53.716974: val_loss -0.778 
2025-04-18 02:19:53.717261: Pseudo dice [np.float32(0.8636), np.float32(0.9186)] 
2025-04-18 02:19:53.717531: Epoch time: 218.46 s 
2025-04-18 02:19:54.756428:  
2025-04-18 02:19:54.756856: Epoch 947 
2025-04-18 02:19:54.757161: Current learning rate: 0.00071 
2025-04-18 02:23:33.388649: train_loss -0.8414 
2025-04-18 02:23:33.389515: val_loss -0.7871 
2025-04-18 02:23:33.389813: Pseudo dice [np.float32(0.8872), np.float32(0.9181)] 
2025-04-18 02:23:33.390116: Epoch time: 218.63 s 
2025-04-18 02:23:34.451458:  
2025-04-18 02:23:34.451996: Epoch 948 
2025-04-18 02:23:34.452312: Current learning rate: 0.0007 
2025-04-18 02:27:13.671776: train_loss -0.8475 
2025-04-18 02:27:13.675339: val_loss -0.7821 
2025-04-18 02:27:13.675622: Pseudo dice [np.float32(0.8699), np.float32(0.9264)] 
2025-04-18 02:27:13.675897: Epoch time: 219.22 s 
2025-04-18 02:27:14.726779:  
2025-04-18 02:27:14.727311: Epoch 949 
2025-04-18 02:27:14.727630: Current learning rate: 0.00069 
2025-04-18 02:31:15.686540: train_loss -0.852 
2025-04-18 02:31:15.687368: val_loss -0.7777 
2025-04-18 02:31:15.687643: Pseudo dice [np.float32(0.8736), np.float32(0.9221)] 
2025-04-18 02:31:15.687924: Epoch time: 240.96 s 
2025-04-18 02:31:17.238048:  
2025-04-18 02:31:17.238487: Epoch 950 
2025-04-18 02:31:17.238807: Current learning rate: 0.00067 
2025-04-18 02:36:02.390017: train_loss -0.8568 
2025-04-18 02:36:02.393764: val_loss -0.7701 
2025-04-18 02:36:02.394109: Pseudo dice [np.float32(0.8517), np.float32(0.9188)] 
2025-04-18 02:36:02.394424: Epoch time: 285.15 s 
2025-04-18 02:36:03.415349:  
2025-04-18 02:36:03.415862: Epoch 951 
2025-04-18 02:36:03.416185: Current learning rate: 0.00066 
2025-04-18 02:39:35.525163: train_loss -0.8517 
2025-04-18 02:39:35.526009: val_loss -0.8107 
2025-04-18 02:39:35.526315: Pseudo dice [np.float32(0.8778), np.float32(0.9204)] 
2025-04-18 02:39:35.526617: Epoch time: 212.11 s 
2025-04-18 02:39:36.578330:  
2025-04-18 02:39:36.578874: Epoch 952 
2025-04-18 02:39:36.579214: Current learning rate: 0.00065 
2025-04-18 02:43:08.444660: train_loss -0.8528 
2025-04-18 02:43:08.448920: val_loss -0.7816 
2025-04-18 02:43:08.449300: Pseudo dice [np.float32(0.8736), np.float32(0.9087)] 
2025-04-18 02:43:08.449615: Epoch time: 211.87 s 
2025-04-18 02:43:09.495082:  
2025-04-18 02:43:09.495545: Epoch 953 
2025-04-18 02:43:09.495870: Current learning rate: 0.00064 
2025-04-18 02:46:46.504678: train_loss -0.8455 
2025-04-18 02:46:46.505400: val_loss -0.7662 
2025-04-18 02:46:46.505695: Pseudo dice [np.float32(0.8569), np.float32(0.9138)] 
2025-04-18 02:46:46.506010: Epoch time: 217.01 s 
2025-04-18 02:46:47.595958:  
2025-04-18 02:46:47.596532: Epoch 954 
2025-04-18 02:46:47.596879: Current learning rate: 0.00063 
2025-04-18 02:50:25.342023: train_loss -0.8537 
2025-04-18 02:50:25.345683: val_loss -0.7776 
2025-04-18 02:50:25.346013: Pseudo dice [np.float32(0.8537), np.float32(0.9206)] 
2025-04-18 02:50:25.346327: Epoch time: 217.75 s 
2025-04-18 02:50:26.414943:  
2025-04-18 02:50:26.415467: Epoch 955 
2025-04-18 02:50:26.415787: Current learning rate: 0.00061 
2025-04-18 02:54:04.471274: train_loss -0.8521 
2025-04-18 02:54:04.472146: val_loss -0.7415 
2025-04-18 02:54:04.472517: Pseudo dice [np.float32(0.8537), np.float32(0.902)] 
2025-04-18 02:54:04.472873: Epoch time: 218.06 s 
2025-04-18 02:54:05.548388:  
2025-04-18 02:54:05.548945: Epoch 956 
2025-04-18 02:54:05.549278: Current learning rate: 0.0006 
2025-04-18 02:57:44.477351: train_loss -0.8512 
2025-04-18 02:57:44.480804: val_loss -0.738 
2025-04-18 02:57:44.481107: Pseudo dice [np.float32(0.8535), np.float32(0.9143)] 
2025-04-18 02:57:44.481394: Epoch time: 218.93 s 
2025-04-18 02:57:45.557642:  
2025-04-18 02:57:45.558186: Epoch 957 
2025-04-18 02:57:45.558527: Current learning rate: 0.00059 
2025-04-18 03:01:24.978136: train_loss -0.8548 
2025-04-18 03:01:24.978995: val_loss -0.7943 
2025-04-18 03:01:24.979297: Pseudo dice [np.float32(0.888), np.float32(0.9257)] 
2025-04-18 03:01:24.979594: Epoch time: 219.42 s 
2025-04-18 03:01:26.051062:  
2025-04-18 03:01:26.051684: Epoch 958 
2025-04-18 03:01:26.052022: Current learning rate: 0.00058 
2025-04-18 03:05:05.601380: train_loss -0.856 
2025-04-18 03:05:05.605097: val_loss -0.8009 
2025-04-18 03:05:05.605393: Pseudo dice [np.float32(0.8972), np.float32(0.9239)] 
2025-04-18 03:05:05.605717: Epoch time: 219.55 s 
2025-04-18 03:05:06.682348:  
2025-04-18 03:05:06.682922: Epoch 959 
2025-04-18 03:05:06.683269: Current learning rate: 0.00056 
2025-04-18 03:08:46.215832: train_loss -0.852 
2025-04-18 03:08:46.216589: val_loss -0.7883 
2025-04-18 03:08:46.216877: Pseudo dice [np.float32(0.8846), np.float32(0.9241)] 
2025-04-18 03:08:46.217172: Epoch time: 219.54 s 
2025-04-18 03:08:47.296774:  
2025-04-18 03:08:47.297375: Epoch 960 
2025-04-18 03:08:47.297729: Current learning rate: 0.00055 
2025-04-18 03:12:27.057733: train_loss -0.8461 
2025-04-18 03:12:27.060896: val_loss -0.7927 
2025-04-18 03:12:27.061225: Pseudo dice [np.float32(0.8864), np.float32(0.913)] 
2025-04-18 03:12:27.061521: Epoch time: 219.76 s 
2025-04-18 03:12:28.140692:  
2025-04-18 03:12:28.141211: Epoch 961 
2025-04-18 03:12:28.141555: Current learning rate: 0.00054 
2025-04-18 03:16:08.507658: train_loss -0.8422 
2025-04-18 03:16:08.508556: val_loss -0.785 
2025-04-18 03:16:08.508897: Pseudo dice [np.float32(0.8664), np.float32(0.9222)] 
2025-04-18 03:16:08.509230: Epoch time: 220.37 s 
2025-04-18 03:16:09.589200:  
2025-04-18 03:16:09.589795: Epoch 962 
2025-04-18 03:16:09.590146: Current learning rate: 0.00053 
2025-04-18 03:19:49.312691: train_loss -0.8482 
2025-04-18 03:19:49.316213: val_loss -0.7716 
2025-04-18 03:19:49.316535: Pseudo dice [np.float32(0.8769), np.float32(0.9208)] 
2025-04-18 03:19:49.316835: Epoch time: 219.73 s 
2025-04-18 03:19:50.372120:  
2025-04-18 03:19:50.372666: Epoch 963 
2025-04-18 03:19:50.373006: Current learning rate: 0.00051 
2025-04-18 03:23:30.246144: train_loss -0.8446 
2025-04-18 03:23:30.246988: val_loss -0.7837 
2025-04-18 03:23:30.247281: Pseudo dice [np.float32(0.8766), np.float32(0.9257)] 
2025-04-18 03:23:30.247565: Epoch time: 219.88 s 
2025-04-18 03:23:31.310977:  
2025-04-18 03:23:31.311562: Epoch 964 
2025-04-18 03:23:31.311906: Current learning rate: 0.0005 
2025-04-18 03:27:11.093964: train_loss -0.8547 
2025-04-18 03:27:11.097666: val_loss -0.7943 
2025-04-18 03:27:11.097999: Pseudo dice [np.float32(0.8689), np.float32(0.9169)] 
2025-04-18 03:27:11.098312: Epoch time: 219.79 s 
2025-04-18 03:27:12.194320:  
2025-04-18 03:27:12.194946: Epoch 965 
2025-04-18 03:27:12.195290: Current learning rate: 0.00049 
2025-04-18 03:30:51.907384: train_loss -0.8455 
2025-04-18 03:30:51.908242: val_loss -0.7944 
2025-04-18 03:30:51.908545: Pseudo dice [np.float32(0.8833), np.float32(0.9283)] 
2025-04-18 03:30:51.908853: Epoch time: 219.72 s 
2025-04-18 03:30:53.849079:  
2025-04-18 03:30:53.849623: Epoch 966 
2025-04-18 03:30:53.849963: Current learning rate: 0.00048 
2025-04-18 03:34:32.009784: train_loss -0.8583 
2025-04-18 03:34:32.013788: val_loss -0.7877 
2025-04-18 03:34:32.014131: Pseudo dice [np.float32(0.8523), np.float32(0.9245)] 
2025-04-18 03:34:32.014436: Epoch time: 218.16 s 
2025-04-18 03:34:33.064447:  
2025-04-18 03:34:33.064879: Epoch 967 
2025-04-18 03:34:33.065200: Current learning rate: 0.00046 
2025-04-18 03:38:11.128314: train_loss -0.854 
2025-04-18 03:38:11.129171: val_loss -0.8243 
2025-04-18 03:38:11.129483: Pseudo dice [np.float32(0.9046), np.float32(0.9372)] 
2025-04-18 03:38:11.129793: Epoch time: 218.07 s 
2025-04-18 03:38:12.223963:  
2025-04-18 03:38:12.224509: Epoch 968 
2025-04-18 03:38:12.224854: Current learning rate: 0.00045 
2025-04-18 03:41:49.574817: train_loss -0.8548 
2025-04-18 03:41:49.578610: val_loss -0.7866 
2025-04-18 03:41:49.578970: Pseudo dice [np.float32(0.8712), np.float32(0.9152)] 
2025-04-18 03:41:49.579290: Epoch time: 217.35 s 
2025-04-18 03:41:50.659428:  
2025-04-18 03:41:50.659935: Epoch 969 
2025-04-18 03:41:50.660265: Current learning rate: 0.00044 
2025-04-18 03:45:28.307603: train_loss -0.8545 
2025-04-18 03:45:28.308440: val_loss -0.7593 
2025-04-18 03:45:28.308758: Pseudo dice [np.float32(0.8738), np.float32(0.9298)] 
2025-04-18 03:45:28.309059: Epoch time: 217.65 s 
2025-04-18 03:45:29.379640:  
2025-04-18 03:45:29.380172: Epoch 970 
2025-04-18 03:45:29.380493: Current learning rate: 0.00043 
2025-04-18 03:49:06.734847: train_loss -0.855 
2025-04-18 03:49:06.738682: val_loss -0.775 
2025-04-18 03:49:06.739013: Pseudo dice [np.float32(0.8497), np.float32(0.92)] 
2025-04-18 03:49:06.739309: Epoch time: 217.36 s 
2025-04-18 03:49:07.818865:  
2025-04-18 03:49:07.819408: Epoch 971 
2025-04-18 03:49:07.819749: Current learning rate: 0.00041 
2025-04-18 03:52:44.819875: train_loss -0.8558 
2025-04-18 03:52:44.820852: val_loss -0.7839 
2025-04-18 03:52:44.821160: Pseudo dice [np.float32(0.8835), np.float32(0.9159)] 
2025-04-18 03:52:44.821496: Epoch time: 217.0 s 
2025-04-18 03:52:45.903460:  
2025-04-18 03:52:45.903927: Epoch 972 
2025-04-18 03:52:45.904272: Current learning rate: 0.0004 
2025-04-18 03:56:23.045442: train_loss -0.8513 
2025-04-18 03:56:23.049209: val_loss -0.8048 
2025-04-18 03:56:23.049579: Pseudo dice [np.float32(0.8891), np.float32(0.9281)] 
2025-04-18 03:56:23.049911: Epoch time: 217.14 s 
2025-04-18 03:56:24.121069:  
2025-04-18 03:56:24.121647: Epoch 973 
2025-04-18 03:56:24.122000: Current learning rate: 0.00039 
2025-04-18 04:00:01.477685: train_loss -0.8595 
2025-04-18 04:00:01.479088: val_loss -0.7957 
2025-04-18 04:00:01.479413: Pseudo dice [np.float32(0.8661), np.float32(0.9214)] 
2025-04-18 04:00:01.479725: Epoch time: 217.36 s 
2025-04-18 04:00:02.563724:  
2025-04-18 04:00:02.564229: Epoch 974 
2025-04-18 04:00:02.564573: Current learning rate: 0.00037 
2025-04-18 04:03:41.036213: train_loss -0.854 
2025-04-18 04:03:41.040398: val_loss -0.8107 
2025-04-18 04:03:41.040812: Pseudo dice [np.float32(0.8781), np.float32(0.9279)] 
2025-04-18 04:03:41.041141: Epoch time: 218.47 s 
2025-04-18 04:03:42.140033:  
2025-04-18 04:03:42.140526: Epoch 975 
2025-04-18 04:03:42.140850: Current learning rate: 0.00036 
2025-04-18 04:07:21.312060: train_loss -0.852 
2025-04-18 04:07:21.312969: val_loss -0.7711 
2025-04-18 04:07:21.313274: Pseudo dice [np.float32(0.8681), np.float32(0.917)] 
2025-04-18 04:07:21.313569: Epoch time: 219.17 s 
2025-04-18 04:07:22.402737:  
2025-04-18 04:07:22.403234: Epoch 976 
2025-04-18 04:07:22.403553: Current learning rate: 0.00035 
2025-04-18 04:11:01.760329: train_loss -0.8594 
2025-04-18 04:11:01.764115: val_loss -0.7522 
2025-04-18 04:11:01.764463: Pseudo dice [np.float32(0.8346), np.float32(0.9155)] 
2025-04-18 04:11:01.764857: Epoch time: 219.36 s 
2025-04-18 04:11:02.849241:  
2025-04-18 04:11:02.849826: Epoch 977 
2025-04-18 04:11:02.850166: Current learning rate: 0.00034 
2025-04-18 04:14:42.395238: train_loss -0.8662 
2025-04-18 04:14:42.396135: val_loss -0.8029 
2025-04-18 04:14:42.396425: Pseudo dice [np.float32(0.8914), np.float32(0.9318)] 
2025-04-18 04:14:42.396710: Epoch time: 219.55 s 
2025-04-18 04:14:43.481609:  
2025-04-18 04:14:43.482193: Epoch 978 
2025-04-18 04:14:43.482510: Current learning rate: 0.00032 
2025-04-18 04:18:22.496345: train_loss -0.8481 
2025-04-18 04:18:22.499934: val_loss -0.7716 
2025-04-18 04:18:22.500239: Pseudo dice [np.float32(0.8455), np.float32(0.9236)] 
2025-04-18 04:18:22.500533: Epoch time: 219.02 s 
2025-04-18 04:18:23.605459:  
2025-04-18 04:18:23.605976: Epoch 979 
2025-04-18 04:18:23.606384: Current learning rate: 0.00031 
2025-04-18 04:22:02.758327: train_loss -0.8559 
2025-04-18 04:22:02.759189: val_loss -0.7685 
2025-04-18 04:22:02.759490: Pseudo dice [np.float32(0.8286), np.float32(0.9218)] 
2025-04-18 04:22:02.759794: Epoch time: 219.16 s 
2025-04-18 04:22:03.858237:  
2025-04-18 04:22:03.858854: Epoch 980 
2025-04-18 04:22:03.859196: Current learning rate: 0.0003 
2025-04-18 04:25:42.324350: train_loss -0.8599 
2025-04-18 04:25:42.328064: val_loss -0.7868 
2025-04-18 04:25:42.328387: Pseudo dice [np.float32(0.8606), np.float32(0.9145)] 
2025-04-18 04:25:42.328699: Epoch time: 218.47 s 
2025-04-18 04:25:43.403983:  
2025-04-18 04:25:43.404640: Epoch 981 
2025-04-18 04:25:43.405005: Current learning rate: 0.00028 
2025-04-18 04:29:21.612889: train_loss -0.8448 
2025-04-18 04:29:21.613793: val_loss -0.7424 
2025-04-18 04:29:21.614085: Pseudo dice [np.float32(0.8185), np.float32(0.9122)] 
2025-04-18 04:29:21.614376: Epoch time: 218.21 s 
2025-04-18 04:29:22.703664:  
2025-04-18 04:29:22.704191: Epoch 982 
2025-04-18 04:29:22.704504: Current learning rate: 0.00027 
2025-04-18 04:33:00.350528: train_loss -0.8488 
2025-04-18 04:33:00.355077: val_loss -0.7783 
2025-04-18 04:33:00.355482: Pseudo dice [np.float32(0.8682), np.float32(0.9133)] 
2025-04-18 04:33:00.355848: Epoch time: 217.65 s 
2025-04-18 04:33:01.467185:  
2025-04-18 04:33:01.467801: Epoch 983 
2025-04-18 04:33:01.468173: Current learning rate: 0.00026 
2025-04-18 04:36:39.069955: train_loss -0.8557 
2025-04-18 04:36:39.070760: val_loss -0.8096 
2025-04-18 04:36:39.071076: Pseudo dice [np.float32(0.8866), np.float32(0.9298)] 
2025-04-18 04:36:39.071372: Epoch time: 217.61 s 
2025-04-18 04:36:40.187842:  
2025-04-18 04:36:40.188399: Epoch 984 
2025-04-18 04:36:40.188725: Current learning rate: 0.00024 
2025-04-18 04:40:17.161162: train_loss -0.8535 
2025-04-18 04:40:17.164785: val_loss -0.7754 
2025-04-18 04:40:17.165130: Pseudo dice [np.float32(0.8575), np.float32(0.9056)] 
2025-04-18 04:40:17.165445: Epoch time: 216.98 s 
2025-04-18 04:40:19.053787:  
2025-04-18 04:40:19.054272: Epoch 985 
2025-04-18 04:40:19.054593: Current learning rate: 0.00023 
2025-04-18 04:43:56.475220: train_loss -0.8458 
2025-04-18 04:43:56.475994: val_loss -0.791 
2025-04-18 04:43:56.476290: Pseudo dice [np.float32(0.8761), np.float32(0.926)] 
2025-04-18 04:43:56.476579: Epoch time: 217.42 s 
2025-04-18 04:43:57.528715:  
2025-04-18 04:43:57.529186: Epoch 986 
2025-04-18 04:43:57.529489: Current learning rate: 0.00021 
2025-04-18 04:47:35.709041: train_loss -0.8634 
2025-04-18 04:47:35.712791: val_loss -0.8141 
2025-04-18 04:47:35.713163: Pseudo dice [np.float32(0.8973), np.float32(0.9258)] 
2025-04-18 04:47:35.713484: Epoch time: 218.18 s 
2025-04-18 04:47:36.772163:  
2025-04-18 04:47:36.772703: Epoch 987 
2025-04-18 04:47:36.773056: Current learning rate: 0.0002 
2025-04-18 04:51:15.071788: train_loss -0.8548 
2025-04-18 04:51:15.072654: val_loss -0.8032 
2025-04-18 04:51:15.072972: Pseudo dice [np.float32(0.879), np.float32(0.9341)] 
2025-04-18 04:51:15.073263: Epoch time: 218.3 s 
2025-04-18 04:51:16.143559:  
2025-04-18 04:51:16.144030: Epoch 988 
2025-04-18 04:51:16.144363: Current learning rate: 0.00019 
2025-04-18 04:54:53.784737: train_loss -0.847 
2025-04-18 04:54:53.788481: val_loss -0.7998 
2025-04-18 04:54:53.788817: Pseudo dice [np.float32(0.853), np.float32(0.928)] 
2025-04-18 04:54:53.789143: Epoch time: 217.64 s 
2025-04-18 04:54:54.857063:  
2025-04-18 04:54:54.857697: Epoch 989 
2025-04-18 04:54:54.858059: Current learning rate: 0.00017 
2025-04-18 04:58:31.665615: train_loss -0.8682 
2025-04-18 04:58:31.666431: val_loss -0.7904 
2025-04-18 04:58:31.666750: Pseudo dice [np.float32(0.8673), np.float32(0.9205)] 
2025-04-18 04:58:31.667051: Epoch time: 216.81 s 
2025-04-18 04:58:32.725413:  
2025-04-18 04:58:32.725865: Epoch 990 
2025-04-18 04:58:32.726178: Current learning rate: 0.00016 
2025-04-18 05:02:09.539251: train_loss -0.858 
2025-04-18 05:02:09.542944: val_loss -0.7974 
2025-04-18 05:02:09.543278: Pseudo dice [np.float32(0.8946), np.float32(0.9282)] 
2025-04-18 05:02:09.543579: Epoch time: 216.82 s 
2025-04-18 05:02:10.628772:  
2025-04-18 05:02:10.629252: Epoch 991 
2025-04-18 05:02:10.629560: Current learning rate: 0.00014 
2025-04-18 05:05:48.209280: train_loss -0.8642 
2025-04-18 05:05:48.210122: val_loss -0.804 
2025-04-18 05:05:48.210421: Pseudo dice [np.float32(0.8737), np.float32(0.9233)] 
2025-04-18 05:05:48.210703: Epoch time: 217.58 s 
2025-04-18 05:05:49.304581:  
2025-04-18 05:05:49.305099: Epoch 992 
2025-04-18 05:05:49.305431: Current learning rate: 0.00013 
2025-04-18 05:09:27.089706: train_loss -0.8575 
2025-04-18 05:09:27.093215: val_loss -0.7701 
2025-04-18 05:09:27.093524: Pseudo dice [np.float32(0.8634), np.float32(0.9238)] 
2025-04-18 05:09:27.093832: Epoch time: 217.79 s 
2025-04-18 05:09:28.155819:  
2025-04-18 05:09:28.156338: Epoch 993 
2025-04-18 05:09:28.156687: Current learning rate: 0.00011 
2025-04-18 05:13:06.528170: train_loss -0.8624 
2025-04-18 05:13:06.528943: val_loss -0.7835 
2025-04-18 05:13:06.529233: Pseudo dice [np.float32(0.8611), np.float32(0.9187)] 
2025-04-18 05:13:06.529515: Epoch time: 218.37 s 
2025-04-18 05:13:07.603818:  
2025-04-18 05:13:07.604347: Epoch 994 
2025-04-18 05:13:07.604689: Current learning rate: 0.0001 
2025-04-18 05:16:46.068953: train_loss -0.8488 
2025-04-18 05:16:46.072678: val_loss -0.7944 
2025-04-18 05:16:46.073013: Pseudo dice [np.float32(0.8875), np.float32(0.9228)] 
2025-04-18 05:16:46.073312: Epoch time: 218.47 s 
2025-04-18 05:16:47.151519:  
2025-04-18 05:16:47.152056: Epoch 995 
2025-04-18 05:16:47.152372: Current learning rate: 8e-05 
2025-04-18 05:20:25.766753: train_loss -0.8591 
2025-04-18 05:20:25.767553: val_loss -0.7884 
2025-04-18 05:20:25.767890: Pseudo dice [np.float32(0.8859), np.float32(0.9218)] 
2025-04-18 05:20:25.768201: Epoch time: 218.62 s 
2025-04-18 05:20:26.909374:  
2025-04-18 05:20:26.909848: Epoch 996 
2025-04-18 05:20:26.910176: Current learning rate: 7e-05 
2025-04-18 05:24:05.137464: train_loss -0.852 
2025-04-18 05:24:05.140707: val_loss -0.7731 
2025-04-18 05:24:05.141269: Pseudo dice [np.float32(0.874), np.float32(0.9299)] 
2025-04-18 05:24:05.141560: Epoch time: 218.23 s 
2025-04-18 05:24:06.235648:  
2025-04-18 05:24:06.236179: Epoch 997 
2025-04-18 05:24:06.236500: Current learning rate: 5e-05 
2025-04-18 05:27:43.874975: train_loss -0.8672 
2025-04-18 05:27:43.875645: val_loss -0.7765 
2025-04-18 05:27:43.875939: Pseudo dice [np.float32(0.8653), np.float32(0.9242)] 
2025-04-18 05:27:43.876224: Epoch time: 217.64 s 
2025-04-18 05:27:44.990502:  
2025-04-18 05:27:44.990957: Epoch 998 
2025-04-18 05:27:44.991276: Current learning rate: 4e-05 
2025-04-18 05:31:22.401776: train_loss -0.8501 
2025-04-18 05:31:22.405264: val_loss -0.797 
2025-04-18 05:31:22.405611: Pseudo dice [np.float32(0.8684), np.float32(0.9242)] 
2025-04-18 05:31:22.405922: Epoch time: 217.41 s 
2025-04-18 05:31:23.504179:  
2025-04-18 05:31:23.504611: Epoch 999 
2025-04-18 05:31:23.504933: Current learning rate: 2e-05 
2025-04-18 05:35:00.899943: train_loss -0.8517 
2025-04-18 05:35:00.900672: val_loss -0.8155 
2025-04-18 05:35:00.901006: Pseudo dice [np.float32(0.8899), np.float32(0.9178)] 
2025-04-18 05:35:00.901301: Epoch time: 217.4 s 
2025-04-18 05:35:02.529009: Training done. 
2025-04-18 05:35:02.584478: Using splits from existing split file: /physical_sciences/DEEP-PSMA/GTRC_Baseline/nnUNet_data/preprocessed/Dataset802_FDG_PET/splits_final.json 
2025-04-18 05:35:02.585066: The split file contains 5 splits. 
2025-04-18 05:35:02.585318: Desired fold for training: 0 
2025-04-18 05:35:02.585562: This split has 80 training and 20 validation cases. 
2025-04-18 05:35:02.585958: predicting train_0005 
2025-04-18 05:35:02.842092: train_0005, shape torch.Size([2, 151, 335, 151]), rank 0 
2025-04-18 05:35:43.593472: predicting train_0010 
2025-04-18 05:35:43.872144: train_0010, shape torch.Size([2, 223, 290, 223]), rank 0 
2025-04-18 05:36:08.872558: predicting train_0014 
2025-04-18 05:36:09.140728: train_0014, shape torch.Size([2, 223, 277, 223]), rank 0 
2025-04-18 05:36:26.030256: predicting train_0021 
2025-04-18 05:36:26.176570: train_0021, shape torch.Size([2, 151, 335, 151]), rank 0 
2025-04-18 05:36:37.627118: predicting train_0026 
2025-04-18 05:36:37.743629: train_0026, shape torch.Size([2, 151, 299, 151]), rank 0 
2025-04-18 05:36:49.228816: predicting train_0029 
2025-04-18 05:36:49.525803: train_0029, shape torch.Size([2, 223, 311, 223]), rank 0 
2025-04-18 05:37:15.293016: predicting train_0034 
2025-04-18 05:37:15.430380: train_0034, shape torch.Size([2, 158, 312, 158]), rank 0 
2025-04-18 05:37:27.061430: predicting train_0036 
2025-04-18 05:37:27.297745: train_0036, shape torch.Size([2, 192, 335, 192]), rank 0 
2025-04-18 05:37:53.425484: predicting train_0041 
2025-04-18 05:37:53.729862: train_0041, shape torch.Size([2, 223, 309, 223]), rank 0 
2025-04-18 05:38:19.797855: predicting train_0043 
2025-04-18 05:38:19.934349: train_0043, shape torch.Size([2, 151, 335, 151]), rank 0 
2025-04-18 05:38:31.622861: predicting train_0050 
2025-04-18 05:38:31.838706: train_0050, shape torch.Size([2, 192, 335, 192]), rank 0 
2025-04-18 05:38:58.081078: predicting train_0052 
2025-04-18 05:38:58.217201: train_0052, shape torch.Size([2, 151, 335, 151]), rank 0 
2025-04-18 05:39:09.933918: predicting train_0061 
2025-04-18 05:39:10.116692: train_0061, shape torch.Size([2, 151, 407, 151]), rank 0 
2025-04-18 05:39:25.670627: predicting train_0064 
2025-04-18 05:39:25.990538: train_0064, shape torch.Size([2, 192, 429, 192]), rank 0 
2025-04-18 05:40:01.031909: predicting train_0066 
2025-04-18 05:40:01.179882: train_0066, shape torch.Size([2, 151, 335, 151]), rank 0 
2025-04-18 05:40:12.905909: predicting train_0070 
2025-04-18 05:40:13.035376: train_0070, shape torch.Size([2, 151, 335, 151]), rank 0 
2025-04-18 05:40:24.798405: predicting train_0076 
2025-04-18 05:40:24.936397: train_0076, shape torch.Size([2, 151, 335, 151]), rank 0 
2025-04-18 05:40:36.671574: predicting train_0079 
2025-04-18 05:40:36.949106: train_0079, shape torch.Size([2, 223, 284, 223]), rank 0 
2025-04-18 05:40:54.467509: predicting train_0087 
2025-04-18 05:40:54.881334: train_0087, shape torch.Size([2, 223, 309, 223]), rank 0 
2025-04-18 05:41:21.140166: predicting train_0089 
2025-04-18 05:41:21.267387: train_0089, shape torch.Size([2, 151, 299, 151]), rank 0 
2025-04-18 05:41:45.305580: Validation complete 
2025-04-18 05:41:45.308329: Mean Validation Dice:  0.878909310656098 
