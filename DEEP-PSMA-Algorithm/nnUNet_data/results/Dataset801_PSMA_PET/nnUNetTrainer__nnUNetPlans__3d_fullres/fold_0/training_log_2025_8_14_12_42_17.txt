
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-08-14 12:42:18.039872: Using torch.compile... 
2025-08-14 12:42:19.013968: do_dummy_2d_data_aug: False 
2025-08-14 12:42:19.014231: Using splits from existing split file: /home/jovyan/DEEP-PSMA/Baseline_Model/data/nnUNet_data/preprocessed/Dataset801_PSMA_PET/splits_final.json 
2025-08-14 12:42:19.014333: The split file contains 5 splits. 
2025-08-14 12:42:19.014363: Desired fold for training: 0 
2025-08-14 12:42:19.014380: This split has 80 training and 20 validation cases. 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [112, 192, 112], 'median_image_size_in_voxels': [183.0, 335.0, 183.0], 'spacing': [3.822916626930237, 3.2699999809265137, 3.822916626930237], 'normalization_schemes': ['NoNormalization', 'CTNormalization'], 'use_mask_for_norm': [False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [1, 2, 1]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset801_PSMA_PET', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [3.822916626930237, 3.2699999809265137, 3.822916626930237], 'original_median_shape_after_transp': [192, 335, 192], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [1, 0, 2], 'transpose_backward': [1, 0, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 122.71910858154297, 'mean': 2.8939762115478516, 'median': 1.8348745107650757, 'min': 0.9997730255126953, 'percentile_00_5': 1.0056307303905487, 'percentile_99_5': 20.265780572890208, 'std': 3.168104887008667}, '1': {'max': 3071.0, 'mean': 50.165374755859375, 'median': 33.0, 'min': -1024.0, 'percentile_00_5': -725.0, 'percentile_99_5': 976.0, 'std': 191.89183044433594}}} 
 
2025-08-14 12:42:27.087597: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-08-14 12:42:27.186436:  
2025-08-14 12:42:27.186505: Epoch 0 
2025-08-14 12:42:27.186621: Current learning rate: 0.01 
2025-08-14 12:45:40.886092: train_loss -0.4017 
2025-08-14 12:45:40.886239: val_loss -0.5959 
2025-08-14 12:45:40.886287: Pseudo dice [0.6147, 0.846] 
2025-08-14 12:45:40.886335: Epoch time: 193.7 s 
2025-08-14 12:45:40.886373: Yayy! New best EMA pseudo Dice: 0.7303 
2025-08-14 12:45:41.556585:  
2025-08-14 12:45:41.556668: Epoch 1 
2025-08-14 12:45:41.556732: Current learning rate: 0.00999 
2025-08-14 12:47:46.186637: train_loss -0.6381 
2025-08-14 12:47:46.186796: val_loss -0.6645 
2025-08-14 12:47:46.186840: Pseudo dice [0.7331, 0.9001] 
2025-08-14 12:47:46.186881: Epoch time: 124.63 s 
2025-08-14 12:47:46.186912: Yayy! New best EMA pseudo Dice: 0.7389 
2025-08-14 12:47:50.108772:  
2025-08-14 12:47:50.108851: Epoch 2 
2025-08-14 12:47:50.108917: Current learning rate: 0.00998 
2025-08-14 12:49:48.887156: train_loss -0.6795 
2025-08-14 12:49:48.887373: val_loss -0.6803 
2025-08-14 12:49:48.887420: Pseudo dice [0.7281, 0.8922] 
2025-08-14 12:49:48.887572: Epoch time: 118.78 s 
2025-08-14 12:49:48.887691: Yayy! New best EMA pseudo Dice: 0.7461 
2025-08-14 12:49:51.832692:  
2025-08-14 12:49:51.832771: Epoch 3 
2025-08-14 12:49:51.832837: Current learning rate: 0.00997 
2025-08-14 12:51:48.086537: train_loss -0.729 
2025-08-14 12:51:48.086720: val_loss -0.6979 
2025-08-14 12:51:48.086761: Pseudo dice [0.7819, 0.8706] 
2025-08-14 12:51:48.086803: Epoch time: 116.25 s 
2025-08-14 12:51:48.086834: Yayy! New best EMA pseudo Dice: 0.7541 
2025-08-14 12:51:52.266326:  
2025-08-14 12:51:52.266503: Epoch 4 
2025-08-14 12:51:52.266571: Current learning rate: 0.00996 
2025-08-14 12:53:50.886305: train_loss -0.7313 
2025-08-14 12:53:50.886451: val_loss -0.7164 
2025-08-14 12:53:50.886493: Pseudo dice [0.7891, 0.9096] 
2025-08-14 12:53:50.886533: Epoch time: 118.62 s 
2025-08-14 12:53:50.886563: Yayy! New best EMA pseudo Dice: 0.7636 
2025-08-14 12:53:54.540211:  
2025-08-14 12:53:54.540286: Epoch 5 
2025-08-14 12:53:54.540353: Current learning rate: 0.00995 
2025-08-14 12:55:56.692580: train_loss -0.7516 
2025-08-14 12:55:56.692700: val_loss -0.784 
2025-08-14 12:55:56.692740: Pseudo dice [0.8062, 0.9319] 
2025-08-14 12:55:56.692786: Epoch time: 122.15 s 
2025-08-14 12:55:56.692822: Yayy! New best EMA pseudo Dice: 0.7742 
2025-08-14 12:56:01.148282:  
2025-08-14 12:56:01.148393: Epoch 6 
2025-08-14 12:56:01.148468: Current learning rate: 0.00995 
2025-08-14 12:58:05.586759: train_loss -0.7648 
2025-08-14 12:58:05.586907: val_loss -0.7712 
2025-08-14 12:58:05.586946: Pseudo dice [0.832, 0.9189] 
2025-08-14 12:58:05.586987: Epoch time: 124.44 s 
2025-08-14 12:58:05.587018: Yayy! New best EMA pseudo Dice: 0.7843 
2025-08-14 12:58:09.348578:  
2025-08-14 12:58:09.348661: Epoch 7 
2025-08-14 12:58:09.348727: Current learning rate: 0.00994 
2025-08-14 13:00:08.787603: train_loss -0.7607 
2025-08-14 13:00:08.787750: val_loss -0.798 
2025-08-14 13:00:08.787793: Pseudo dice [0.8334, 0.9361] 
2025-08-14 13:00:08.787835: Epoch time: 119.44 s 
2025-08-14 13:00:08.787867: Yayy! New best EMA pseudo Dice: 0.7943 
2025-08-14 13:00:12.139455:  
2025-08-14 13:00:12.139539: Epoch 8 
2025-08-14 13:00:12.139605: Current learning rate: 0.00993 
2025-08-14 13:02:16.286413: train_loss -0.7544 
2025-08-14 13:02:16.286545: val_loss -0.7906 
2025-08-14 13:02:16.286587: Pseudo dice [0.8242, 0.9331] 
2025-08-14 13:02:16.286627: Epoch time: 124.15 s 
2025-08-14 13:02:16.286657: Yayy! New best EMA pseudo Dice: 0.8028 
2025-08-14 13:02:19.649947:  
2025-08-14 13:02:19.650033: Epoch 9 
2025-08-14 13:02:19.650104: Current learning rate: 0.00992 
2025-08-14 13:04:18.286661: train_loss -0.7782 
2025-08-14 13:04:18.286794: val_loss -0.7905 
2025-08-14 13:04:18.286834: Pseudo dice [0.8619, 0.9287] 
2025-08-14 13:04:18.286874: Epoch time: 118.64 s 
2025-08-14 13:04:18.286904: Yayy! New best EMA pseudo Dice: 0.812 
2025-08-14 13:04:21.758946:  
2025-08-14 13:04:21.759027: Epoch 10 
2025-08-14 13:04:21.759092: Current learning rate: 0.00991 
2025-08-14 13:06:18.186372: train_loss -0.7927 
2025-08-14 13:06:18.186526: val_loss -0.7626 
2025-08-14 13:06:18.186576: Pseudo dice [0.8456, 0.9233] 
2025-08-14 13:06:18.186627: Epoch time: 116.43 s 
2025-08-14 13:06:18.186669: Yayy! New best EMA pseudo Dice: 0.8193 
2025-08-14 13:06:21.950106:  
2025-08-14 13:06:21.950210: Epoch 11 
2025-08-14 13:06:21.950277: Current learning rate: 0.0099 
2025-08-14 13:08:19.287561: train_loss -0.7992 
2025-08-14 13:08:19.287739: val_loss -0.8295 
2025-08-14 13:08:19.287869: Pseudo dice [0.871, 0.945] 
2025-08-14 13:08:19.288165: Epoch time: 117.34 s 
2025-08-14 13:08:19.288254: Yayy! New best EMA pseudo Dice: 0.8281 
2025-08-14 13:08:22.575468:  
2025-08-14 13:08:22.575638: Epoch 12 
2025-08-14 13:08:22.575754: Current learning rate: 0.00989 
2025-08-14 13:10:14.986777: train_loss -0.795 
2025-08-14 13:10:14.986902: val_loss -0.7988 
2025-08-14 13:10:14.986943: Pseudo dice [0.8646, 0.9306] 
2025-08-14 13:10:14.986983: Epoch time: 112.41 s 
2025-08-14 13:10:14.987013: Yayy! New best EMA pseudo Dice: 0.8351 
2025-08-14 13:10:18.505016:  
2025-08-14 13:10:18.505157: Epoch 13 
2025-08-14 13:10:18.505241: Current learning rate: 0.00988 
2025-08-14 13:12:14.886223: train_loss -0.8017 
2025-08-14 13:12:14.886364: val_loss -0.791 
2025-08-14 13:12:14.886410: Pseudo dice [0.8592, 0.9155] 
2025-08-14 13:12:14.886461: Epoch time: 116.38 s 
2025-08-14 13:12:14.886493: Yayy! New best EMA pseudo Dice: 0.8403 
2025-08-14 13:12:18.111695:  
2025-08-14 13:12:18.111827: Epoch 14 
2025-08-14 13:12:18.111895: Current learning rate: 0.00987 
2025-08-14 13:14:18.886532: train_loss -0.7983 
2025-08-14 13:14:18.886685: val_loss -0.7809 
2025-08-14 13:14:18.886725: Pseudo dice [0.8172, 0.9046] 
2025-08-14 13:14:18.886767: Epoch time: 120.78 s 
2025-08-14 13:14:18.886796: Yayy! New best EMA pseudo Dice: 0.8424 
2025-08-14 13:14:22.321743:  
2025-08-14 13:14:22.321848: Epoch 15 
2025-08-14 13:14:22.321916: Current learning rate: 0.00986 
2025-08-14 13:16:15.886693: train_loss -0.8083 
2025-08-14 13:16:15.886845: val_loss -0.8032 
2025-08-14 13:16:15.886886: Pseudo dice [0.8693, 0.9105] 
2025-08-14 13:16:15.886929: Epoch time: 113.57 s 
2025-08-14 13:16:15.886959: Yayy! New best EMA pseudo Dice: 0.8471 
2025-08-14 13:16:18.989038:  
2025-08-14 13:16:18.989117: Epoch 16 
2025-08-14 13:16:18.989182: Current learning rate: 0.00986 
2025-08-14 13:18:10.791297: train_loss -0.7963 
2025-08-14 13:18:10.791484: val_loss -0.779 
2025-08-14 13:18:10.791528: Pseudo dice [0.8339, 0.9036] 
2025-08-14 13:18:10.791569: Epoch time: 111.8 s 
2025-08-14 13:18:10.791598: Yayy! New best EMA pseudo Dice: 0.8493 
2025-08-14 13:18:14.234181:  
2025-08-14 13:18:14.234259: Epoch 17 
2025-08-14 13:18:14.234323: Current learning rate: 0.00985 
2025-08-14 13:20:15.786366: train_loss -0.798 
2025-08-14 13:20:15.786603: val_loss -0.8143 
2025-08-14 13:20:15.786694: Pseudo dice [0.8751, 0.932] 
2025-08-14 13:20:15.786765: Epoch time: 121.55 s 
2025-08-14 13:20:15.786811: Yayy! New best EMA pseudo Dice: 0.8547 
2025-08-14 13:20:19.179310:  
2025-08-14 13:20:19.179408: Epoch 18 
2025-08-14 13:20:19.179484: Current learning rate: 0.00984 
2025-08-14 13:22:20.987727: train_loss -0.7915 
2025-08-14 13:22:20.987924: val_loss -0.8076 
2025-08-14 13:22:20.987967: Pseudo dice [0.8737, 0.9393] 
2025-08-14 13:22:20.988013: Epoch time: 121.81 s 
2025-08-14 13:22:20.988047: Yayy! New best EMA pseudo Dice: 0.8599 
2025-08-14 13:22:24.517366:  
2025-08-14 13:22:24.517444: Epoch 19 
2025-08-14 13:22:24.517503: Current learning rate: 0.00983 
2025-08-14 13:24:24.286118: train_loss -0.8091 
2025-08-14 13:24:24.286313: val_loss -0.8083 
2025-08-14 13:24:24.286361: Pseudo dice [0.8691, 0.9344] 
2025-08-14 13:24:24.286409: Epoch time: 119.77 s 
2025-08-14 13:24:24.286453: Yayy! New best EMA pseudo Dice: 0.8641 
2025-08-14 13:24:27.699981:  
2025-08-14 13:24:27.700063: Epoch 20 
2025-08-14 13:24:27.700129: Current learning rate: 0.00982 
2025-08-14 13:26:24.686116: train_loss -0.8194 
2025-08-14 13:26:24.686359: val_loss -0.8463 
2025-08-14 13:26:24.686471: Pseudo dice [0.8918, 0.9454] 
2025-08-14 13:26:24.686563: Epoch time: 116.99 s 
2025-08-14 13:26:24.686633: Yayy! New best EMA pseudo Dice: 0.8695 
2025-08-14 13:26:27.856844:  
2025-08-14 13:26:27.856943: Epoch 21 
2025-08-14 13:26:27.857026: Current learning rate: 0.00981 
2025-08-14 13:28:27.386803: train_loss -0.8148 
2025-08-14 13:28:27.386939: val_loss -0.7655 
2025-08-14 13:28:27.386979: Pseudo dice [0.8369, 0.9267] 
2025-08-14 13:28:27.387019: Epoch time: 119.53 s 
2025-08-14 13:28:27.387048: Yayy! New best EMA pseudo Dice: 0.8708 
2025-08-14 13:28:30.608700:  
2025-08-14 13:28:30.608783: Epoch 22 
2025-08-14 13:28:30.608847: Current learning rate: 0.0098 
2025-08-14 13:30:25.186566: train_loss -0.8072 
2025-08-14 13:30:25.186745: val_loss -0.7824 
2025-08-14 13:30:25.186801: Pseudo dice [0.8486, 0.9059] 
2025-08-14 13:30:25.186848: Epoch time: 114.58 s 
2025-08-14 13:30:25.186882: Yayy! New best EMA pseudo Dice: 0.8714 
2025-08-14 13:30:27.997848:  
2025-08-14 13:30:27.997926: Epoch 23 
2025-08-14 13:30:27.997994: Current learning rate: 0.00979 
2025-08-14 13:32:25.787824: train_loss -0.8071 
2025-08-14 13:32:25.788036: val_loss -0.8395 
2025-08-14 13:32:25.788081: Pseudo dice [0.8729, 0.9421] 
2025-08-14 13:32:25.788126: Epoch time: 117.79 s 
2025-08-14 13:32:25.788159: Yayy! New best EMA pseudo Dice: 0.875 
2025-08-14 13:32:29.398197:  
2025-08-14 13:32:29.398339: Epoch 24 
2025-08-14 13:32:29.398407: Current learning rate: 0.00978 
2025-08-14 13:34:33.986498: train_loss -0.807 
2025-08-14 13:34:33.986637: val_loss -0.823 
2025-08-14 13:34:33.986679: Pseudo dice [0.8743, 0.9408] 
2025-08-14 13:34:33.986722: Epoch time: 124.59 s 
2025-08-14 13:34:33.986752: Yayy! New best EMA pseudo Dice: 0.8783 
2025-08-14 13:34:37.760026:  
2025-08-14 13:34:37.760118: Epoch 25 
2025-08-14 13:34:37.760194: Current learning rate: 0.00977 
2025-08-14 13:36:38.885941: train_loss -0.8198 
2025-08-14 13:36:38.886074: val_loss -0.7938 
2025-08-14 13:36:38.890686: Pseudo dice [0.8227, 0.9027] 
2025-08-14 13:36:38.890813: Epoch time: 121.13 s 
2025-08-14 13:36:40.443464:  
2025-08-14 13:36:40.443609: Epoch 26 
2025-08-14 13:36:40.443683: Current learning rate: 0.00977 
2025-08-14 13:38:35.686392: train_loss -0.8138 
2025-08-14 13:38:35.686528: val_loss -0.7989 
2025-08-14 13:38:35.686570: Pseudo dice [0.8349, 0.9228] 
2025-08-14 13:38:35.686609: Epoch time: 115.24 s 
2025-08-14 13:38:37.215477:  
2025-08-14 13:38:37.215568: Epoch 27 
2025-08-14 13:38:37.215635: Current learning rate: 0.00976 
2025-08-14 13:40:32.688554: train_loss -0.7979 
2025-08-14 13:40:32.688710: val_loss -0.813 
2025-08-14 13:40:32.688752: Pseudo dice [0.8682, 0.9115] 
2025-08-14 13:40:32.688878: Epoch time: 115.47 s 
2025-08-14 13:40:35.592903:  
2025-08-14 13:40:35.592996: Epoch 28 
2025-08-14 13:40:35.593062: Current learning rate: 0.00975 
2025-08-14 13:42:34.586501: train_loss -0.8192 
2025-08-14 13:42:34.586694: val_loss -0.8505 
2025-08-14 13:42:34.586748: Pseudo dice [0.876, 0.9335] 
2025-08-14 13:42:34.586799: Epoch time: 118.99 s 
2025-08-14 13:42:34.586833: Yayy! New best EMA pseudo Dice: 0.8809 
2025-08-14 13:42:38.312508:  
2025-08-14 13:42:38.312639: Epoch 29 
2025-08-14 13:42:38.312709: Current learning rate: 0.00974 
2025-08-14 13:44:40.886493: train_loss -0.8324 
2025-08-14 13:44:40.886630: val_loss -0.8442 
2025-08-14 13:44:40.886670: Pseudo dice [0.8735, 0.9485] 
2025-08-14 13:44:40.886709: Epoch time: 122.57 s 
2025-08-14 13:44:40.886738: Yayy! New best EMA pseudo Dice: 0.8839 
2025-08-14 13:44:44.564449:  
2025-08-14 13:44:44.564534: Epoch 30 
2025-08-14 13:44:44.564584: Current learning rate: 0.00973 
2025-08-14 13:46:49.486703: train_loss -0.8218 
2025-08-14 13:46:49.486813: val_loss -0.8235 
2025-08-14 13:46:49.486853: Pseudo dice [0.8801, 0.9234] 
2025-08-14 13:46:49.486891: Epoch time: 124.92 s 
2025-08-14 13:46:49.486919: Yayy! New best EMA pseudo Dice: 0.8857 
2025-08-14 13:46:52.436722:  
2025-08-14 13:46:52.436805: Epoch 31 
2025-08-14 13:46:52.436868: Current learning rate: 0.00972 
2025-08-14 13:48:44.486626: train_loss -0.8194 
2025-08-14 13:48:44.486762: val_loss -0.8267 
2025-08-14 13:48:44.486803: Pseudo dice [0.8714, 0.9318] 
2025-08-14 13:48:44.486843: Epoch time: 112.05 s 
2025-08-14 13:48:44.486873: Yayy! New best EMA pseudo Dice: 0.8873 
2025-08-14 13:48:47.603799:  
2025-08-14 13:48:47.603892: Epoch 32 
2025-08-14 13:48:47.603959: Current learning rate: 0.00971 
2025-08-14 13:50:42.686142: train_loss -0.8243 
2025-08-14 13:50:42.686301: val_loss -0.8346 
2025-08-14 13:50:42.686342: Pseudo dice [0.8921, 0.9296] 
2025-08-14 13:50:42.686392: Epoch time: 115.08 s 
2025-08-14 13:50:42.686421: Yayy! New best EMA pseudo Dice: 0.8896 
2025-08-14 13:50:45.406894:  
2025-08-14 13:50:45.406979: Epoch 33 
2025-08-14 13:50:45.407042: Current learning rate: 0.0097 
2025-08-14 13:52:45.486668: train_loss -0.8232 
2025-08-14 13:52:45.486840: val_loss -0.8407 
2025-08-14 13:52:45.486886: Pseudo dice [0.88, 0.9441] 
2025-08-14 13:52:45.486931: Epoch time: 120.08 s 
2025-08-14 13:52:45.486965: Yayy! New best EMA pseudo Dice: 0.8919 
2025-08-14 13:52:49.159087:  
2025-08-14 13:52:49.159180: Epoch 34 
2025-08-14 13:52:49.159263: Current learning rate: 0.00969 
2025-08-14 13:54:44.588793: train_loss -0.8175 
2025-08-14 13:54:44.588921: val_loss -0.8051 
2025-08-14 13:54:44.588961: Pseudo dice [0.8692, 0.898] 
2025-08-14 13:54:44.589001: Epoch time: 115.43 s 
2025-08-14 13:54:47.205999:  
2025-08-14 13:54:47.206087: Epoch 35 
2025-08-14 13:54:47.206154: Current learning rate: 0.00968 
2025-08-14 13:56:48.786512: train_loss -0.8196 
2025-08-14 13:56:48.786660: val_loss -0.8286 
2025-08-14 13:56:48.786706: Pseudo dice [0.8852, 0.9432] 
2025-08-14 13:56:48.786753: Epoch time: 121.58 s 
2025-08-14 13:56:48.786788: Yayy! New best EMA pseudo Dice: 0.8934 
2025-08-14 13:56:51.919405:  
2025-08-14 13:56:51.919497: Epoch 36 
2025-08-14 13:56:51.919601: Current learning rate: 0.00968 
2025-08-14 13:58:51.786686: train_loss -0.8177 
2025-08-14 13:58:51.786914: val_loss -0.8243 
2025-08-14 13:58:51.787071: Pseudo dice [0.8957, 0.929] 
2025-08-14 13:58:51.787205: Epoch time: 119.87 s 
2025-08-14 13:58:51.787335: Yayy! New best EMA pseudo Dice: 0.8953 
2025-08-14 13:58:55.420358:  
2025-08-14 13:58:55.420441: Epoch 37 
2025-08-14 13:58:55.420507: Current learning rate: 0.00967 
2025-08-14 14:00:50.988130: train_loss -0.824 
2025-08-14 14:00:50.988477: val_loss -0.8071 
2025-08-14 14:00:50.988640: Pseudo dice [0.8527, 0.9356] 
2025-08-14 14:00:50.988890: Epoch time: 115.57 s 
2025-08-14 14:00:53.192103:  
2025-08-14 14:00:53.192258: Epoch 38 
2025-08-14 14:00:53.192327: Current learning rate: 0.00966 
2025-08-14 14:02:54.587840: train_loss -0.8135 
2025-08-14 14:02:54.588010: val_loss -0.8429 
2025-08-14 14:02:54.588052: Pseudo dice [0.8969, 0.9354] 
2025-08-14 14:02:54.588097: Epoch time: 121.4 s 
2025-08-14 14:02:54.588128: Yayy! New best EMA pseudo Dice: 0.8972 
2025-08-14 14:02:57.915766:  
2025-08-14 14:02:57.915937: Epoch 39 
2025-08-14 14:02:57.916062: Current learning rate: 0.00965 
2025-08-14 14:05:01.485929: train_loss -0.8196 
2025-08-14 14:05:01.486068: val_loss -0.8294 
2025-08-14 14:05:01.486172: Pseudo dice [0.8516, 0.9085] 
2025-08-14 14:05:01.486232: Epoch time: 123.57 s 
2025-08-14 14:05:03.716053:  
2025-08-14 14:05:03.716160: Epoch 40 
2025-08-14 14:05:03.716224: Current learning rate: 0.00964 
2025-08-14 14:07:10.286237: train_loss -0.8284 
2025-08-14 14:07:10.286402: val_loss -0.8432 
2025-08-14 14:07:10.286456: Pseudo dice [0.8935, 0.9431] 
2025-08-14 14:07:10.286501: Epoch time: 126.57 s 
2025-08-14 14:07:10.286532: Yayy! New best EMA pseudo Dice: 0.8978 
2025-08-14 14:07:13.793793:  
2025-08-14 14:07:13.793880: Epoch 41 
2025-08-14 14:07:13.793952: Current learning rate: 0.00963 
2025-08-14 14:09:15.886770: train_loss -0.8178 
2025-08-14 14:09:15.886908: val_loss -0.8372 
2025-08-14 14:09:15.886948: Pseudo dice [0.8854, 0.9307] 
2025-08-14 14:09:15.886986: Epoch time: 122.09 s 
2025-08-14 14:09:15.887015: Yayy! New best EMA pseudo Dice: 0.8988 
2025-08-14 14:09:18.610991:  
2025-08-14 14:09:18.611099: Epoch 42 
2025-08-14 14:09:18.611170: Current learning rate: 0.00962 
2025-08-14 14:11:19.986489: train_loss -0.8234 
2025-08-14 14:11:19.986617: val_loss -0.8171 
2025-08-14 14:11:19.986657: Pseudo dice [0.8735, 0.9365] 
2025-08-14 14:11:19.986696: Epoch time: 121.38 s 
2025-08-14 14:11:19.986727: Yayy! New best EMA pseudo Dice: 0.8994 
2025-08-14 14:11:23.236299:  
2025-08-14 14:11:23.236410: Epoch 43 
2025-08-14 14:11:23.236494: Current learning rate: 0.00961 
2025-08-14 14:13:24.589959: train_loss -0.8214 
2025-08-14 14:13:24.590099: val_loss -0.8382 
2025-08-14 14:13:24.590148: Pseudo dice [0.8719, 0.9227] 
2025-08-14 14:13:24.590188: Epoch time: 121.35 s 
2025-08-14 14:13:27.312522:  
2025-08-14 14:13:27.312665: Epoch 44 
2025-08-14 14:13:27.312738: Current learning rate: 0.0096 
2025-08-14 14:15:30.988588: train_loss -0.8143 
2025-08-14 14:15:30.988863: val_loss -0.8386 
2025-08-14 14:15:30.988909: Pseudo dice [0.9004, 0.9185] 
2025-08-14 14:15:30.988954: Epoch time: 123.68 s 
2025-08-14 14:15:30.988985: Yayy! New best EMA pseudo Dice: 0.9003 
2025-08-14 14:15:34.214869:  
2025-08-14 14:15:34.214977: Epoch 45 
2025-08-14 14:15:34.215049: Current learning rate: 0.00959 
2025-08-14 14:17:39.986199: train_loss -0.8231 
2025-08-14 14:17:39.986321: val_loss -0.8368 
2025-08-14 14:17:39.986362: Pseudo dice [0.8878, 0.9452] 
2025-08-14 14:17:39.986402: Epoch time: 125.77 s 
2025-08-14 14:17:39.986441: Yayy! New best EMA pseudo Dice: 0.9019 
2025-08-14 14:17:42.707878:  
2025-08-14 14:17:42.707984: Epoch 46 
2025-08-14 14:17:42.708066: Current learning rate: 0.00959 
2025-08-14 14:19:46.490769: train_loss -0.8244 
2025-08-14 14:19:46.490977: val_loss -0.8472 
2025-08-14 14:19:46.491099: Pseudo dice [0.8871, 0.9379] 
2025-08-14 14:19:46.491193: Epoch time: 123.78 s 
2025-08-14 14:19:46.491333: Yayy! New best EMA pseudo Dice: 0.9029 
2025-08-14 14:19:50.284536:  
2025-08-14 14:19:50.284676: Epoch 47 
2025-08-14 14:19:50.284749: Current learning rate: 0.00958 
2025-08-14 14:21:54.086067: train_loss -0.8371 
2025-08-14 14:21:54.086189: val_loss -0.8352 
2025-08-14 14:21:54.086230: Pseudo dice [0.8946, 0.946] 
2025-08-14 14:21:54.086274: Epoch time: 123.8 s 
2025-08-14 14:21:54.086304: Yayy! New best EMA pseudo Dice: 0.9047 
2025-08-14 14:21:57.366408:  
2025-08-14 14:21:57.366595: Epoch 48 
2025-08-14 14:21:57.366672: Current learning rate: 0.00957 
2025-08-14 14:23:56.486241: train_loss -0.8406 
2025-08-14 14:23:56.490390: val_loss -0.781 
2025-08-14 14:23:56.490537: Pseudo dice [0.8479, 0.9351] 
2025-08-14 14:23:56.490596: Epoch time: 119.12 s 
2025-08-14 14:23:58.426309:  
2025-08-14 14:23:58.426403: Epoch 49 
2025-08-14 14:23:58.426474: Current learning rate: 0.00956 
2025-08-14 14:25:54.586958: train_loss -0.8312 
2025-08-14 14:25:54.591344: val_loss -0.8538 
2025-08-14 14:25:54.591459: Pseudo dice [0.8857, 0.9397] 
2025-08-14 14:25:54.591519: Epoch time: 116.16 s 
2025-08-14 14:25:58.109988:  
2025-08-14 14:25:58.110090: Epoch 50 
2025-08-14 14:25:58.110158: Current learning rate: 0.00955 
2025-08-14 14:28:02.386468: train_loss -0.8376 
2025-08-14 14:28:02.386613: val_loss -0.8554 
2025-08-14 14:28:02.386653: Pseudo dice [0.8891, 0.937] 
2025-08-14 14:28:02.386693: Epoch time: 124.28 s 
2025-08-14 14:28:02.386721: Yayy! New best EMA pseudo Dice: 0.9052 
2025-08-14 14:28:06.104203:  
2025-08-14 14:28:06.104283: Epoch 51 
2025-08-14 14:28:06.104347: Current learning rate: 0.00954 
2025-08-14 14:30:05.586123: train_loss -0.8376 
2025-08-14 14:30:05.586396: val_loss -0.8167 
2025-08-14 14:30:05.586456: Pseudo dice [0.8727, 0.9216] 
2025-08-14 14:30:05.586507: Epoch time: 119.48 s 
2025-08-14 14:30:08.822774:  
2025-08-14 14:30:08.822892: Epoch 52 
2025-08-14 14:30:08.822991: Current learning rate: 0.00953 
2025-08-14 14:32:05.186399: train_loss -0.8404 
2025-08-14 14:32:05.186581: val_loss -0.864 
2025-08-14 14:32:05.186635: Pseudo dice [0.9102, 0.9457] 
2025-08-14 14:32:05.186692: Epoch time: 116.36 s 
2025-08-14 14:32:05.186737: Yayy! New best EMA pseudo Dice: 0.9067 
2025-08-14 14:32:08.201718:  
2025-08-14 14:32:08.201793: Epoch 53 
2025-08-14 14:32:08.201857: Current learning rate: 0.00952 
2025-08-14 14:34:06.787078: train_loss -0.8459 
2025-08-14 14:34:06.787209: val_loss -0.8251 
2025-08-14 14:34:06.787251: Pseudo dice [0.8888, 0.9427] 
2025-08-14 14:34:06.787291: Epoch time: 118.59 s 
2025-08-14 14:34:06.787321: Yayy! New best EMA pseudo Dice: 0.9076 
2025-08-14 14:34:09.837600:  
2025-08-14 14:34:09.837680: Epoch 54 
2025-08-14 14:34:09.837745: Current learning rate: 0.00951 
2025-08-14 14:36:02.385862: train_loss -0.8433 
2025-08-14 14:36:02.385987: val_loss -0.8359 
2025-08-14 14:36:02.386037: Pseudo dice [0.8996, 0.9309] 
2025-08-14 14:36:02.386076: Epoch time: 112.55 s 
2025-08-14 14:36:02.386105: Yayy! New best EMA pseudo Dice: 0.9084 
2025-08-14 14:36:05.995583:  
2025-08-14 14:36:05.995673: Epoch 55 
2025-08-14 14:36:05.995752: Current learning rate: 0.0095 
2025-08-14 14:38:09.886280: train_loss -0.8328 
2025-08-14 14:38:09.886390: val_loss -0.8321 
2025-08-14 14:38:09.886443: Pseudo dice [0.8702, 0.9241] 
2025-08-14 14:38:09.886484: Epoch time: 123.89 s 
2025-08-14 14:38:12.599811:  
2025-08-14 14:38:12.599892: Epoch 56 
2025-08-14 14:38:12.599956: Current learning rate: 0.00949 
2025-08-14 14:40:10.186844: train_loss -0.8209 
2025-08-14 14:40:10.187088: val_loss -0.8316 
2025-08-14 14:40:10.187195: Pseudo dice [0.8761, 0.9257] 
2025-08-14 14:40:10.187257: Epoch time: 117.59 s 
2025-08-14 14:40:13.010288:  
2025-08-14 14:40:13.010445: Epoch 57 
2025-08-14 14:40:13.010527: Current learning rate: 0.00949 
2025-08-14 14:42:17.686352: train_loss -0.8409 
2025-08-14 14:42:17.686480: val_loss -0.8569 
2025-08-14 14:42:17.686521: Pseudo dice [0.9051, 0.9429] 
2025-08-14 14:42:17.686561: Epoch time: 124.68 s 
2025-08-14 14:42:19.909967:  
2025-08-14 14:42:19.910055: Epoch 58 
2025-08-14 14:42:19.910124: Current learning rate: 0.00948 
